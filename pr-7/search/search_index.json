{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pantsagon","text":"<p>Pantsagon bootstraps hexagonal monorepos managed by Pants, with enforcement from day one.</p> <p>You use Pantsagon to generate a repository where:</p> <ul> <li>each service is structured as <code>domain/</code>, <code>application/</code>, <code>adapters/</code>, <code>entrypoints/</code></li> <li>shared code is split into foundation (pure) and shared adapters (allowlisted integrations)</li> <li>dependency boundaries hard-fail locally and in CI</li> <li>optional packs add contract-first OpenAPI and Docker packaging</li> </ul>"},{"location":"#what-you-can-do-in-v1","title":"What you can do in v1","text":"<ul> <li><code>pantsagon init</code> - create a new monorepo</li> <li><code>pantsagon add service</code> - add a new service skeleton</li> <li><code>pantsagon validate</code> - validate invariants and optionally run Pants checks</li> </ul>"},{"location":"#key-concepts","title":"Key concepts","text":"<ul> <li>Packs: versioned templates (<code>pack.yaml</code> + <code>copier.yml</code> + <code>templates/</code>)</li> <li>Repo lock: <code>.pantsagon.toml</code> is the single source of truth for pack pins and answers</li> <li>Diagnostics: structured errors/warnings emitted by all frontends</li> </ul> <p>Start with Getting started -&gt; Quickstart.</p> <p>Looking to contribute? See Contributing -&gt; Docs.</p>"},{"location":"cli/","title":"CLI overview","text":"<p>v1 commands:</p> <ul> <li><code>pantsagon init</code></li> <li><code>pantsagon add service</code></li> <li><code>pantsagon validate</code></li> </ul> <p>All commands support structured diagnostics and stable exit codes.</p>"},{"location":"cli/add-service/","title":"pantsagon add service","text":"<p>Add a new service skeleton into an existing Pantsagon repo.</p> <pre><code>pantsagon add service &lt;name&gt; --lang python\n</code></pre> <p>Optional:</p> <ul> <li><code>--feature openapi</code></li> <li><code>--feature docker</code></li> <li><code>--strict</code></li> </ul>"},{"location":"cli/exit-codes/","title":"Exit codes","text":"<p>Stable exit codes:</p> <ul> <li><code>0</code> success</li> <li><code>2</code> validation failure (schema/invariants/compatibility)</li> <li><code>3</code> execution failure (IO/renderer/subprocess)</li> <li><code>4</code> internal error (unexpected exception)</li> </ul>"},{"location":"cli/init/","title":"pantsagon init","text":"<p>Create a new monorepo.</p> <pre><code>pantsagon init &lt;repo&gt;\n</code></pre> <p>Common flags:</p> <ul> <li><code>--lang python</code> (required in v1)</li> <li><code>--services a,b</code></li> <li><code>--feature openapi</code> (repeatable)</li> <li><code>--feature docker</code> (repeatable)</li> <li><code>--strict</code></li> <li><code>--renderer copier</code></li> <li><code>--non-interactive</code></li> </ul>"},{"location":"cli/validate/","title":"pantsagon validate","text":"<p>Validate <code>.pantsagon.toml</code>, packs, and repo invariants.</p> <pre><code>pantsagon validate\n</code></pre> <p>Flags:</p> <ul> <li><code>--exec</code> runs configured Pants goals (lint/check/test etc.)</li> <li><code>--strict</code> upgrades warnings to errors</li> <li><code>--json</code> outputs machine-readable Result</li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>Pantsagon itself is hexagonal:</p> <ul> <li>Domain models <code>Blueprint -&gt; PackSelection -&gt; RenderPlan -&gt; RepoLock -&gt; Diagnostics</code></li> <li>Application orchestrates <code>init</code>, <code>add service</code>, and <code>validate</code></li> <li>Ports define pack discovery, rendering, workspace IO, policy checks, and command execution</li> <li>Adapters implement those ports (Copier renderer, filesystem workspace, bundled/local packs)</li> </ul> <p>This lets Pantsagon support multiple frontends and third-party extensions without forking.</p>"},{"location":"concepts/diagnostics/","title":"Diagnostics","text":"<p>All frontends emit structured diagnostics:</p> <ul> <li>code (stable identifier)</li> <li>rule (stable rule id / namespace)</li> <li>severity (error|warn|info)</li> <li>message</li> <li>optional location/hint/details</li> </ul> <p>Commands return a Result:</p> <ul> <li>diagnostics</li> <li>artifacts (written paths, applied packs, executed commands)</li> <li>exit_code</li> </ul> <p>Use <code>--json</code> to emit a machine-readable Result (for CI / GitHub Actions).</p>"},{"location":"concepts/documentation-contract/","title":"Documentation contract","text":"<p>This page defines documentation requirements and rules for Pantsagon releases.</p>"},{"location":"concepts/documentation-contract/#release-requirements","title":"Release requirements","text":"<p>Every release must include:</p> <ul> <li>updated CLI docs if flags changed</li> <li>updated schema docs if schemas changed</li> <li>updated diagnostic codes if codes changed</li> <li>updated pack docs if pack format or bundled packs changed</li> </ul>"},{"location":"concepts/documentation-contract/#versioning-rules","title":"Versioning rules","text":"<p>Documentation is published per tool version:</p> <ul> <li><code>dev</code> - tracks <code>main</code></li> <li><code>latest</code> - alias for the newest release</li> <li><code>vX.Y.Z</code> - tagged releases</li> <li><code>pr-&lt;num&gt;</code> - PR previews</li> </ul>"},{"location":"concepts/documentation-contract/#local-docs-workflow","title":"Local docs workflow","text":"<pre><code>pip install -r docs/requirements.txt\npip install pyyaml\npython scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\nmkdocs serve\n</code></pre>"},{"location":"concepts/documentation-contract/#generated-reference-docs","title":"Generated reference docs","text":"<p>Reference docs are generated and must not be edited by hand.</p> <ul> <li>generator scripts run in CI</li> <li>CI fails if <code>git diff</code> is non-empty after generation</li> <li>contributors must run generators locally before committing</li> </ul> <p>If you need to change reference docs, update the source files and re-run the generators.</p>"},{"location":"concepts/documentation-contract/#backlog","title":"Backlog","text":"<ul> <li>Docs: remove PR preview versions from mike on PR close</li> </ul>"},{"location":"concepts/hexagonal-architecture/","title":"Hexagonal architecture (generated repos)","text":"<p>Generated repos follow a strict layering model:</p> <ul> <li><code>domain</code>: pure rules and types (no IO)</li> <li><code>application</code>: use-cases (no concrete integrations)</li> <li><code>adapters</code>: integrations and IO (SDKs, HTTP, DB, etc.)</li> <li><code>entrypoints</code>: wiring (CLI/HTTP/workers)</li> </ul> <p>The critical property is dependency direction:</p> <ul> <li>domain depends only on itself (+ foundation)</li> <li>application depends on domain (+ foundation)</li> <li>adapters depend on application/domain (+ allowlisted shared adapters)</li> <li>entrypoints depend on adapters/application/domain</li> </ul>"},{"location":"concepts/packs/","title":"Packs","text":"<p>A pack is a versioned directory containing:</p> <ul> <li><code>pack.yaml</code> - tool-agnostic manifest (authoritative)</li> <li><code>copier.yml</code> - Copier rendering config</li> <li><code>templates/</code> - template files</li> </ul> <p>Pantsagon validates:</p> <ul> <li><code>pack.yaml</code> against a JSON Schema</li> <li><code>pack.yaml.variables</code> to <code>copier.yml</code> variable consistency</li> </ul> <p>Packs can be bundled with Pantsagon or loaded from a local directory in v1.</p>"},{"location":"concepts/repo-lock/","title":"Repo lock: .pantsagon.toml","text":"<p><code>.pantsagon.toml</code> is the single source of truth for:</p> <ul> <li>tool version</li> <li>selected packs (id/version/source)</li> <li>selected features and services</li> <li>resolved answers passed to the renderer</li> <li>strictness settings</li> </ul> <p>In v1:</p> <ul> <li>pack versions are pinned and never auto-upgraded</li> <li><code>add service</code> updates the lock deterministically</li> </ul>"},{"location":"concepts/trust-and-security/","title":"Trust and security","text":"<p>Packs are treated as untrusted content by default.</p> <ul> <li>hook execution is disabled unless explicitly allowed (or pack is trusted)</li> <li>v1 supports only bundled and local packs (no network fetching)</li> </ul> <p>Future:</p> <ul> <li>trust allowlist (local file)</li> <li>signed pack metadata</li> <li>registry-based distribution</li> </ul>"},{"location":"contributing/docs/","title":"Contributing to docs","text":"<p>Docs are part of the Pantsagon API surface. Keep them versioned and reproducible.</p>"},{"location":"contributing/docs/#where-to-edit","title":"Where to edit","text":"<ul> <li>user docs live in <code>docs/</code></li> <li>reference docs are generated from <code>schemas/</code> and <code>pantsagon/diagnostics/codes.yaml</code></li> </ul>"},{"location":"contributing/docs/#edit-links","title":"Edit links","text":"<p>Each page has an \"Edit this page\" link in the header. If you are a pack author or plugin author, start in Pack authoring or Plugin authoring.</p>"},{"location":"contributing/docs/#local-workflow","title":"Local workflow","text":"<pre><code>pip install -r docs/requirements.txt\npip install pyyaml\npython scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\nmkdocs serve\n</code></pre>"},{"location":"contributing/docs/#generated-files","title":"Generated files","text":"<p>Generated reference docs must not be edited by hand. Run the scripts above to update them.</p>"},{"location":"contributing/docs/#backlog","title":"Backlog","text":"<ul> <li>Docs: remove PR preview versions from mike on PR close</li> </ul>"},{"location":"contributing/release-checklist-v1.0.0/","title":"v1.0.0 Release Checklist","text":"<p>This checklist defines the minimum release readiness steps for Pantsagon v1.0.0.</p>"},{"location":"contributing/release-checklist-v1.0.0/#pre-release-verification","title":"Pre-release verification","text":"<ul> <li>[ ] CI green: pytest + pack validation (deterministic mode)</li> <li>[ ] <code>python -m pantsagon.tools.validate_packs --bundled</code> passes locally</li> <li>[ ] Docs generators ran with clean git diff</li> <li>[ ] README reflects current CLI behavior and status</li> </ul>"},{"location":"contributing/release-checklist-v1.0.0/#packaging-and-versioning","title":"Packaging and versioning","text":"<ul> <li>[ ] Update <code>pyproject.toml</code> version to <code>1.0.0</code></li> <li>[ ] Tag the release <code>v1.0.0</code></li> <li>[ ] Publish release notes</li> </ul>"},{"location":"contributing/release-checklist-v1.0.0/#documentation","title":"Documentation","text":"<ul> <li>[ ] Update CLI docs if flags changed</li> <li>[ ] Update schema docs if schemas changed</li> <li>[ ] Update diagnostic codes if codes changed</li> <li>[ ] Update pack docs if packs changed</li> <li>[ ] Publish docs for <code>v1.0.0</code> and update <code>latest</code></li> </ul>"},{"location":"getting-started/faq/","title":"FAQ","text":""},{"location":"getting-started/faq/#does-pantsagon-support-languages-other-than-python","title":"Does Pantsagon support languages other than Python?","text":"<p>Not in v1. The architecture supports multi-language packs later.</p>"},{"location":"getting-started/faq/#do-i-have-to-use-docker","title":"Do I have to use Docker?","text":"<p>No. Docker is a feature pack.</p>"},{"location":"getting-started/faq/#why-is-layering-enforced","title":"Why is layering enforced?","text":"<p>Because directory structure alone does not stop coupling. Enforcement makes the architecture real.</p>"},{"location":"getting-started/faq/#does-pantsagon-run-pants-during-generation","title":"Does Pantsagon run Pants during generation?","text":"<p>Only if you ask for it (for example, <code>validate --exec</code>), to keep init fast and predictable.</p>"},{"location":"getting-started/generated-repo-tour/","title":"Generated repo tour","text":"<p>A generated repo has these top-level areas:</p> <ul> <li><code>services/</code> - independently-deployable services</li> <li><code>shared/foundation/</code> - pure primitives, globally allowed</li> <li><code>shared/adapters/</code> - reusable integrations (allowlisted)</li> <li><code>tools/</code> - repo-owned checks (forbidden imports, validators)</li> <li><code>.pantsagon.toml</code> - pack pins and answers (source of truth)</li> </ul> <p>Each service follows:</p> <ul> <li><code>domain/</code>: pure business rules</li> <li><code>application/</code>: use-cases</li> <li><code>adapters/</code>: IO implementations</li> <li><code>entrypoints/</code>: CLI/HTTP/worker wiring</li> </ul> <p>The repo is designed so layering is enforced by Pants dependency rules.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":""},{"location":"getting-started/quickstart/#install-pantsagon","title":"Install Pantsagon","text":"<p>Recommended (isolated): - <code>pipx install pantsagon</code></p>"},{"location":"getting-started/quickstart/#create-a-repo","title":"Create a repo","text":"<pre><code>pantsagon init my-repo \\\n  --lang python \\\n  --services monitors,governance \\\n  --feature openapi \\\n  --feature docker\n</code></pre>"},{"location":"getting-started/quickstart/#add-a-service","title":"Add a service","text":"<pre><code>cd my-repo\npantsagon add service billing --lang python --feature docker\n</code></pre>"},{"location":"getting-started/quickstart/#validate","title":"Validate","text":"<pre><code>pantsagon validate\npantsagon validate --exec\n</code></pre> <ul> <li><code>validate</code> checks structure and manifests</li> <li><code>validate --exec</code> runs Pants goals (lint/check/test as configured)</li> </ul> <p>See CLI -&gt; init for full flags and semantics.</p>"},{"location":"pack-authoring/","title":"Pack authoring","text":"<p>Packs are the primary extension mechanism.</p> <p>A pack contains:</p> <ul> <li><code>pack.yaml</code> (authoritative manifest)</li> <li><code>copier.yml</code> (renderer config)</li> <li><code>templates/</code></li> </ul> <p>Pantsagon enforces:</p> <ul> <li>schema validation</li> <li>manifest to copier variable cross-check</li> <li>render smoke-test (for bundled packs)</li> </ul>"},{"location":"pack-authoring/pack-format/","title":"Pack format","text":"<p>Minimum pack structure:</p> <pre><code>&lt;pack&gt;/\n  pack.yaml\n  copier.yml\n  templates/\n</code></pre> <p><code>pack.yaml</code> declares:</p> <ul> <li>id + version</li> <li>compatibility</li> <li>requires/provides</li> <li>variables</li> </ul>"},{"location":"pack-authoring/publishing/","title":"Publishing","text":"<p>v1 supports:</p> <ul> <li>bundled packs (shipped with Pantsagon)</li> <li>local directory packs (user-provided paths)</li> </ul> <p>Future:</p> <ul> <li>git packs</li> <li>registry packs</li> </ul>"},{"location":"pack-authoring/validation/","title":"Validation","text":"<p>Bundled packs must pass:</p> <p>1) <code>pack.yaml</code> schema validation 2) manifest to copier variable cross-check 3) render smoke-test with minimal inputs</p>"},{"location":"pack-authoring/variables/","title":"Variables","text":"<p>Variables are declared in <code>pack.yaml</code> and mirrored in <code>copier.yml</code>.</p> <p>Policy:</p> <ul> <li>every manifest variable must exist in copier questions</li> <li>undeclared copier variables are errors (default)</li> <li>default mismatches are warnings (strict mode turns warnings into errors)</li> </ul>"},{"location":"plans/2026-01-10-docs-system/","title":"Docs System Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement a docs-as-code system with MkDocs + Material + mike, versioned publishing, reference-doc generators, and CI enforcement.</p> <p>Architecture: Documentation lives under <code>docs/</code> with a structured nav. Generated reference docs are produced by scripts from canonical sources (<code>schemas/</code> and <code>pantsagon/diagnostics/codes.yaml</code>) and CI fails if outputs drift. GitHub Actions publishes versioned docs to <code>gh-pages</code> using mike.</p> <p>Tech Stack: MkDocs + Material, mike, GitHub Actions, Python 3.12, PyYAML, JSON Schema.</p>"},{"location":"plans/2026-01-10-docs-system/#task-1-add-mkdocs-config-docs-dependency-pins-python-pin","title":"Task 1: Add MkDocs config + docs dependency pins + Python pin","text":"<p>Files: - Create: <code>mkdocs.yml</code> - Create: <code>docs/requirements.txt</code> - Create: <code>.python-version</code></p> <p>Step 1: Create <code>mkdocs.yml</code></p> <pre><code>site_name: Pantsagon\nsite_description: Hexagonal monorepos in Pants - generated with enforced boundaries.\nsite_url: https://engineeringergonomics.github.io/pantsagon/\nrepo_url: https://github.com/EngineeringErgonomics/pantsagon\nrepo_name: EngineeringErgonomics/pantsagon\nedit_uri: edit/main/docs/\n\ntheme:\n  name: material\n  language: en\n  features:\n    - navigation.instant\n    - navigation.instant.progress\n    - navigation.tracking\n    - navigation.sections\n    - navigation.expand\n    - navigation.path\n    - toc.follow\n    - content.action.edit\n    - content.code.copy\n    - content.tabs.link\n    - search.suggest\n    - search.highlight\n  icon:\n    repo: fontawesome/brands/github\n  palette:\n    - scheme: default\n      primary: indigo\n      accent: indigo\n\nplugins:\n  - search\n\nmarkdown_extensions:\n  - admonition\n  - attr_list\n  - def_list\n  - footnotes\n  - pymdownx.details\n  - pymdownx.superfences\n  - pymdownx.inlinehilite\n  - pymdownx.highlight:\n      anchor_linenums: true\n  - pymdownx.tabbed:\n      alternate_style: true\n  - toc:\n      permalink: true\n\nextra:\n  version:\n    provider: mike\n\nnav:\n  - Home: index.md\n\n  - Getting started:\n      - Quickstart: getting-started/quickstart.md\n      - Generated repo tour: getting-started/generated-repo-tour.md\n      - FAQ: getting-started/faq.md\n\n  - Concepts:\n      - Architecture: concepts/architecture.md\n      - Documentation contract: concepts/documentation-contract.md\n      - Hexagonal layering: concepts/hexagonal-architecture.md\n      - Packs: concepts/packs.md\n      - Repo lock: concepts/repo-lock.md\n      - Diagnostics: concepts/diagnostics.md\n      - Trust model: concepts/trust-and-security.md\n\n  - CLI:\n      - Overview: cli/index.md\n      - init: cli/init.md\n      - add service: cli/add-service.md\n      - validate: cli/validate.md\n      - Exit codes: cli/exit-codes.md\n\n  - Pack authoring:\n      - Overview: pack-authoring/index.md\n      - Pack format: pack-authoring/pack-format.md\n      - Variables: pack-authoring/variables.md\n      - Validation: pack-authoring/validation.md\n      - Publishing: pack-authoring/publishing.md\n\n  - Plugin authoring:\n      - Overview: plugin-authoring/index.md\n      - Ports: plugin-authoring/ports.md\n      - Adapters: plugin-authoring/adapters.md\n      - Discovery: plugin-authoring/discovery.md\n\n  - Reference:\n      - Schemas:\n          - pack.schema.v1: reference/pack.schema.v1.md\n          - repo lock schema: reference/repo-lock.schema.v1.md\n          - result schema: reference/result.schema.v1.md\n      - Diagnostic codes: reference/diagnostic-codes.md\n\n  - Contributing:\n      - Docs: contributing/docs.md\n</code></pre> <p>Step 2: Create <code>docs/requirements.txt</code></p> <pre><code>mkdocs-material==9.5.36\nmike==2.1.2\n</code></pre> <p>Step 3: Create <code>.python-version</code></p> <pre><code>3.12.0\n</code></pre> <p>Step 4: Commit</p> <pre><code>git add mkdocs.yml docs/requirements.txt .python-version\ngit commit -m \"docs: add mkdocs config and pinned deps\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-2-create-docs-tree-starter-content-contract-contributing-page","title":"Task 2: Create docs tree + starter content + contract + contributing page","text":"<p>Files: - Create: <code>docs/index.md</code> - Create: <code>docs/getting-started/quickstart.md</code> - Create: <code>docs/getting-started/generated-repo-tour.md</code> - Create: <code>docs/getting-started/faq.md</code> - Create: <code>docs/concepts/architecture.md</code> - Create: <code>docs/concepts/documentation-contract.md</code> - Create: <code>docs/concepts/hexagonal-architecture.md</code> - Create: <code>docs/concepts/packs.md</code> - Create: <code>docs/concepts/repo-lock.md</code> - Create: <code>docs/concepts/diagnostics.md</code> - Create: <code>docs/concepts/trust-and-security.md</code> - Create: <code>docs/cli/index.md</code> - Create: <code>docs/cli/init.md</code> - Create: <code>docs/cli/add-service.md</code> - Create: <code>docs/cli/validate.md</code> - Create: <code>docs/cli/exit-codes.md</code> - Create: <code>docs/pack-authoring/index.md</code> - Create: <code>docs/pack-authoring/pack-format.md</code> - Create: <code>docs/pack-authoring/variables.md</code> - Create: <code>docs/pack-authoring/validation.md</code> - Create: <code>docs/pack-authoring/publishing.md</code> - Create: <code>docs/plugin-authoring/index.md</code> - Create: <code>docs/plugin-authoring/ports.md</code> - Create: <code>docs/plugin-authoring/adapters.md</code> - Create: <code>docs/plugin-authoring/discovery.md</code> - Create: <code>docs/contributing/docs.md</code></p> <p>Step 1: Create <code>docs/index.md</code></p> <pre><code># Pantsagon\n\nPantsagon bootstraps **hexagonal monorepos** managed by **Pants**, with enforcement from day one.\n\nYou use Pantsagon to generate a repository where:\n\n- each service is structured as `domain/`, `application/`, `adapters/`, `entrypoints/`\n- shared code is split into **foundation** (pure) and **shared adapters** (allowlisted integrations)\n- dependency boundaries hard-fail locally and in CI\n- optional packs add contract-first OpenAPI and Docker packaging\n\n## What you can do in v1\n\n- `pantsagon init` - create a new monorepo\n- `pantsagon add service` - add a new service skeleton\n- `pantsagon validate` - validate invariants and optionally run Pants checks\n\n## Key concepts\n\n- **Packs**: versioned templates (`pack.yaml` + `copier.yml` + `templates/`)\n- **Repo lock**: `.pantsagon.toml` is the single source of truth for pack pins and answers\n- **Diagnostics**: structured errors/warnings emitted by all frontends\n\nStart with **Getting started \u2192 Quickstart**.\n\nLooking to contribute? See **Contributing \u2192 Docs**.\n</code></pre> <p>Step 2: Create Getting started pages</p> <pre><code># Quickstart\n\n## Install Pantsagon\n\nRecommended (isolated):\n- `pipx install pantsagon`\n\n## Create a repo\n\n```bash\npantsagon init my-repo \\\n  --lang python \\\n  --services monitors,governance \\\n  --feature openapi \\\n  --feature docker\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#add-a-service","title":"Add a service","text":"<pre><code>cd my-repo\npantsagon add service billing --lang python --feature docker\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#validate","title":"Validate","text":"<pre><code>pantsagon validate\npantsagon validate --exec\n</code></pre> <ul> <li><code>validate</code> checks structure and manifests</li> <li><code>validate --exec</code> runs Pants goals (lint/check/test as configured)</li> </ul> <p>See CLI \u2192 init for full flags and semantics. <pre><code>```md\n# Generated repo tour\n\nA generated repo has these top-level areas:\n\n- `services/` - independently-deployable services\n- `shared/foundation/` - pure primitives, globally allowed\n- `shared/adapters/` - reusable integrations (allowlisted)\n- `tools/` - repo-owned checks (e.g., forbidden imports)\n- `.pantsagon.toml` - pack pins and answers (source of truth)\n\nEach service follows:\n\n- `domain/`: pure business rules\n- `application/`: use-cases\n- `adapters/`: IO implementations\n- `entrypoints/`: CLI/HTTP/worker wiring\n\nThe repo is designed so layering is enforced by Pants dependency rules.\n</code></pre></p> <pre><code># FAQ\n\n## Does Pantsagon support languages other than Python?\n\nNot in v1. The architecture supports multi-language packs later.\n\n## Do I have to use Docker?\n\nNo. Docker is a feature pack.\n\n## Why is layering enforced?\n\nBecause \u201cdirectory structure\u201d alone does not stop coupling. Enforcement makes the architecture real.\n\n## Does Pantsagon run Pants during generation?\n\nOnly if you ask for it (e.g., `validate --exec`), to keep init fast and predictable.\n</code></pre> <p>Step 3: Create Concepts pages (including documentation contract)</p> <pre><code># Architecture\n\nPantsagon itself is hexagonal:\n\n- **Domain** models `Blueprint \u2192 PackSelection \u2192 RenderPlan \u2192 RepoLock \u2192 Diagnostics`\n- **Application** orchestrates `init`, `add service`, and `validate`\n- **Ports** define pack discovery, rendering, workspace IO, policy checks, and command execution\n- **Adapters** implement those ports (Copier renderer, filesystem workspace, bundled/local packs)\n\nThis lets Pantsagon support multiple frontends and third-party extensions without forking.\n</code></pre> <pre><code># Documentation contract\n\nThis page defines the documentation requirements and rules for Pantsagon releases.\n\n## Release requirements\n\nEvery release must include:\n\n- updated CLI docs if flags changed\n- updated schema docs if schemas changed\n- updated diagnostic codes if codes changed\n- updated pack docs if pack format or bundled packs changed\n\n## Versioning rules\n\nDocumentation is published per tool version:\n\n- `dev` - tracks `main`\n- `latest` - alias for the newest release\n- `vX.Y.Z` - tagged releases\n- `pr-&lt;num&gt;` - PR previews\n\n## Local docs workflow\n\n```bash\npip install -r docs/requirements.txt\npip install pyyaml\npython scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\nmkdocs serve\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#generated-reference-docs","title":"Generated reference docs","text":"<p>Reference docs are generated and must not be edited by hand.</p> <ul> <li>generator scripts run in CI</li> <li>CI fails if <code>git diff</code> is non-empty after generation</li> <li>contributors must run generators locally before committing</li> </ul> <p>If you need to change reference docs, update the source files and re-run the generators. <pre><code>```md\n# Hexagonal architecture (generated repos)\n\nGenerated repos follow a strict layering model:\n\n- `domain`: pure rules and types (no IO)\n- `application`: use-cases (no concrete integrations)\n- `adapters`: integrations and IO (SDKs, HTTP, DB, etc.)\n- `entrypoints`: wiring (CLI/HTTP/workers)\n\nThe critical property is **dependency direction**:\n- domain depends only on itself (+ foundation)\n- application depends on domain (+ foundation)\n- adapters depend on application/domain (+ allowlisted shared adapters)\n- entrypoints depend on adapters/application/domain\n</code></pre></p> <pre><code># Packs\n\nA pack is a versioned directory containing:\n\n- `pack.yaml` - tool-agnostic manifest (authoritative)\n- `copier.yml` - Copier rendering config\n- `templates/` - template files\n\nPantsagon validates:\n- `pack.yaml` against a JSON Schema\n- `pack.yaml.variables` \u2194 `copier.yml` variables consistency\n\nPacks can be bundled with Pantsagon or loaded from a local directory in v1.\n</code></pre> <pre><code># Repo lock: .pantsagon.toml\n\n`.pantsagon.toml` is the single source of truth for:\n\n- tool version\n- selected packs (id/version/source)\n- selected features and services\n- resolved answers passed to the renderer\n- strictness settings\n\nIn v1:\n- pack versions are pinned and never auto-upgraded\n- `add service` updates the lock deterministically\n</code></pre> <pre><code># Diagnostics\n\nAll frontends emit structured diagnostics:\n\n- code (stable identifier)\n- rule (stable rule id / namespace)\n- severity (error|warn|info)\n- message\n- optional location/hint/details\n\nCommands return a `Result`:\n- diagnostics\n- artifacts (written paths, applied packs, executed commands)\n- exit_code\n\nUse `--json` to emit a machine-readable Result (for CI / GH Actions).\n</code></pre> <pre><code># Trust and security\n\nPacks are treated as untrusted content by default.\n\n- Hook execution is disabled unless explicitly allowed (or pack is trusted).\n- v1 supports only bundled and local packs (no network fetching).\n\nFuture:\n- trust allowlist (local file)\n- signed pack metadata\n- registry-based distribution\n</code></pre> <p>Step 4: Create CLI pages</p> <pre><code># CLI overview\n\nv1 commands:\n\n- `pantsagon init`\n- `pantsagon add service`\n- `pantsagon validate`\n\nAll commands support structured diagnostics and stable exit codes.\n</code></pre> <pre><code># pantsagon init\n\nCreate a new monorepo.\n\n```bash\npantsagon init &lt;repo&gt;\n</code></pre> <p>Common flags:</p> <ul> <li><code>--lang python</code> (required in v1)</li> <li><code>--services a,b</code></li> <li><code>--feature openapi</code> (repeatable)</li> <li><code>--feature docker</code> (repeatable)</li> <li><code>--strict</code></li> <li><code>--renderer copier</code></li> <li><code>--non-interactive</code> <pre><code>```md\n# pantsagon add service\n\nAdd a new service skeleton into an existing Pantsagon repo.\n\n```bash\npantsagon add service &lt;name&gt; --lang python\n</code></pre></li> </ul> <p>Optional:</p> <ul> <li><code>--feature openapi</code></li> <li><code>--feature docker</code></li> <li><code>--strict</code> <pre><code>```md\n# pantsagon validate\n\nValidate `.pantsagon.toml`, packs, and repo invariants.\n\n```bash\npantsagon validate\n</code></pre></li> </ul> <p>Flags:</p> <ul> <li><code>--exec</code> runs configured Pants goals (lint/check/test etc.)</li> <li><code>--strict</code> upgrades warnings to errors</li> <li><code>--json</code> outputs machine-readable Result <pre><code>```md\n# Exit codes\n\nStable exit codes:\n\n- `0` success\n- `2` validation failure (schema/invariants/compatibility)\n- `3` execution failure (IO/renderer/subprocess)\n- `4` internal error (unexpected exception)\n</code></pre></li> </ul> <p>Step 5: Create Pack authoring pages</p> <pre><code># Pack authoring\n\nPacks are the primary extension mechanism.\n\nA pack contains:\n- `pack.yaml` (authoritative manifest)\n- `copier.yml` (renderer config)\n- `templates/`\n\nPantsagon enforces:\n- schema validation\n- manifest \u2194 copier variable cross-check\n- render smoke-test (for bundled packs)\n</code></pre> <pre><code># Pack format\n\nMinimum pack structure:\n\n```text\n&lt;pack&gt;/\n  pack.yaml\n  copier.yml\n  templates/\n</code></pre> <p><code>pack.yaml</code> declares:</p> <ul> <li>id + version</li> <li>compatibility</li> <li>requires/provides</li> <li>variables <pre><code>```md\n# Variables\n\nVariables are declared in `pack.yaml` and mirrored in `copier.yml`.\n\nPolicy:\n- every manifest variable must exist in copier questions\n- undeclared copier variables are errors (default)\n- default mismatches are warnings (strict mode =&gt; errors)\n</code></pre></li> </ul> <pre><code># Validation\n\nBundled packs must pass:\n1) `pack.yaml` schema validation\n2) manifest \u2194 copier variable cross-check\n3) render smoke-test with minimal inputs\n</code></pre> <pre><code># Publishing\n\nv1 supports:\n- bundled packs (shipped with Pantsagon)\n- local directory packs (user-provided paths)\n\nFuture:\n- git packs\n- registry packs\n</code></pre> <p>Step 6: Create Plugin authoring pages</p> <pre><code># Plugin authoring\n\nPlugins provide adapter implementations for ports (future scope).\n\nIn v1, plugins are not loaded, but the port contracts are designed for it.\n</code></pre> <pre><code># Ports\n\nCore ports:\n- PackCatalogPort\n- RendererPort\n- WorkspacePort\n- PolicyEnginePort\n- CommandPort\n\nPorts accept and return domain objects and must not leak implementation details.\n</code></pre> <pre><code># Adapters\n\nAdapters implement ports.\nThey should:\n- raise typed AdapterError on IO/exec failures\n- return Result/Diagnostics for expected validation outcomes\n</code></pre> <pre><code># Discovery (future)\n\nFuture plugins will be discovered via Python entry points, grouped by port:\n\n- pantsagon.pack_catalog\n- pantsagon.renderer\n- pantsagon.workspace\n- pantsagon.policy_engine\n- pantsagon.command_runner\n</code></pre> <p>Step 7: Create Contributing docs page</p> <pre><code># Contributing to docs\n\nDocs are part of the Pantsagon API surface. Keep them versioned and reproducible.\n\n## Where to edit\n\n- User docs live in `docs/`\n- Reference docs are generated from `schemas/` and `pantsagon/diagnostics/codes.yaml`\n\n## Edit links\n\nEach page has an \u201cEdit this page\u201d link in the header.\nIf you\u2019re a pack author or plugin author, start in **Pack authoring** or **Plugin authoring**.\n\n## Local workflow\n\n```bash\npip install -r docs/requirements.txt\npip install pyyaml\npython scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\nmkdocs serve\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#generated-files","title":"Generated files","text":"<p>Generated reference docs must not be edited by hand. Run the scripts above to update them.</p>"},{"location":"plans/2026-01-10-docs-system/#backlog","title":"Backlog","text":"<ul> <li>Docs: remove PR preview versions from mike on PR close <pre><code>**Step 8: Commit**\n\n```bash\ngit add docs/index.md \\\n  docs/getting-started/quickstart.md \\\n  docs/getting-started/generated-repo-tour.md \\\n  docs/getting-started/faq.md \\\n  docs/concepts/architecture.md \\\n  docs/concepts/documentation-contract.md \\\n  docs/concepts/hexagonal-architecture.md \\\n  docs/concepts/packs.md \\\n  docs/concepts/repo-lock.md \\\n  docs/concepts/diagnostics.md \\\n  docs/concepts/trust-and-security.md \\\n  docs/cli/index.md \\\n  docs/cli/init.md \\\n  docs/cli/add-service.md \\\n  docs/cli/validate.md \\\n  docs/cli/exit-codes.md \\\n  docs/pack-authoring/index.md \\\n  docs/pack-authoring/pack-format.md \\\n  docs/pack-authoring/variables.md \\\n  docs/pack-authoring/validation.md \\\n  docs/pack-authoring/publishing.md \\\n  docs/plugin-authoring/index.md \\\n  docs/plugin-authoring/ports.md \\\n  docs/plugin-authoring/adapters.md \\\n  docs/plugin-authoring/discovery.md \\\n  docs/contributing/docs.md\ngit commit -m \"docs: add starter content and contributor guidance\"\n</code></pre></li> </ul>"},{"location":"plans/2026-01-10-docs-system/#task-3-add-failing-tests-for-schema-doc-generator-tdd","title":"Task 3: Add failing tests for schema-doc generator (TDD)","text":"<p>Files: - Create: <code>tests/test_generate_schema_docs.py</code> - Create: <code>scripts/__init__.py</code></p> <p>Step 1: Create <code>scripts/__init__.py</code></p> <pre><code># Intentionally empty to allow imports in tests.\n</code></pre> <p>Step 2: Write the failing test <code>tests/test_generate_schema_docs.py</code></p> <pre><code>import json\nimport tempfile\nimport unittest\nfrom pathlib import Path\n\nfrom scripts import generate_schema_docs\n\n\nclass GenerateSchemaDocsTest(unittest.TestCase):\n    def test_generates_markdown_from_schemas(self) -&gt; None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            repo_root = Path(tmpdir)\n            schemas_dir = repo_root / \"schemas\"\n            schemas_dir.mkdir(parents=True)\n            (repo_root / \"docs\" / \"reference\").mkdir(parents=True)\n\n            def write_schema(name: str, title: str) -&gt; None:\n                (schemas_dir / name).write_text(\n                    json.dumps(\n                        {\n                            \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n                            \"$id\": f\"https://example.test/{name}\",\n                            \"title\": title,\n                            \"description\": f\"{title} description\",\n                            \"type\": \"object\",\n                            \"properties\": {\"alpha\": {\"type\": \"string\"}},\n                            \"required\": [\"alpha\"],\n                        }\n                    ),\n                    encoding=\"utf-8\",\n                )\n\n            write_schema(\"pack.schema.v1.json\", \"Pack Schema\")\n            write_schema(\"repo-lock.schema.v1.json\", \"Repo Lock Schema\")\n            write_schema(\"result.schema.v1.json\", \"Result Schema\")\n\n            generate_schema_docs.generate(repo_root)\n\n            out = (repo_root / \"docs\" / \"reference\" / \"pack.schema.v1.md\").read_text(\n                encoding=\"utf-8\"\n            )\n            self.assertIn(\"Generated file. Do not edit directly.\", out)\n            self.assertIn(\"# Pack Schema\", out)\n            self.assertIn(\"alpha\", out)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n</code></pre> <p>Step 3: Run the test to verify it fails</p> <p>Run: <code>python -m unittest tests/test_generate_schema_docs.py -v</code></p> <p>Expected: FAIL with <code>AttributeError</code> or <code>ImportError</code> because <code>generate_schema_docs.generate</code> does not exist yet.</p> <p>Step 4: Commit</p> <pre><code>git add scripts/__init__.py tests/test_generate_schema_docs.py\ngit commit -m \"test: add schema docs generator test\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-4-implement-schema-doc-generator-to-pass-tests","title":"Task 4: Implement schema-doc generator to pass tests","text":"<p>Files: - Create: <code>scripts/generate_schema_docs.py</code></p> <p>Step 1: Write minimal implementation <code>scripts/generate_schema_docs.py</code></p> <pre><code>#!/usr/bin/env python3\nfrom __future__ import annotations\n\nimport json\nfrom pathlib import Path\nfrom typing import Any\n\n\nREPO_ROOT = Path(__file__).resolve().parents[1]\n\nSCHEMA_MAP = {\n    \"pack.schema.v1.json\": \"pack.schema.v1.md\",\n    \"repo-lock.schema.v1.json\": \"repo-lock.schema.v1.md\",\n    \"result.schema.v1.json\": \"result.schema.v1.md\",\n}\n\n\ndef _load_json(path: Path) -&gt; dict[str, Any]:\n    return json.loads(path.read_text(encoding=\"utf-8\"))\n\n\ndef _md_escape(s: str) -&gt; str:\n    return s.replace(\"&lt;\", \"&amp;lt;\").replace(\"&gt;\", \"&amp;gt;\")\n\n\ndef _render_generated_notice(command: str) -&gt; str:\n    return \"\\n\".join(\n        [\n            \"&gt; **Generated file. Do not edit directly.**\",\n            f\"&gt; Run: `{command}`\",\n        ]\n    )\n\n\ndef _render_schema_overview(schema: dict[str, Any]) -&gt; str:\n    title = schema.get(\"title\") or \"Schema\"\n    desc = schema.get(\"description\") or \"\"\n    schema_id = schema.get(\"$id\") or \"\"\n    schema_version = schema.get(\"$schema\") or \"\"\n\n    lines: list[str] = []\n    lines.append(f\"# {_md_escape(title)}\")\n    if desc:\n        lines.append(\"\")\n        lines.append(desc.strip())\n    if schema_id or schema_version:\n        lines.append(\"\")\n        if schema_id:\n            lines.append(f\"- **$id**: `{schema_id}`\")\n        if schema_version:\n            lines.append(f\"- **$schema**: `{schema_version}`\")\n    return \"\\n\".join(lines)\n\n\ndef _render_properties(schema: dict[str, Any]) -&gt; str:\n    props: dict[str, Any] = schema.get(\"properties\") or {}\n    required: set[str] = set(schema.get(\"required\") or [])\n\n    if not props:\n        return \"## Properties\\n\\n(No top-level properties declared.)\"\n\n    lines: list[str] = []\n    lines.append(\"## Properties\")\n    lines.append(\"\")\n    lines.append(\"| Name | Type | Required | Description |\")\n    lines.append(\"|---|---|---:|---|\")\n\n    for name in sorted(props.keys()):\n        p = props[name] or {}\n        p_type = p.get(\"type\")\n        if isinstance(p_type, list):\n            type_str = \" | \".join(str(t) for t in p_type)\n        else:\n            type_str = str(p_type) if p_type is not None else \"(unspecified)\"\n        desc = (p.get(\"description\") or \"\").strip().replace(\"\\n\", \" \")\n        lines.append(\n            f\"| `{name}` | `{type_str}` | {'yes' if name in required else 'no'} | {desc} |\"\n        )\n\n    return \"\\n\".join(lines)\n\n\ndef _render_raw(schema: dict[str, Any]) -&gt; str:\n    pretty = json.dumps(schema, indent=2, sort_keys=True)\n    return \"## Raw JSON\\n\\n```json\\n\" + pretty + \"\\n```\\n\"\n\n\ndef generate(repo_root: Path = REPO_ROOT) -&gt; None:\n    schemas_dir = repo_root / \"schemas\"\n    out_dir = repo_root / \"docs\" / \"reference\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    for in_name, out_name in SCHEMA_MAP.items():\n        in_path = schemas_dir / in_name\n        if not in_path.exists():\n            raise SystemExit(f\"Schema file not found: {in_path}\")\n\n        schema = _load_json(in_path)\n        md = \"\\n\\n\".join(\n            [\n                _render_generated_notice(\"python scripts/generate_schema_docs.py\"),\n                _render_schema_overview(schema),\n                _render_properties(schema),\n                _render_raw(schema),\n            ]\n        )\n        out_path = out_dir / out_name\n        out_path.write_text(md + \"\\n\", encoding=\"utf-8\")\n\n    print(f\"Generated schema docs into {out_dir}\")\n\n\nif __name__ == \"__main__\":\n    generate()\n</code></pre> <p>Step 2: Run tests to verify pass</p> <p>Run: <code>python -m unittest tests/test_generate_schema_docs.py -v</code></p> <p>Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add scripts/generate_schema_docs.py\ngit commit -m \"feat: add schema docs generator\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-5-add-failing-tests-for-diagnostic-codes-generator-tdd","title":"Task 5: Add failing tests for diagnostic-codes generator (TDD)","text":"<p>Files: - Create: <code>tests/test_generate_diagnostic_codes.py</code></p> <p>Step 1: Write the failing test <code>tests/test_generate_diagnostic_codes.py</code></p> <pre><code>import tempfile\nimport unittest\nfrom pathlib import Path\n\nfrom scripts import generate_diagnostic_codes\n\n\nclass GenerateDiagnosticCodesTest(unittest.TestCase):\n    def test_generates_markdown_from_codes_yaml(self) -&gt; None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            repo_root = Path(tmpdir)\n            src = repo_root / \"pantsagon\" / \"diagnostics\"\n            src.mkdir(parents=True)\n            (repo_root / \"docs\" / \"reference\").mkdir(parents=True)\n\n            (src / \"codes.yaml\").write_text(\n                \"\"\"\nversion: 1\ncodes:\n  - code: EXAMPLE_CODE\n    severity: error\n    rule: example.rule\n    message: Example message\n    hint: Example hint\n\"\"\".lstrip(),\n                encoding=\"utf-8\",\n            )\n\n            generate_diagnostic_codes.generate(repo_root)\n\n            out = (repo_root / \"docs\" / \"reference\" / \"diagnostic-codes.md\").read_text(\n                encoding=\"utf-8\"\n            )\n            self.assertIn(\"Generated file. Do not edit directly.\", out)\n            self.assertIn(\"EXAMPLE_CODE\", out)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n</code></pre> <p>Step 2: Run the test to verify it fails</p> <p>Run: <code>python -m unittest tests/test_generate_diagnostic_codes.py -v</code></p> <p>Expected: FAIL with <code>AttributeError</code> or <code>ImportError</code> because <code>generate_diagnostic_codes.generate</code> does not exist yet.</p> <p>Step 3: Commit</p> <pre><code>git add tests/test_generate_diagnostic_codes.py\ngit commit -m \"test: add diagnostic codes generator test\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-6-implement-diagnostic-codes-generator-to-pass-tests","title":"Task 6: Implement diagnostic-codes generator to pass tests","text":"<p>Files: - Create: <code>scripts/generate_diagnostic_codes.py</code></p> <p>Step 1: Write minimal implementation <code>scripts/generate_diagnostic_codes.py</code></p> <pre><code>#!/usr/bin/env python3\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml\n\n\nREPO_ROOT = Path(__file__).resolve().parents[1]\n\n\ndef _load_yaml(path: Path) -&gt; dict[str, Any]:\n    return yaml.safe_load(path.read_text(encoding=\"utf-8\")) or {}\n\n\ndef _render_generated_notice(command: str) -&gt; str:\n    return \"\\n\".join(\n        [\n            \"&gt; **Generated file. Do not edit directly.**\",\n            f\"&gt; Run: `{command}`\",\n        ]\n    )\n\n\ndef generate(repo_root: Path = REPO_ROOT) -&gt; None:\n    src = repo_root / \"pantsagon\" / \"diagnostics\" / \"codes.yaml\"\n    out = repo_root / \"docs\" / \"reference\" / \"diagnostic-codes.md\"\n\n    if not src.exists():\n        raise SystemExit(f\"Diagnostics source not found: {src}\")\n\n    data = _load_yaml(src)\n    if data.get(\"version\") != 1:\n        raise SystemExit(f\"Unsupported diagnostics version: {data.get('version')}\")\n\n    codes = data.get(\"codes\")\n    if not isinstance(codes, list):\n        raise SystemExit(\"Invalid codes.yaml: expected top-level 'codes' list\")\n\n    lines: list[str] = []\n    lines.append(_render_generated_notice(\"python scripts/generate_diagnostic_codes.py\"))\n    lines.append(\"\")\n    lines.append(\"# Diagnostic codes\")\n    lines.append(\"\")\n    lines.append(\"This page is generated from `pantsagon/diagnostics/codes.yaml`.\")\n    lines.append(\"\")\n    lines.append(\"| Code | Severity | Rule | Message | Hint |\")\n    lines.append(\"|---|---|---|---|---|\")\n\n    for item in sorted(codes, key=lambda x: (x.get(\"code\") or \"\")):\n        code = (item.get(\"code\") or \"\").strip()\n        sev = (item.get(\"severity\") or \"\").strip()\n        rule = (item.get(\"rule\") or \"\").strip()\n        msg = (item.get(\"message\") or \"\").strip().replace(\"\\n\", \" \")\n        hint = (item.get(\"hint\") or \"\").strip().replace(\"\\n\", \" \")\n\n        if not code or not sev or not rule:\n            raise SystemExit(f\"Invalid diagnostic entry (missing required fields): {item}\")\n\n        lines.append(f\"| `{code}` | `{sev}` | `{rule}` | {msg} | {hint} |\")\n\n    out.parent.mkdir(parents=True, exist_ok=True)\n    out.write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"utf-8\")\n    print(f\"Generated {out}\")\n\n\nif __name__ == \"__main__\":\n    generate()\n</code></pre> <p>Step 2: Run tests to verify pass</p> <p>Run: <code>python -m unittest tests/test_generate_diagnostic_codes.py -v</code></p> <p>Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add scripts/generate_diagnostic_codes.py\ngit commit -m \"feat: add diagnostic codes generator\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-7-add-schemas-diagnostics-codes-source","title":"Task 7: Add schemas + diagnostics codes source","text":"<p>Files: - Create: <code>schemas/pack.schema.v1.json</code> - Create: <code>schemas/repo-lock.schema.v1.json</code> - Create: <code>schemas/result.schema.v1.json</code> - Create: <code>pantsagon/diagnostics/codes.yaml</code></p> <p>Step 1: Create <code>schemas/pack.schema.v1.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://pantsagon.dev/schemas/pack.schema.v1.json\",\n  \"title\": \"Pantsagon Pack Manifest (v1)\",\n  \"description\": \"Tool-agnostic manifest describing a Pantsagon pack: identity, compatibility, features, and variables.\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"version\", \"compatibility\"],\n  \"additionalProperties\": false,\n  \"properties\": {\n    \"schema_version\": {\n      \"type\": \"integer\",\n      \"const\": 1,\n      \"description\": \"Schema version for this manifest.\"\n    },\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z0-9_.-]+$\",\n      \"description\": \"Globally unique pack identifier (e.g. pantsagon.python).\"\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\",\n      \"description\": \"SemVer version of the pack.\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"description\": \"Human-readable description of the pack.\"\n    },\n    \"compatibility\": {\n      \"type\": \"object\",\n      \"required\": [\"pants\"],\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"pants\": {\n          \"type\": \"string\",\n          \"description\": \"Supported Pants version range (PEP 440 / semver-style range).\"\n        },\n        \"languages\": {\n          \"type\": \"object\",\n          \"additionalProperties\": {\n            \"type\": \"string\",\n            \"description\": \"Supported version range for a language (e.g. python: \\\"&gt;=3.12,&lt;3.15\\\").\"\n          }\n        }\n      }\n    },\n    \"requires\": {\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"packs\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\",\n            \"pattern\": \"^[a-z0-9_.-]+$\"\n          },\n          \"description\": \"Other packs that must be present for this pack to be applied.\"\n        }\n      }\n    },\n    \"provides\": {\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"features\": {\n          \"type\": \"array\",\n          \"items\": { \"type\": \"string\" },\n          \"description\": \"Feature flags provided by this pack (e.g. openapi, docker).\"\n        },\n        \"service_templates\": {\n          \"type\": \"array\",\n          \"description\": \"Service template capabilities exposed by this pack.\",\n          \"items\": {\n            \"type\": \"object\",\n            \"required\": [\"kind\", \"language\"],\n            \"additionalProperties\": false,\n            \"properties\": {\n              \"kind\": {\n                \"type\": \"string\",\n                \"enum\": [\"service\"],\n                \"description\": \"Template kind.\"\n              },\n              \"language\": {\n                \"type\": \"string\",\n                \"description\": \"Language supported by this template.\"\n              },\n              \"layout\": {\n                \"type\": \"string\",\n                \"description\": \"Declared layout (e.g. hexagonal).\"\n              }\n            }\n          }\n        }\n      }\n    },\n    \"variables\": {\n      \"type\": \"array\",\n      \"description\": \"Variables required or accepted by this pack.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"name\", \"type\"],\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"name\": {\n            \"type\": \"string\",\n            \"pattern\": \"^[a-zA-Z_][a-zA-Z0-9_]*$\",\n            \"description\": \"Variable name.\"\n          },\n          \"type\": {\n            \"type\": \"string\",\n            \"enum\": [\"string\", \"int\", \"bool\", \"enum\"],\n            \"description\": \"Variable type.\"\n          },\n          \"default\": {\n            \"description\": \"Default value if not provided.\"\n          },\n          \"required\": {\n            \"type\": \"boolean\",\n            \"default\": false,\n            \"description\": \"Whether the variable is required.\"\n          },\n          \"enum\": {\n            \"type\": \"array\",\n            \"items\": { \"type\": \"string\" },\n            \"description\": \"Allowed values when type is enum.\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Step 2: Create <code>schemas/repo-lock.schema.v1.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://pantsagon.dev/schemas/repo-lock.schema.v1.json\",\n  \"title\": \"Pantsagon Repo Lock (.pantsagon.toml) (v1)\",\n  \"description\": \"Single source of truth for a Pantsagon-generated repository.\",\n  \"type\": \"object\",\n  \"required\": [\"tool\", \"resolved\"],\n  \"additionalProperties\": false,\n  \"properties\": {\n    \"tool\": {\n      \"type\": \"object\",\n      \"required\": [\"name\", \"version\"],\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"name\": {\n          \"type\": \"string\",\n          \"const\": \"pantsagon\"\n        },\n        \"version\": {\n          \"type\": \"string\",\n          \"description\": \"Pantsagon tool version used to generate or update this repo.\"\n        }\n      }\n    },\n    \"settings\": {\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"renderer\": {\n          \"type\": \"string\",\n          \"default\": \"copier\",\n          \"description\": \"Renderer adapter to use.\"\n        },\n        \"strict\": {\n          \"type\": \"boolean\",\n          \"default\": false,\n          \"description\": \"Whether strict mode is enabled.\"\n        },\n        \"strict_manifest\": {\n          \"type\": \"boolean\",\n          \"default\": true,\n          \"description\": \"Whether manifest/Copier mismatches are fatal.\"\n        },\n        \"allow_hooks\": {\n          \"type\": \"boolean\",\n          \"default\": false,\n          \"description\": \"Whether pack hooks are allowed to execute.\"\n        }\n      }\n    },\n    \"selection\": {\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"languages\": {\n          \"type\": \"array\",\n          \"items\": { \"type\": \"string\" }\n        },\n        \"features\": {\n          \"type\": \"array\",\n          \"items\": { \"type\": \"string\" }\n        },\n        \"services\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\",\n            \"pattern\": \"^[a-z][a-z0-9-]*$\"\n          }\n        }\n      }\n    },\n    \"resolved\": {\n      \"type\": \"object\",\n      \"required\": [\"packs\"],\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"packs\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\",\n            \"required\": [\"id\", \"version\", \"source\"],\n            \"additionalProperties\": false,\n            \"properties\": {\n              \"id\": {\n                \"type\": \"string\"\n              },\n              \"version\": {\n                \"type\": \"string\"\n              },\n              \"source\": {\n                \"type\": \"string\",\n                \"enum\": [\"bundled\", \"local\", \"git\", \"registry\"]\n              },\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"Filesystem path or URL, depending on source.\"\n              },\n              \"ref\": {\n                \"type\": \"string\",\n                \"description\": \"Git ref, commit, or registry digest.\"\n              }\n            }\n          }\n        },\n        \"answers\": {\n          \"type\": \"object\",\n          \"additionalProperties\": true,\n          \"description\": \"Resolved variable answers passed to the renderer.\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Step 3: Create <code>schemas/result.schema.v1.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://pantsagon.dev/schemas/result.schema.v1.json\",\n  \"title\": \"Pantsagon Result (v1)\",\n  \"description\": \"Structured output returned by Pantsagon commands for humans and machines.\",\n  \"type\": \"object\",\n  \"required\": [\"result_schema_version\", \"exit_code\", \"diagnostics\"],\n  \"additionalProperties\": false,\n  \"properties\": {\n    \"result_schema_version\": {\n      \"type\": \"integer\",\n      \"const\": 1,\n      \"description\": \"Schema version for the Result object.\"\n    },\n    \"exit_code\": {\n      \"type\": \"integer\",\n      \"enum\": [0, 2, 3, 4],\n      \"description\": \"Process exit code.\"\n    },\n    \"diagnostics\": {\n      \"type\": \"array\",\n      \"description\": \"Structured diagnostics emitted during execution.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"code\", \"rule\", \"severity\", \"message\"],\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"id\": {\n            \"type\": \"string\",\n            \"description\": \"Stable or deterministic diagnostic identifier.\"\n          },\n          \"code\": {\n            \"type\": \"string\",\n            \"description\": \"Short, stable diagnostic code (e.g. PACK_NOT_FOUND).\"\n          },\n          \"rule\": {\n            \"type\": \"string\",\n            \"description\": \"Rule identifier or namespace (e.g. pack.requires.packs).\"\n          },\n          \"severity\": {\n            \"type\": \"string\",\n            \"enum\": [\"error\", \"warn\", \"info\"]\n          },\n          \"message\": {\n            \"type\": \"string\"\n          },\n          \"location\": {\n            \"type\": \"object\",\n            \"description\": \"Optional structured location of the diagnostic.\",\n            \"additionalProperties\": true\n          },\n          \"hint\": {\n            \"type\": \"string\",\n            \"description\": \"Optional remediation hint.\"\n          },\n          \"details\": {\n            \"type\": \"object\",\n            \"additionalProperties\": true,\n            \"description\": \"Optional machine-readable details.\"\n          }\n        }\n      }\n    },\n    \"artifacts\": {\n      \"type\": \"array\",\n      \"description\": \"Artifacts produced by the command (paths, packs, commands).\",\n      \"items\": {\n        \"type\": \"object\",\n        \"additionalProperties\": true\n      }\n    }\n  }\n}\n</code></pre> <p>Step 4: Create <code>pantsagon/diagnostics/codes.yaml</code></p> <pre><code>version: 1\n\ncodes:\n  - code: PACK_NOT_FOUND\n    severity: error\n    rule: pack.catalog.fetch\n    message: Pack could not be found.\n    hint: Check pack id/version and configured pack sources.\n\n  - code: PACK_MISSING_REQUIRED\n    severity: error\n    rule: pack.requires.packs\n    message: Pack is missing required dependency packs.\n    hint: Add the required pack or choose a compatible feature set.\n\n  - code: COPIER_UNDECLARED_VARIABLE\n    severity: error\n    rule: pack.variables.copier_undeclared\n    message: Copier defines a variable that is not declared in pack.yaml.\n    hint: Declare it in pack.yaml.variables or remove it from copier.yml.\n\n  - code: COPIER_DEFAULT_MISMATCH\n    severity: warn\n    rule: pack.variables.default_mismatch\n    message: Copier default does not match pack.yaml default.\n    hint: Align defaults, or run in strict mode to fail builds.\n</code></pre> <p>Step 5: Commit</p> <pre><code>git add schemas/pack.schema.v1.json \\\n  schemas/repo-lock.schema.v1.json \\\n  schemas/result.schema.v1.json \\\n  pantsagon/diagnostics/codes.yaml\ngit commit -m \"docs: add schema and diagnostics sources\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-8-generate-reference-docs-from-sources","title":"Task 8: Generate reference docs from sources","text":"<p>Files: - Create: <code>docs/reference/pack.schema.v1.md</code> - Create: <code>docs/reference/repo-lock.schema.v1.md</code> - Create: <code>docs/reference/result.schema.v1.md</code> - Create: <code>docs/reference/diagnostic-codes.md</code></p> <p>Step 1: Run generators</p> <pre><code>python scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\n</code></pre> <p>Step 2: Spot-check headers</p> <p>Check each generated file begins with: - \u201cGenerated file. Do not edit directly.\u201d - \u201cRun: <code>python scripts/...</code>\u201d</p> <p>Step 3: Commit</p> <pre><code>git add docs/reference/pack.schema.v1.md \\\n  docs/reference/repo-lock.schema.v1.md \\\n  docs/reference/result.schema.v1.md \\\n  docs/reference/diagnostic-codes.md\ngit commit -m \"docs: generate reference docs\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-9-add-docs-github-actions-workflow","title":"Task 9: Add docs GitHub Actions workflow","text":"<p>Files: - Create: <code>.github/workflows/docs.yml</code></p> <p>Step 1: Create <code>.github/workflows/docs.yml</code></p> <pre><code>name: Docs\n\non:\n  pull_request:\n    paths:\n      - \"docs/**\"\n      - \"mkdocs.yml\"\n      - \".github/workflows/docs.yml\"\n      - \"schemas/**\"\n      - \"scripts/**\"\n      - \"pantsagon/diagnostics/codes.yaml\"\n  push:\n    branches: [\"main\"]\n    tags: [\"v*.*.*\"]\n    paths:\n      - \"docs/**\"\n      - \"mkdocs.yml\"\n      - \".github/workflows/docs.yml\"\n      - \"schemas/**\"\n      - \"scripts/**\"\n      - \"pantsagon/diagnostics/codes.yaml\"\n  workflow_dispatch: {}\n\npermissions:\n  contents: write\n  pull-requests: write\n\nconcurrency:\n  group: docs-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  docs:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n\n      - name: Install docs dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r docs/requirements.txt\n\n      - name: Install generator dependencies\n        run: |\n          pip install pyyaml\n\n      - name: Generate reference docs (schemas + diagnostic codes)\n        run: |\n          python scripts/generate_schema_docs.py\n          python scripts/generate_diagnostic_codes.py\n\n      - name: Fail if generated docs are out of date\n        run: |\n          git diff --exit-code\n\n      - name: Build (strict)\n        run: |\n          mkdocs build --strict\n\n      - name: Configure git identity\n        run: |\n          git config user.name \"github-actions[bot]\"\n          git config user.email \"github-actions[bot]@users.noreply.github.com\"\n\n      - name: Publish PR preview\n        if: github.event_name == 'pull_request'\n        env:\n          PR_NUM: ${{ github.event.number }}\n        run: |\n          mike deploy --push --branch gh-pages \"pr-${PR_NUM}\"\n\n      - name: Comment PR preview URL\n        if: github.event_name == 'pull_request'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const pr = context.payload.pull_request.number;\n            const owner = context.repo.owner;\n            const repo = context.repo.repo;\n            const url = `https://${owner}.github.io/${repo}/pr-${pr}/`;\n            const body = [\n              \"Docs preview published:\",\n              \"\",\n              url\n            ].join(\"\\n\");\n            await github.rest.issues.createComment({\n              owner,\n              repo,\n              issue_number: pr,\n              body\n            });\n\n      - name: Publish dev docs (main)\n        if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n        run: |\n          mike deploy --push --branch gh-pages \"dev\"\n\n      - name: Publish release docs (tag) + update latest\n        if: github.event_name == 'push' &amp;&amp; startsWith(github.ref, 'refs/tags/v')\n        env:\n          TAG: ${{ github.ref_name }}\n        run: |\n          mike deploy --push --branch gh-pages --update-aliases \"${TAG}\" latest\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add .github/workflows/docs.yml\ngit commit -m \"ci: add docs build and publish workflow\"\n</code></pre>"},{"location":"plans/2026-01-10-docs-system/#task-10-verification","title":"Task 10: Verification","text":"<p>Step 1: Run generators locally</p> <pre><code>python scripts/generate_schema_docs.py\npython scripts/generate_diagnostic_codes.py\n</code></pre> <p>Step 2: Build docs locally</p> <pre><code>mkdocs build --strict\n</code></pre> <p>Expected: <code>build</code> succeeds with no warnings or missing files.</p>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/","title":"M3 Repo Lock Fidelity Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement repo lock fidelity v1: <code>.pantsagon.toml</code> full structure, pack index mapping, resolved pack/answer persistence, drift validation, and README updates.</p> <p>Architecture: Add a pack index file (<code>packs/_index.json</code>) and a small application utility module to load/resolve packs. Centralize lock read/write/validation in <code>application/repo_lock.py</code>. <code>init_repo</code> computes pack refs + answers, writes lock into a staging workspace, renders, then commits. <code>validate_repo</code> is resolved-driven: it reads the lock, validates pack refs/availability/requirements, checks repo invariants, and emits drift diagnostics.</p> <p>Tech Stack: Python 3.12, tomllib/tomli-w, json, PyYAML, jsonschema, pytest.</p>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-1-add-pack-index-loader-resolution-tests-tdd","title":"Task 1: Add pack index loader + resolution tests (TDD)","text":"<p>Files: - Create: <code>tests/application/test_pack_index.py</code> - Create: <code>services/pantsagon/src/pantsagon/application/pack_index.py</code> - Create: <code>packs/_index.json</code></p> <p>Step 1: Write failing tests</p> <pre><code>import json\nfrom pathlib import Path\n\nfrom pantsagon.application.pack_index import load_pack_index, resolve_pack_ids\n\n\ndef test_resolve_pack_ids_from_index(tmp_path):\n    index_path = tmp_path / \"_index.json\"\n    index_path.write_text(\n        json.dumps(\n            {\n                \"schema_version\": 1,\n                \"base_packs\": [\"pantsagon.core\"],\n                \"languages\": {\"python\": [\"pantsagon.python\"]},\n                \"features\": {\"openapi\": [\"pantsagon.openapi\"], \"docker\": [\"pantsagon.docker\"]},\n            }\n        ),\n        encoding=\"utf-8\",\n    )\n    index = load_pack_index(index_path)\n    result = resolve_pack_ids(index, languages=[\"python\"], features=[\"openapi\", \"docker\"])\n    assert result.diagnostics == []\n    assert result.value == [\n        \"pantsagon.core\",\n        \"pantsagon.python\",\n        \"pantsagon.openapi\",\n        \"pantsagon.docker\",\n    ]\n\n\ndef test_resolve_pack_ids_unknown_language(tmp_path):\n    index_path = tmp_path / \"_index.json\"\n    index_path.write_text(\n        json.dumps({\"schema_version\": 1, \"base_packs\": [\"pantsagon.core\"], \"languages\": {}, \"features\": {}}),\n        encoding=\"utf-8\",\n    )\n    index = load_pack_index(index_path)\n    result = resolve_pack_ids(index, languages=[\"elixir\"], features=[])\n    assert any(d.code == \"PACK_INDEX_UNKNOWN_LANGUAGE\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify failure</p> <p>Run: <code>pytest tests/application/test_pack_index.py -q</code></p> <p>Expected: FAIL with <code>ModuleNotFoundError</code> for <code>pantsagon.application.pack_index</code>.</p> <p>Step 3: Commit</p> <pre><code>git add tests/application/test_pack_index.py\ngit commit -m \"test: add pack index resolution tests\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-2-implement-pack-index-loader-resolution","title":"Task 2: Implement pack index loader + resolution","text":"<p>Files: - Create: <code>services/pantsagon/src/pantsagon/application/pack_index.py</code> - Create: <code>packs/_index.json</code></p> <p>Step 1: Implement <code>pack_index.py</code></p> <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass\nimport json\nfrom pathlib import Path\nfrom typing import Any\n\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\nfrom pantsagon.domain.result import Result\n\n\n@dataclass(frozen=True)\nclass PackIndex:\n    base_packs: list[str]\n    languages: dict[str, list[str]]\n    features: dict[str, list[str]]\n\n\ndef load_pack_index(path: Path) -&gt; PackIndex:\n    raw = json.loads(path.read_text(encoding=\"utf-8\"))\n    base = list(raw.get(\"base_packs\") or [])\n    languages = dict(raw.get(\"languages\") or {})\n    features = dict(raw.get(\"features\") or {})\n    return PackIndex(base_packs=base, languages=languages, features=features)\n\n\ndef resolve_pack_ids(index: PackIndex, languages: list[str], features: list[str]) -&gt; Result[list[str]]:\n    diagnostics: list[Diagnostic] = []\n    packs: list[str] = []\n    packs.extend(index.base_packs)\n\n    for lang in languages:\n        if lang not in index.languages:\n            diagnostics.append(\n                Diagnostic(\n                    code=\"PACK_INDEX_UNKNOWN_LANGUAGE\",\n                    rule=\"pack.index.language\",\n                    severity=Severity.ERROR,\n                    message=f\"Unknown language in pack index: {lang}\",\n                )\n            )\n            continue\n        packs.extend(index.languages[lang])\n\n    for feature in features:\n        if feature not in index.features:\n            diagnostics.append(\n                Diagnostic(\n                    code=\"PACK_INDEX_UNKNOWN_FEATURE\",\n                    rule=\"pack.index.feature\",\n                    severity=Severity.ERROR,\n                    message=f\"Unknown feature in pack index: {feature}\",\n                )\n            )\n            continue\n        packs.extend(index.features[feature])\n\n    seen: set[str] = set()\n    ordered: list[str] = []\n    for pack_id in packs:\n        if pack_id not in seen:\n            seen.add(pack_id)\n            ordered.append(pack_id)\n\n    return Result(value=ordered, diagnostics=diagnostics)\n</code></pre> <p>Step 2: Create <code>packs/_index.json</code></p> <pre><code>{\n  \"schema_version\": 1,\n  \"base_packs\": [\"pantsagon.core\"],\n  \"languages\": {\n    \"python\": [\"pantsagon.python\"]\n  },\n  \"features\": {\n    \"openapi\": [\"pantsagon.openapi\"],\n    \"docker\": [\"pantsagon.docker\"]\n  }\n}\n</code></pre> <p>Step 3: Run tests</p> <p>Run: <code>pytest tests/application/test_pack_index.py -q</code></p> <p>Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add services/pantsagon/src/pantsagon/application/pack_index.py packs/_index.json\ngit commit -m \"feat: add pack index mapping\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-3-add-repo-lock-readwrite-tests-tdd","title":"Task 3: Add repo lock read/write tests (TDD)","text":"<p>Files: - Create: <code>tests/application/test_repo_lock.py</code> - Create: <code>services/pantsagon/src/pantsagon/application/repo_lock.py</code></p> <p>Step 1: Write failing tests</p> <pre><code>import tomllib\nfrom pathlib import Path\n\nfrom pantsagon.application.repo_lock import read_lock, write_lock\n\n\ndef test_read_lock_missing(tmp_path):\n    result = read_lock(tmp_path / \".pantsagon.toml\")\n    assert any(d.code == \"LOCK_MISSING\" for d in result.diagnostics)\n\n\ndef test_write_lock_roundtrip(tmp_path):\n    lock = {\n        \"tool\": {\"name\": \"pantsagon\", \"version\": \"0.1.0\"},\n        \"settings\": {\"renderer\": \"copier\", \"strict\": False, \"strict_manifest\": True, \"allow_hooks\": False},\n        \"selection\": {\"languages\": [\"python\"], \"features\": [\"openapi\"], \"services\": [\"svc\"], \"augmented_coding\": \"none\"},\n        \"resolved\": {\"packs\": [{\"id\": \"pantsagon.core\", \"version\": \"1.0.0\", \"source\": \"bundled\"}], \"answers\": {\"repo_name\": \"demo\"}},\n    }\n    path = tmp_path / \".pantsagon.toml\"\n    write_lock(path, lock)\n    parsed = tomllib.loads(path.read_text(encoding=\"utf-8\"))\n    assert parsed[\"tool\"][\"name\"] == \"pantsagon\"\n    assert parsed[\"resolved\"][\"packs\"][0][\"id\"] == \"pantsagon.core\"\n</code></pre> <p>Step 2: Run tests to verify failure</p> <p>Run: <code>pytest tests/application/test_repo_lock.py -q</code></p> <p>Expected: FAIL with import error or missing functions.</p> <p>Step 3: Commit</p> <pre><code>git add tests/application/test_repo_lock.py\ngit commit -m \"test: add repo lock io tests\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-4-implement-repo-lock-readwrite-pack-ordering","title":"Task 4: Implement repo lock read/write + pack ordering","text":"<p>Files: - Create: <code>services/pantsagon/src/pantsagon/application/repo_lock.py</code></p> <p>Step 1: Implement lock helpers</p> <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport tomllib\nfrom typing import Any\n\nfrom pantsagon.domain.diagnostics import Diagnostic, FileLocation, Severity\nfrom pantsagon.domain.result import Result\n\n\nLockDict = dict[str, Any]\n\n\ndef read_lock(path: Path) -&gt; Result[LockDict]:\n    if not path.exists():\n        return Result(diagnostics=[Diagnostic(code=\"LOCK_MISSING\", rule=\"lock.exists\", severity=Severity.ERROR, message=\".pantsagon.toml not found\")])\n    try:\n        data = tomllib.loads(path.read_text(encoding=\"utf-8\"))\n    except Exception as e:\n        return Result(\n            diagnostics=[\n                Diagnostic(\n                    code=\"LOCK_PARSE_FAILED\",\n                    rule=\"lock.parse\",\n                    severity=Severity.ERROR,\n                    message=str(e),\n                    location=FileLocation(str(path)),\n                )\n            ]\n        )\n    return Result(value=data)\n\n\ndef write_lock(path: Path, lock: LockDict) -&gt; None:\n    import tomli_w\n\n    content = tomli_w.dumps(lock)\n    path.write_text(content, encoding=\"utf-8\")\n</code></pre> <p>Step 2: Run tests</p> <p>Run: <code>pytest tests/application/test_repo_lock.py -q</code></p> <p>Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add services/pantsagon/src/pantsagon/application/repo_lock.py\ngit commit -m \"feat: add repo lock io helpers\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-5-add-init_repo-lock-fidelity-tests-tdd","title":"Task 5: Add init_repo lock fidelity tests (TDD)","text":"<p>Files: - Create: <code>tests/application/test_init_repo_lock.py</code> - Modify: <code>services/pantsagon/src/pantsagon/application/init_repo.py</code></p> <p>Step 1: Write failing test</p> <pre><code>import tomllib\nfrom pantsagon.application.init_repo import init_repo\n\n\ndef test_init_repo_writes_full_lock(tmp_path):\n    init_repo(\n        repo_path=tmp_path,\n        languages=[\"python\"],\n        services=[\"monitors\"],\n        features=[\"openapi\"],\n        renderer=\"copier\",\n    )\n    lock = tomllib.loads((tmp_path / \".pantsagon.toml\").read_text(encoding=\"utf-8\"))\n    assert \"tool\" in lock\n    assert \"settings\" in lock\n    assert \"selection\" in lock\n    assert \"resolved\" in lock\n    assert lock[\"resolved\"][\"packs\"]\n    assert \"answers\" in lock[\"resolved\"]\n</code></pre> <p>Step 2: Run test to verify failure</p> <p>Run: <code>pytest tests/application/test_init_repo_lock.py -q</code></p> <p>Expected: FAIL because init_repo writes minimal lock.</p> <p>Step 3: Commit</p> <pre><code>git add tests/application/test_init_repo_lock.py\ngit commit -m \"test: add init repo lock structure test\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-6-implement-init_repo-lock-fidelity-staging","title":"Task 6: Implement init_repo lock fidelity + staging","text":"<p>Files: - Modify: <code>services/pantsagon/src/pantsagon/application/init_repo.py</code> - Modify: <code>services/pantsagon/src/pantsagon/adapters/workspace/filesystem.py</code> (if needed) - Modify: <code>services/pantsagon/src/pantsagon/application/pack_index.py</code> - Modify: <code>services/pantsagon/src/pantsagon/adapters/pack_catalog/bundled.py</code></p> <p>Step 1: Implement staging flow</p> <ul> <li>Create <code>FilesystemWorkspace(repo_path)</code></li> <li><code>stage = workspace.begin_transaction()</code></li> <li>Write <code>.pantsagon.toml</code> into <code>stage</code> (using <code>write_lock</code>)</li> <li>Write minimal <code>pants.toml</code> into <code>stage</code></li> <li>Render packs into <code>stage</code> if available (optional for v1)</li> <li>Commit stage via <code>workspace.commit(stage)</code></li> </ul> <p>Step 2: Resolve packs and answers</p> <ul> <li>Load pack index from <code>packs/_index.json</code></li> <li>Resolve pack IDs from selection</li> <li>Load each pack manifest to get version and requires</li> <li>Build <code>resolved.packs</code> with <code>id/version/source</code> (source = bundled)</li> <li>Persist <code>resolved.answers</code> = <code>{repo_name, service_name}</code></li> <li>Ensure deterministic ordering via topological sort on <code>requires.packs</code> then id</li> </ul> <p>Step 3: Update init_repo implementation</p> <ul> <li>Use <code>write_lock</code> to serialize full lock dict</li> <li>Return Result with diagnostics if resolution fails</li> </ul> <p>Step 4: Run test</p> <p>Run: <code>pytest tests/application/test_init_repo_lock.py -q</code></p> <p>Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add services/pantsagon/src/pantsagon/application/init_repo.py\ngit commit -m \"feat: write full repo lock during init\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-7-add-validate_repo-drift-tests-tdd","title":"Task 7: Add validate_repo drift tests (TDD)","text":"<p>Files: - Create: <code>tests/application/test_validate_repo.py</code></p> <p>Step 1: Write failing tests</p> <pre><code>import tomllib\nfrom pathlib import Path\n\nfrom pantsagon.application.init_repo import init_repo\nfrom pantsagon.application.validate_repo import validate_repo\n\n\ndef test_validate_repo_missing_lock(tmp_path):\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"LOCK_MISSING\" for d in result.diagnostics)\n\n\ndef test_validate_repo_missing_service_dir(tmp_path):\n    init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"missing\"], features=[], renderer=\"copier\")\n    # Remove service dir if created\n    svc_dir = tmp_path / \"services\" / \"missing\"\n    if svc_dir.exists():\n        for p in svc_dir.rglob(\"*\"):\n            if p.is_file():\n                p.unlink()\n        svc_dir.rmdir()\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"REPO_SERVICE_MISSING\" for d in result.diagnostics)\n\n\ndef test_validate_repo_pack_not_found(tmp_path):\n    init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"svc\"], features=[], renderer=\"copier\")\n    lock_path = tmp_path / \".pantsagon.toml\"\n    lock = tomllib.loads(lock_path.read_text(encoding=\"utf-8\"))\n    lock[\"resolved\"][\"packs\"][0][\"id\"] = \"pantsagon.missing\"\n    lock_path.write_text(\"\".join([\"[tool]\\nname=\\\"pantsagon\\\"\\nversion=\\\"0.1.0\\\"\\n\"]))\n    # overwrite with tampered lock for simplicity in test\n    import tomli_w\n    lock_path.write_text(tomli_w.dumps(lock), encoding=\"utf-8\")\n\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"PACK_NOT_FOUND\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify failure</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code></p> <p>Expected: FAIL because validate_repo is stub.</p> <p>Step 3: Commit</p> <pre><code>git add tests/application/test_validate_repo.py\ngit commit -m \"test: add validate repo drift tests\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-8-implement-validate_repo-structural-drift-b","title":"Task 8: Implement validate_repo structural drift (B)","text":"<p>Files: - Modify: <code>services/pantsagon/src/pantsagon/application/validate_repo.py</code> - Modify: <code>services/pantsagon/src/pantsagon/application/repo_lock.py</code> - Modify: <code>services/pantsagon/src/pantsagon/application/pack_index.py</code></p> <p>Step 1: Implement <code>validate_repo</code></p> <ul> <li>Use <code>read_lock</code> to parse lock</li> <li>Validate presence of <code>tool</code> and <code>resolved.packs</code> (emit <code>LOCK_SECTION_MISSING</code>)</li> <li>Validate resolved pack list integrity (unique ids, required fields)</li> <li>For each pack ref:</li> <li>resolve pack path (bundled =&gt; <code>packs/&lt;name&gt;</code>; local =&gt; <code>location</code>)</li> <li>if missing, emit <code>PACK_NOT_FOUND</code></li> <li>load manifest and validate with <code>PackPolicyEngine</code></li> <li>check <code>requires.packs</code> satisfied by resolved set</li> <li>Check service directories for each <code>selection.services</code> if present</li> <li>If <code>pantsagon.python</code> in resolved packs, ensure service layer dirs exist</li> <li>If selection is present, ensure selection languages/features are compatible with resolved packs (mapping in index)</li> </ul> <p>Step 2: Run tests</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code></p> <p>Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add services/pantsagon/src/pantsagon/application/validate_repo.py services/pantsagon/src/pantsagon/application/repo_lock.py\ngit commit -m \"feat: validate repo lock drift\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-9-update-diagnostics-codes-regenerate-docs-if-needed","title":"Task 9: Update diagnostics codes + regenerate docs (if needed)","text":"<p>Files: - Modify: <code>pantsagon/diagnostics/codes.yaml</code> - Modify: <code>docs/reference/diagnostic-codes.md</code> (generated)</p> <p>Step 1: Add codes</p> <p>Add entries for: - <code>LOCK_MISSING</code>, <code>LOCK_PARSE_FAILED</code>, <code>LOCK_SECTION_MISSING</code> - <code>PACK_INDEX_UNKNOWN_LANGUAGE</code>, <code>PACK_INDEX_UNKNOWN_FEATURE</code> - <code>REPO_SERVICE_MISSING</code>, <code>REPO_LAYER_MISSING</code></p> <p>Step 2: Regenerate docs</p> <p>Run: <pre><code>python scripts/generate_diagnostic_codes.py\n</code></pre></p> <p>Step 3: Commit</p> <pre><code>git add pantsagon/diagnostics/codes.yaml docs/reference/diagnostic-codes.md\ngit commit -m \"docs: add lock drift diagnostics\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-10-update-readme-with-lock-structure","title":"Task 10: Update README with lock structure","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Add <code>.pantsagon.toml</code> structure example</p> <p>Include snippet:</p> <pre><code>[tool]\nname = \"pantsagon\"\nversion = \"0.1.0\"\n\n[settings]\nrenderer = \"copier\"\nstrict = false\nstrict_manifest = true\nallow_hooks = false\n\n[selection]\nlanguages = [\"python\"]\nfeatures = [\"openapi\", \"docker\"]\nservices = [\"monitors\", \"governance\"]\naugmented_coding = \"none\"\n\n[[resolved.packs]]\nid = \"pantsagon.core\"\nversion = \"1.0.0\"\nsource = \"bundled\"\n\n[resolved.answers]\nrepo_name = \"my-repo\"\nservice_name = \"monitors\"\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add README.md\ngit commit -m \"docs: document repo lock structure\"\n</code></pre>"},{"location":"plans/2026-01-10-m3-repo-lock-fidelity/#task-11-verification","title":"Task 11: Verification","text":"<p>Run:</p> <pre><code>pytest -q\n</code></pre> <p>Expected: All tests pass.</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/","title":"M4 Real Pack Content Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement real bundled pack content (core/python/openapi/docker), add pack smoke tests, and update README with an example tree.</p> <p>Architecture: Keep packs tool-agnostic and minimal while aligning with the hexagonal monorepo design. Core provides repo skeleton and CI, python provides service hex layers and BUILD rules, openapi provides contract scaffolding, docker provides runnable packaging and Dockerfile. Tests verify schema, copier cross-check, and render smoke.</p> <p>Tech Stack: Python, Copier templates, Pants build metadata, Pytest.</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-1-add-bundled-pack-render-smoke-tests-red","title":"Task 1: Add bundled pack render smoke tests (RED)","text":"<p>Files: - Create: <code>tests/packs/test_bundled_pack_smoke.py</code></p> <p>Step 1: Write the failing test</p> <pre><code>import importlib.util\nfrom pathlib import Path\n\nimport pytest\n\nfrom pantsagon.adapters.renderer.copier_renderer import CopierRenderer\nfrom pantsagon.domain.pack import PackRef\nfrom pantsagon.ports.renderer import RenderRequest\n\npytestmark = pytest.mark.skipif(\n    importlib.util.find_spec(\"copier\") is None,\n    reason=\"copier not installed\",\n)\n\n\ndef _render(pack_dir: Path, out: Path, answers: dict) -&gt; None:\n    req = RenderRequest(\n        pack=PackRef(id=\"x\", version=\"1.0.0\", source=\"bundled\"),\n        pack_path=pack_dir,\n        staging_dir=out,\n        answers=answers,\n        allow_hooks=False,\n    )\n    CopierRenderer().render(req)\n\n\ndef test_core_pack_renders_minimum_skeleton(tmp_path):\n    pack = Path(\"packs/core\")\n    out = tmp_path / \"core\"\n    out.mkdir()\n    _render(pack, out, {\"repo_name\": \"acme\"})\n    assert (out / \"pants.toml\").exists()\n    assert (out / \".github\" / \"workflows\" / \"ci.yml\").exists()\n    assert (out / \"shared\" / \"foundation\" / \"README.md\").exists()\n    assert (out / \"docs\" / \"README.md\").exists()\n\n\ndef test_python_pack_renders_hex_layers_with_snake_pkg(tmp_path):\n    pack = Path(\"packs/python\")\n    out = tmp_path / \"python\"\n    out.mkdir()\n    _render(pack, out, {\"service_name\": \"monitor-cost\", \"service_pkg\": \"monitor_cost\"})\n    base = out / \"services\" / \"monitor-cost\" / \"src\" / \"monitor_cost\"\n    assert (base / \"domain\" / \"__init__.py\").exists()\n    assert (base / \"entrypoints\" / \"BUILD\").exists()\n\n\ndef test_openapi_pack_renders_contracts(tmp_path):\n    pack = Path(\"packs/openapi\")\n    out = tmp_path / \"openapi\"\n    out.mkdir()\n    _render(pack, out, {\"service_name\": \"monitor-cost\"})\n    assert (out / \"shared\" / \"contracts\" / \"openapi\" / \"monitor-cost.yaml\").exists()\n    assert (out / \"shared\" / \"contracts\" / \"openapi\" / \"BUILD\").exists()\n\n\ndef test_docker_pack_renders_dockerfile_and_pex(tmp_path):\n    pack = Path(\"packs/docker\")\n    out = tmp_path / \"docker\"\n    out.mkdir()\n    _render(pack, out, {\"service_name\": \"monitor-cost\", \"service_pkg\": \"monitor_cost\"})\n    assert (out / \"services\" / \"monitor-cost\" / \"Dockerfile\").exists()\n    assert (out / \"services\" / \"monitor-cost\" / \"BUILD\").exists()\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/packs/test_bundled_pack_smoke.py -q</code> Expected: FAIL (missing templates/content)</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-2-fix-pack-manifests-schema-cross-check","title":"Task 2: Fix pack manifests (schema + cross-check)","text":"<p>Files: - Modify: <code>packs/core/pack.yaml</code> - Modify: <code>packs/python/pack.yaml</code> - Modify: <code>packs/openapi/pack.yaml</code> - Modify: <code>packs/docker/pack.yaml</code> - Modify: <code>packs/python/copier.yml</code> - Modify: <code>packs/docker/copier.yml</code></p> <p>Step 1: Confirm failing validation</p> <p>Run: <code>pytest tests/packs/test_bundled_packs.py -q</code> Expected: FAIL (missing compatibility)</p> <p>Step 2: Update manifests to satisfy schema</p> <p>Example (core): <pre><code>schema_version: 1\nid: pantsagon.core\nversion: 1.0.0\ndescription: Core monorepo skeleton\ncompatibility:\n  pants: \"&gt;=2.30.0,&lt;2.31\"\nvariables:\n  - name: repo_name\n    type: string\n</code></pre></p> <p>Update other packs similarly with <code>compatibility.pants</code>, and add: - <code>requires.packs</code> for python/openapi/docker - <code>provides.features</code> for openapi/docker - <code>variables</code> for <code>service_name</code> (and <code>service_pkg</code> for python/docker)</p> <p>Step 3: Run validation test</p> <p>Run: <code>pytest tests/packs/test_bundled_packs.py -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-3-core-pack-templates-repo-skeleton-ci","title":"Task 3: Core pack templates (repo skeleton + CI)","text":"<p>Files: - Modify: <code>packs/core/templates/README.md.jinja</code> - Modify: <code>packs/core/templates/pants.toml.jinja</code> - Create: <code>packs/core/templates/.gitignore.jinja</code> - Create: <code>packs/core/templates/.github/workflows/ci.yml.jinja</code> - Create: <code>packs/core/templates/docs/README.md.jinja</code> - Create: <code>packs/core/templates/shared/foundation/README.md.jinja</code> - Create: <code>packs/core/templates/shared/adapters/README.md.jinja</code> - Create: <code>packs/core/templates/shared/contracts/README.md.jinja</code> - Create: <code>packs/core/templates/tools/forbidden_imports/README.md.jinja</code> - Create: <code>packs/core/templates/3rdparty/python/requirements.txt.jinja</code> - Create: <code>packs/core/templates/3rdparty/python/BUILD.jinja</code></p> <p>Step 1: Implement minimal, deterministic repo skeleton</p> <ul> <li><code>pants.toml</code>: include <code>pants_version</code> and minimal <code>backend_packages</code> (python, resources, docker)</li> <li><code>README.md</code>: mention <code>.pantsagon.toml</code> as source of truth and show top-level layout</li> <li><code>ci.yml</code>: install Pants only and run <code>pants lint ::</code>, <code>pants check ::</code>, <code>pants test ::</code></li> <li><code>.gitignore</code>: include <code>.pants.d/</code>, caches, <code>dist/</code>, <code>.env</code></li> </ul> <p>Step 2: Run smoke tests</p> <p>Run: <code>pytest tests/packs/test_bundled_pack_smoke.py::test_core_pack_renders_minimum_skeleton -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-4-python-pack-templates-hex-layers-build-rules","title":"Task 4: Python pack templates (hex layers + BUILD rules)","text":"<p>Files: - Modify: <code>packs/python/templates/README.md.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/README.md.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/domain/__init__.py.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/ports/__init__.py.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/application/__init__.py.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/adapters/__init__.py.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/entrypoints/__init__.py.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/domain/BUILD.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/ports/BUILD.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/application/BUILD.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/adapters/BUILD.jinja</code> - Create: <code>packs/python/templates/services/{{ service_name }}/src/{{ service_pkg }}/entrypoints/BUILD.jinja</code></p> <p>Step 1: Implement hex layer packages and BUILD rules</p> <ul> <li>Use <code>service_name</code> for directory and <code>service_pkg</code> (snake_case) for package path</li> <li>Add <code>__dependents_rules__</code> restricting dependents to <code>svc:{{ service_name }}</code></li> <li>Entry points target restricts dependents to tag <code>entrypoint-consumer</code></li> <li>Dependencies follow hex direction (domain -&gt; foundation; ports -&gt; domain; etc.)</li> </ul> <p>Step 2: Run smoke test</p> <p>Run: <code>pytest tests/packs/test_bundled_pack_smoke.py::test_python_pack_renders_hex_layers_with_snake_pkg -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-5-openapi-pack-templates-contracts-resources-target","title":"Task 5: OpenAPI pack templates (contracts + resources target)","text":"<p>Files: - Modify: <code>packs/openapi/templates/README.md.jinja</code> - Create: <code>packs/openapi/templates/shared/contracts/openapi/README.md.jinja</code> - Create: <code>packs/openapi/templates/shared/contracts/openapi/{{ service_name }}.yaml.jinja</code> - Create: <code>packs/openapi/templates/shared/contracts/openapi/BUILD.jinja</code></p> <p>Step 1: Implement contract scaffolding</p> <ul> <li><code>/health</code> placeholder in spec with note it is disposable</li> <li><code>resources(name=\"openapi_specs\", sources=[\"*.yaml\"])</code></li> <li>README notes multiple specs per service and future backend upgrade</li> </ul> <p>Step 2: Run smoke test</p> <p>Run: <code>pytest tests/packs/test_bundled_pack_smoke.py::test_openapi_pack_renders_contracts -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-6-docker-pack-templates-dockerfile-docker_image-target","title":"Task 6: Docker pack templates (Dockerfile + docker_image target)","text":"<p>Files: - Modify: <code>packs/docker/templates/README.md.jinja</code> - Create: <code>packs/docker/templates/services/{{ service_name }}/entrypoints/main.py.jinja</code> - Create: <code>packs/docker/templates/services/{{ service_name }}/Dockerfile.jinja</code> - Create: <code>packs/docker/templates/services/{{ service_name }}/BUILD.jinja</code></p> <p>Step 1: Implement runnable packaging</p> <ul> <li><code>entrypoints/main.py</code> placeholder with clear comment</li> <li><code>pex_binary(name=\"app\", entry_point=\"{{ service_pkg }}.entrypoints.main:main\", output_path=\"dist/app.pex\", tags=[\"entrypoint-consumer\", \"svc:{{ service_name }}\"])</code></li> <li><code>docker_image(name=\"image\", image_tags=[], dependencies=[\":app\"], dockerfile=\"Dockerfile\")</code></li> <li>Dockerfile uses <code>WORKDIR /app</code>, copies <code>dist/app.pex</code>, chmod +x, and <code>ENTRYPOINT [\"/app/app.pex\"]</code></li> </ul> <p>Step 2: Run smoke test</p> <p>Run: <code>pytest tests/packs/test_bundled_pack_smoke.py::test_docker_pack_renders_dockerfile_and_pex -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-7-persist-service-package-mapping-in-pantsagontoml","title":"Task 7: Persist service package mapping in .pantsagon.toml","text":"<p>Files: - Modify: <code>pantsagon/application/init_repo.py</code> - Modify: <code>pantsagon/application/rendering.py</code> - Modify: <code>tests/application/test_init_repo.py</code></p> <p>Step 1: Write failing test</p> <pre><code>import tomllib\n\n\ndef test_init_repo_records_service_package(tmp_path):\n    result = init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"monitor-cost\"], features=[\"openapi\"], renderer=\"copier\")\n    data = tomllib.loads((tmp_path / \".pantsagon.toml\").read_text())\n    assert data[\"resolved\"][\"answers\"][\"service_packages\"][\"monitor-cost\"] == \"monitor_cost\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/application/test_init_repo.py::test_init_repo_records_service_package -q</code> Expected: FAIL (missing mapping)</p> <p>Step 3: Implement mapping and pass through render answers</p> <ul> <li>Compute <code>service_packages = {name: name.replace('-', '_') for name in services}</code> in <code>init_repo</code></li> <li>Store under <code>lock[\"resolved\"][\"answers\"][\"service_packages\"]</code></li> <li>Pass <code>service_pkg</code> (first service) into <code>render_bundled_packs</code> answers for template use</li> </ul> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/application/test_init_repo.py::test_init_repo_records_service_package -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-8-update-root-readme-with-example-tree","title":"Task 8: Update root README with example tree","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Add example tree section</p> <ul> <li>Include a compact tree showing <code>services/&lt;svc&gt;/src/&lt;pkg&gt;/...</code>, <code>shared/</code>, <code>docs/</code>, and <code>tools/</code></li> </ul> <p>Step 2: Run docs test</p> <p>Run: <code>pytest tests/docs/test_readme_init_rendering.py -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m4-real-pack-content/#task-9-full-verification","title":"Task 9: Full verification","text":"<p>Step 1: Run pack tests</p> <p>Run: <code>pytest tests/packs/test_bundled_packs.py tests/packs/test_bundled_pack_smoke.py -q</code> Expected: PASS (skips smoke if copier missing)</p> <p>Step 2: Run full suite</p> <p>Run: <code>pytest -q</code> Expected: PASS</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness-design/","title":"M6 CI + Release Readiness Design","text":"<p>Goal: Add deterministic CI validation for packs and tests, plus release readiness docs for v1.0.0.</p> <p>Architecture: Introduce a standalone module entry point <code>python -m pantsagon.tools.validate_packs</code> that validates bundled packs and optionally renders them. Keep the module independent of the Typer CLI. CI will call tests and pack validation as distinct steps.</p> <p>Tech Stack: Python 3.12, argparse, existing <code>validate_pack</code> logic, Copier renderer.</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness-design/#pack-validation-command-behavior","title":"Pack validation command behavior","text":"<p><code>pantsagon.tools.validate_packs</code> provides a focused, deterministic validation path for bundled packs. It enumerates packs under <code>packs/</code> by scanning subdirectories that contain both <code>pack.yaml</code> and <code>copier.yml</code> (missing file(s) produce a validation diagnostic pointing at the missing path). Validation is per pack and continues even when one pack fails. For each pack it runs <code>validate_pack()</code> to perform schema checks and manifest vs Copier variable cross checks. If any error diagnostics exist, the pack is marked failed and render is skipped by default. Flags control render behavior: <code>--no-render</code> forces validation-only, <code>--render-on-validation-error</code> attempts render even after validation failures. <code>--no-render</code> and <code>--render-on-validation-error</code> are mutually exclusive (or <code>--no-render</code> wins if both are provided). Render uses <code>CopierRenderer</code> with <code>allow_hooks=False</code> into a temp directory. Smoke answers use defaults from the manifest when present; otherwise type-based placeholders are used, with name-aware safe defaults for common variables (for example <code>service_name=example-service</code>, <code>repo_name=example-repo</code>, <code>service_pkg=example_service</code>). Render failures produce a Diagnostic with <code>code=PACK_RENDER_FAILED</code>, <code>rule=pack.render</code>, and <code>is_execution=True</code> for exit code precedence.</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness-design/#output-determinism-and-exit-codes","title":"Output, determinism, and exit codes","text":"<p>The tool prints a human summary to stdout and supports <code>--json</code> for structured results. JSON output aligns with the Result schema shape: <code>exit_code</code>, <code>diagnostics</code>, and <code>artifacts</code>. Artifacts include per-pack entries with <code>pack_id</code>, <code>pack_version</code>, <code>source</code>, <code>status</code>, <code>render_skipped</code>, and per-pack diagnostics. Exit codes follow the Result contract: any execution error yields 3, else any validation error yields 2, else 0. Deterministic mode (<code>PANTSAGON_DETERMINISTIC=1</code>) stabilizes output: pack order is sorted, temp paths are omitted, and timing fields are not emitted. All rendering runs in isolated temp dirs with hooks disabled to avoid side effects.</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness-design/#ci-and-release-readiness","title":"CI and release readiness","text":"<p>CI adds a dedicated pack-validation step after pytest, using deterministic mode and <code>python -m pantsagon.tools.validate_packs --bundled</code>. This makes failures easy to triage and keeps validation independent of test discovery. Release readiness adds a v1.0.0 checklist doc and updates README with final status and usage notes. The README keeps deterministic mode and the new pack validation command clearly documented.</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/","title":"M6 CI + Release Readiness Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Add a deterministic pack-validation command, wire CI to run pytest + pack validation, and publish a v1.0.0 release checklist with a final README pass.</p> <p>Architecture: Implement <code>pantsagon.tools.validate_packs</code> as a standalone <code>python -m</code> module that uses existing pack validation + Copier rendering, aggregates diagnostics into Result-shaped JSON, and supports render-control flags. CI runs pytest and the new pack-validation command in deterministic mode. Release readiness is captured in a doc and reflected in README.</p> <p>Tech Stack: Python 3.12, argparse, Copier renderer, GitHub Actions, mkdocs.</p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/#task-1-pack-validation-tool-module","title":"Task 1: Pack validation tool module","text":"<p>Files: - Create: <code>services/pantsagon/src/pantsagon/tools/__init__.py</code> - Create: <code>services/pantsagon/src/pantsagon/tools/validate_packs.py</code> - Modify: <code>pantsagon/diagnostics/codes.yaml</code> - Modify: <code>docs/reference/diagnostic-codes.md</code></p> <p>Step 1: Implement the module (TDD skipped per instruction)</p> <p>Create <code>services/pantsagon/src/pantsagon/tools/validate_packs.py</code> with:</p> <pre><code>from __future__ import annotations\n\nimport argparse\nimport json\nimport os\nfrom dataclasses import asdict\nfrom pathlib import Path\nfrom typing import Any\n\nfrom pantsagon.adapters.errors import RendererExecutionError\nfrom pantsagon.adapters.policy import pack_validator\nfrom pantsagon.adapters.policy.pack_validator import PackPolicyEngine\nfrom pantsagon.adapters.renderer.copier_renderer import CopierRenderer\nfrom pantsagon.application.pack_validation import validate_pack\nfrom pantsagon.domain.determinism import is_deterministic\nfrom pantsagon.domain.diagnostics import Diagnostic, FileLocation, Severity\nfrom pantsagon.domain.pack import PackRef\nfrom pantsagon.domain.result import Result\nfrom pantsagon.ports.renderer import RenderRequest\n\nDEFAULTS_BY_NAME = {\n    \"service_name\": \"example-service\",\n    \"service_name_kebab\": \"example-service\",\n    \"repo_name\": \"example-repo\",\n    \"service_pkg\": \"example_service\",\n    \"service_pkg_snake\": \"example_service\",\n}\n\n\ndef _repo_root() -&gt; Path:\n    for candidate in [Path.cwd(), *Path.cwd().parents]:\n        if (candidate / \"pyproject.toml\").exists():\n            return candidate\n    return Path.cwd()\n\n\ndef _relative_path(path: Path, root: Path) -&gt; str:\n    try:\n        return str(path.relative_to(root))\n    except ValueError:\n        return str(path)\n\n\ndef _serialize_location(location: object | None) -&gt; dict[str, Any] | None:\n    if location is None:\n        return None\n    if isinstance(location, FileLocation):\n        return {\n            \"kind\": \"file\",\n            \"path\": location.path,\n            \"line\": location.line,\n            \"col\": location.col,\n        }\n    return asdict(location) if hasattr(location, \"__dict__\") else {\"kind\": \"unknown\"}\n\n\ndef _serialize_diagnostic(diagnostic: Diagnostic) -&gt; dict[str, Any]:\n    payload: dict[str, Any] = {\n        \"id\": diagnostic.id,\n        \"code\": diagnostic.code,\n        \"rule\": diagnostic.rule,\n        \"severity\": diagnostic.severity.value,\n        \"message\": diagnostic.message,\n    }\n    if diagnostic.location is not None:\n        payload[\"location\"] = _serialize_location(diagnostic.location)\n    if diagnostic.hint is not None:\n        payload[\"hint\"] = diagnostic.hint\n    if diagnostic.details is not None:\n        payload[\"details\"] = diagnostic.details\n    return payload\n\n\ndef _placeholder_for(var: dict[str, Any]) -&gt; Any:\n    name = str(var.get(\"name\", \"\"))\n    if name in DEFAULTS_BY_NAME:\n        return DEFAULTS_BY_NAME[name]\n    if \"default\" in var:\n        return var.get(\"default\")\n    vtype = var.get(\"type\")\n    if vtype == \"int\":\n        return 1\n    if vtype == \"bool\":\n        return False\n    if vtype == \"enum\":\n        enum_values = var.get(\"enum\")\n        if isinstance(enum_values, list) and enum_values:\n            return enum_values[0]\n    return \"example\"\n\n\ndef _build_answers(manifest: dict[str, Any]) -&gt; dict[str, Any]:\n    answers: dict[str, Any] = {}\n    raw_variables = manifest.get(\"variables\", [])\n    if isinstance(raw_variables, list):\n        for entry in raw_variables:\n            if not isinstance(entry, dict):\n                continue\n            name = entry.get(\"name\")\n            if name is None:\n                continue\n            answers[str(name)] = _placeholder_for(entry)\n    return answers\n\n\ndef _pack_dirs(packs_root: Path) -&gt; list[Path]:\n    if not packs_root.exists():\n        return []\n    dirs = [path for path in packs_root.iterdir() if path.is_dir()]\n    return sorted(dirs, key=lambda p: p.name)\n\n\ndef _missing_file_diagnostic(path: Path, root: Path, filename: str) -&gt; Diagnostic:\n    return Diagnostic(\n        code=\"PACK_FILE_MISSING\",\n        rule=\"pack.files\",\n        severity=Severity.ERROR,\n        message=f\"Missing required pack file: {filename}\",\n        location=FileLocation(_relative_path(path / filename, root)),\n    )\n\n\ndef _render_failed_diagnostic(pack_dir: Path, root: Path, pack_id: str, error: Exception) -&gt; Diagnostic:\n    return Diagnostic(\n        code=\"PACK_RENDER_FAILED\",\n        rule=\"pack.render\",\n        severity=Severity.ERROR,\n        message=str(error),\n        location=FileLocation(_relative_path(pack_dir, root)),\n        details={\"pack\": pack_id},\n        is_execution=True,\n    )\n\n\ndef validate_bundled_packs(\n    packs_root: Path,\n    *,\n    render_on_validation_error: bool,\n    render_enabled: bool,\n) -&gt; Result[dict[str, Any]]:\n    root = _repo_root()\n    pack_validator.SCHEMA_PATH = pack_validator._schema_path(root)\n    engine = PackPolicyEngine()\n    renderer = CopierRenderer()\n    diagnostics: list[Diagnostic] = []\n    artifacts: list[dict[str, Any]] = []\n\n    for pack_dir in _pack_dirs(packs_root):\n        pack_diags: list[Diagnostic] = []\n        missing = []\n        if not (pack_dir / \"pack.yaml\").exists():\n            missing.append(\"pack.yaml\")\n        if not (pack_dir / \"copier.yml\").exists():\n            missing.append(\"copier.yml\")\n        for filename in missing:\n            diag = _missing_file_diagnostic(pack_dir, root, filename)\n            pack_diags.append(diag)\n            diagnostics.append(diag)\n\n        manifest: dict[str, Any] = {}\n        pack_id = pack_dir.name\n        pack_version = \"unknown\"\n        if not missing:\n            result = validate_pack(pack_dir, engine)\n            manifest = result.value or {}\n            pack_diags.extend(result.diagnostics)\n            diagnostics.extend(result.diagnostics)\n            pack_id = str(manifest.get(\"id\", pack_dir.name))\n            pack_version = str(manifest.get(\"version\", \"unknown\"))\n\n        has_validation_errors = any(d.severity == Severity.ERROR for d in pack_diags if not d.is_execution)\n        render_skipped = False\n        status = \"passed\"\n\n        if not render_enabled:\n            render_skipped = True\n        elif has_validation_errors and not render_on_validation_error:\n            render_skipped = True\n\n        if has_validation_errors:\n            status = \"failed\"\n\n        if not render_skipped and not missing:\n            answers = _build_answers(manifest)\n            request = RenderRequest(\n                pack=PackRef(id=pack_id, version=pack_version, source=\"bundled\"),\n                pack_path=pack_dir,\n                staging_dir=Path(tempfile.mkdtemp()),\n                answers=answers,\n                allow_hooks=False,\n            )\n            try:\n                renderer.render(request)\n            except RendererExecutionError as exc:\n                diag = _render_failed_diagnostic(pack_dir, root, pack_id, exc)\n                diagnostics.append(diag)\n                pack_diags.append(diag)\n                status = \"failed\"\n\n        artifacts.append(\n            {\n                \"pack_id\": pack_id,\n                \"pack_version\": pack_version,\n                \"source\": \"bundled\",\n                \"status\": status,\n                \"render_skipped\": render_skipped,\n                \"diagnostics\": [_serialize_diagnostic(d) for d in pack_diags],\n            }\n        )\n\n    result = Result(value=None, diagnostics=diagnostics, artifacts=artifacts)\n    return result\n\n\ndef _build_parser() -&gt; argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(description=\"Validate bundled Pantsagon packs\")\n    parser.add_argument(\"--bundled\", action=\"store_true\", help=\"Validate bundled packs under ./packs\")\n    parser.add_argument(\"--json\", action=\"store_true\", help=\"Emit Result JSON\")\n    parser.add_argument(\"--render-on-validation-error\", action=\"store_true\")\n    parser.add_argument(\"--no-render\", action=\"store_true\")\n    return parser\n\n\ndef main(argv: list[str] | None = None) -&gt; int:\n    parser = _build_parser()\n    args = parser.parse_args(argv)\n    if not args.bundled:\n        parser.error(\"--bundled is required in v1\")\n\n    if args.no_render and args.render_on_validation_error:\n        args.render_on_validation_error = False\n\n    result = validate_bundled_packs(\n        packs_root=_repo_root() / \"packs\",\n        render_on_validation_error=args.render_on_validation_error,\n        render_enabled=not args.no_render,\n    )\n\n    if args.json:\n        payload = {\n            \"result_schema_version\": 1,\n            \"exit_code\": result.exit_code,\n            \"diagnostics\": [_serialize_diagnostic(d) for d in result.diagnostics],\n            \"artifacts\": result.artifacts,\n        }\n        print(json.dumps(payload, sort_keys=is_deterministic()))\n    else:\n        failed = [a for a in result.artifacts if a.get(\"status\") != \"passed\"]\n        print(f\"Validated {len(result.artifacts)} bundled packs\")\n        for artifact in result.artifacts:\n            print(f\"- {artifact['pack_id']}: {artifact['status']}\")\n        if failed:\n            print(f\"Failures: {len(failed)}\")\n\n    return result.exit_code\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(main())\n</code></pre> <p>Adjust minor details during implementation: - Import <code>tempfile</code> for staging dirs. - Ensure <code>_serialize_location</code> handles <code>FileLocation</code> correctly. - Use <code>_repo_root()</code> for relative paths and schema path. - Keep <code>pack</code> validation per pack (continue even after failure).</p> <p>Step 2: Add diagnostic codes</p> <p>Update <code>pantsagon/diagnostics/codes.yaml</code> with new codes:</p> <pre><code>  - code: PACK_FILE_MISSING\n    severity: error\n    rule: pack.files\n    message: Pack is missing a required file.\n    hint: Ensure pack.yaml and copier.yml exist in the pack directory.\n\n  - code: PACK_RENDER_FAILED\n    severity: error\n    rule: pack.render\n    message: Pack render failed.\n    hint: Check Copier templates and inputs.\n</code></pre> <p>Run doc generation and verify output:</p> <pre><code>python scripts/generate_diagnostic_codes.py\n</code></pre> <p>Expected: <code>docs/reference/diagnostic-codes.md</code> updated with the two new codes.</p> <p>Step 3: Run manual validation for the new command</p> <pre><code>PANTSAGON_DETERMINISTIC=1 PYTHONPATH=services/pantsagon/src python -m pantsagon.tools.validate_packs --bundled\n</code></pre> <p>Expected: human summary, exit code 0 if packs validate.</p> <p>Step 4: Commit</p> <pre><code>git add services/pantsagon/src/pantsagon/tools/validate_packs.py \\\n  services/pantsagon/src/pantsagon/tools/__init__.py \\\n  pantsagon/diagnostics/codes.yaml \\\n  docs/reference/diagnostic-codes.md\ngit commit -m \"feat: add bundled pack validation tool\"\n</code></pre>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/#task-2-ci-workflow-for-pytest-pack-validation","title":"Task 2: CI workflow for pytest + pack validation","text":"<p>Files: - Create: <code>.github/workflows/ci.yml</code></p> <p>Step 1: Create workflow (TDD skipped per instruction)</p> <pre><code>name: CI\n\non:\n  push:\n  pull_request:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    env:\n      PANTSAGON_DETERMINISTIC: \"1\"\n      PYTHONPATH: services/pantsagon/src\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n      - name: Install deps\n        run: |\n          python -m pip install --upgrade pip\n          python -m pip install -e \".[dev]\"\n      - name: Pytest\n        run: pytest -q\n      - name: Pack validation\n        run: python -m pantsagon.tools.validate_packs --bundled\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add .github/workflows/ci.yml\ngit commit -m \"ci: run pytest and pack validation\"\n</code></pre>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/#task-3-release-checklist-for-v100","title":"Task 3: Release checklist for v1.0.0","text":"<p>Files: - Create: <code>docs/contributing/release-checklist-v1.0.0.md</code> - Modify: <code>mkdocs.yml</code></p> <p>Step 1: Add the checklist doc (TDD skipped per instruction)</p> <pre><code># v1.0.0 Release Checklist\n\nThis checklist defines the minimum release readiness steps for Pantsagon v1.0.0.\n\n## Pre-release verification\n\n- [ ] CI green: pytest + pack validation (deterministic mode)\n- [ ] `python -m pantsagon.tools.validate_packs --bundled` passes locally\n- [ ] Docs generators ran with clean git diff\n- [ ] README reflects current CLI behavior and status\n\n## Packaging and versioning\n\n- [ ] Update `pyproject.toml` version to `1.0.0`\n- [ ] Tag the release `v1.0.0`\n- [ ] Publish release notes\n\n## Documentation\n\n- [ ] Update CLI docs if flags changed\n- [ ] Update schema docs if schemas changed\n- [ ] Update diagnostic codes if codes changed\n- [ ] Update pack docs if packs changed\n- [ ] Publish docs for `v1.0.0` and update `latest`\n</code></pre> <p>Add to mkdocs nav under Contributing:</p> <pre><code>  - Contributing:\n      - Docs: contributing/docs.md\n      - Release checklist v1.0.0: contributing/release-checklist-v1.0.0.md\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add docs/contributing/release-checklist-v1.0.0.md mkdocs.yml\ngit commit -m \"docs: add v1.0.0 release checklist\"\n</code></pre>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/#task-4-readme-final-pass","title":"Task 4: README final pass","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Update README (TDD skipped per instruction)</p> <p>Recommended edits: - Add <code>python -m pantsagon.tools.validate_packs --bundled</code> to Development or Packs sections. - Note deterministic mode used in CI: <code>PANTSAGON_DETERMINISTIC=1</code>. - Clarify pack validation guarantees (schema + copier cross-check + smoke render).</p> <p>Example snippet:</p> <pre><code>## Development\n\nRun tests:\n\n```bash\npytest -q\n</code></pre> <p>Pack validation:</p> <p><pre><code>PANTSAGON_DETERMINISTIC=1 PYTHONPATH=services/pantsagon/src \\\n  python -m pantsagon.tools.validate_packs --bundled\n</code></pre> <pre><code>**Step 2: Commit**\n\n```bash\ngit add README.md\ngit commit -m \"docs: update README for pack validation\"\n</code></pre></p>"},{"location":"plans/2026-01-10-m6-ci-release-readiness/#task-5-update-m6-checklist","title":"Task 5: Update M6 checklist","text":"<p>Files: - Modify: <code>docs/plans/2026-01-10-pantsagon-v1-checklist.md</code></p> <p>Step 1: Check off M6 items (TDD skipped per instruction)</p> <p>Mark the four M6 items as complete once Tasks 1\u20134 are done.</p> <p>Step 2: Commit</p> <pre><code>git add docs/plans/2026-01-10-pantsagon-v1-checklist.md\ngit commit -m \"docs: mark M6 checklist complete\"\n</code></pre>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/","title":"Pants Monorepo Conversion Design","text":"<p>Date: 2026-01-10</p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#goal","title":"Goal","text":"<p>Convert this repo into a Pants-managed monorepo with strict hexagonal layering, hard dependency boundaries, and contract-first guardrails, using Pants as the single control plane.</p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#decisions-validated","title":"Decisions (validated)","text":"<ul> <li><code>pantsagon</code> becomes a service: <code>services/pantsagon/src/pantsagon/</code> with top-level layers: <code>domain/</code>, <code>ports/</code>, <code>application/</code>, <code>adapters/</code>, <code>entrypoints/</code>.</li> <li>CLI stays in <code>entrypoints/cli.py</code> and is executed via a packaging target at the service root.</li> <li><code>ports/</code> is a first-class layer (not nested under application).</li> <li><code>packs/</code> stays at repo root; <code>schemas/</code> move to <code>shared/contracts/schemas/</code>.</li> <li>Entry points are non-importable: only a packaging target may depend on them.</li> <li>Tag taxonomy includes an explicit <code>layer:ports</code>.</li> <li>No cross-service imports by default; add a <code>public_api</code> target only if needed later.</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#target-layout","title":"Target Layout","text":"<pre><code>repo/\n  pants.toml\n  pyproject.toml\n  pyrightconfig.json\n  .ruff.toml\n\n  3rdparty/\n    python/\n      requirements.txt\n      BUILD\n\n  shared/\n    foundation/\n      src/...\n      tests/...\n      BUILD\n    adapters/\n      &lt;integration&gt;/\n        src/...\n        tests/...\n        BUILD\n    contracts/\n      schemas/\n        pack.schema.v1.json\n      BUILD\n\n  services/\n    pantsagon/\n      src/pantsagon/\n        domain/\n        ports/\n        application/\n        adapters/\n        entrypoints/\n      tests/\n      BUILD\n\n  packs/\n    core/\n    python/\n    openapi/\n    docker/\n\n  tools/\n    forbidden_imports/\n      forbidden_imports.yaml\n      src/...\n      tests/...\n      BUILD\n</code></pre>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#dependency-rules-hexagonal-enforcement","title":"Dependency Rules (Hexagonal Enforcement)","text":"<ul> <li>domain \u2192 domain + <code>shared/foundation</code></li> <li>ports \u2192 ports + domain + <code>shared/foundation</code></li> <li>application \u2192 application + ports + domain + <code>shared/foundation</code></li> <li>adapters \u2192 adapters + application + ports + domain + <code>shared/foundation</code> + allowlisted <code>shared/adapters</code> + 3rdparty</li> <li>entrypoints \u2192 entrypoints + adapters + application + ports + domain + <code>shared/foundation</code></li> </ul> <p>Service boundary: each layer target uses <code>__dependents_rules__</code> limited to <code>svc:pantsagon</code> tags, except entrypoints which are only depended on by a packaging target.</p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#tags","title":"Tags","text":"<ul> <li><code>svc:pantsagon</code></li> <li><code>layer:domain|ports|application|adapters|entrypoints</code></li> <li><code>shared:foundation|adapters|contracts</code></li> <li><code>adapter:&lt;integration&gt;</code></li> <li>Optional: <code>domain:&lt;group&gt;</code>, <code>team:&lt;name&gt;</code></li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#build-snippet-patterns-key-example-entrypoints","title":"BUILD Snippet Patterns (key example: entrypoints)","text":"<pre><code># services/pantsagon/src/pantsagon/entrypoints/BUILD\n__dependents_rules__ = [\n  {\"address\": \"services/pantsagon:cli\"},\n]\n\npython_sources(\n  name=\"entrypoints\",\n  tags=[\"svc:pantsagon\", \"layer:entrypoints\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/adapters:adapters\",\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//shared/foundation:lib\",\n  ],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/entrypoints/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/adapters/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/application/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/ports/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n    {\"path\": \"shared/adapters/**\"},\n    {\"path\": \"3rdparty/python/**\"},\n  ],\n)\n</code></pre> <pre><code># services/pantsagon/BUILD\npex_binary(\n  name=\"cli\",\n  entry_point=\"pantsagon.entrypoints.cli:app\",\n  dependencies=[\"//services/pantsagon/src/pantsagon/entrypoints:entrypoints\"],\n)\n</code></pre>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#pants-baseline","title":"Pants Baseline","text":"<ul> <li><code>pants.toml</code> per guide (Python, docker, ruff, pyright, pytest, openapi, visibility, terraform optional).</li> <li><code>[python-infer].unowned_dependency_behavior = \"error\"</code></li> <li><code>[visibility].enforce = true</code></li> <li>Single resolve at <code>3rdparty/python/python-default.lock</code>.</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#contracts-assets","title":"Contracts &amp; Assets","text":"<ul> <li>JSON Schemas in <code>shared/contracts/schemas/</code> (validated with Pants/OpenAPI tooling if applicable).</li> <li>Packs remain at repo root as tool-owned assets (<code>packs/</code>).</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#forbidden-imports-tooling","title":"Forbidden Imports Tooling","text":"<ul> <li>Extend the forbidden-import checker to include ports (deny frameworks/SDKs in <code>services/**/ports/**</code>).</li> <li>Keep domain/application/ports checks as developer-friendly errors; Pants rules remain authoritative.</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#tests-policy","title":"Tests Policy","text":"<ul> <li>Domain tests: depend on domain only.</li> <li>Application tests: depend on application + ports + domain.</li> <li>Adapter tests: depend on adapters + ports + domain + application.</li> <li>Entry point tests: minimal; prefer integration tests.</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#ci-commands","title":"CI Commands","text":"<ul> <li><code>pants tailor --check ::</code></li> <li><code>pants update-build-files --check ::</code></li> <li><code>pants lint check test ::</code></li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion-design/#migration-summary","title":"Migration Summary","text":"<ul> <li>Move <code>pantsagon/</code> \u2192 <code>services/pantsagon/src/pantsagon/</code></li> <li>Keep layer subdirectories and add <code>ports/</code> as a top-level layer.</li> <li>Move <code>tests/</code> \u2192 <code>services/pantsagon/tests/</code></li> <li>Move <code>schemas/pack.schema.v1.json</code> \u2192 <code>shared/contracts/schemas/</code></li> <li>Keep <code>packs/</code> at repo root</li> </ul>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/","title":"Pants Monorepo Conversion Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Convert the repo into a Pants-managed monorepo with strict hexagonal layering, hard dependency boundaries, and contract-first guardrails.</p> <p>Architecture: Treat <code>pantsagon</code> as a service under <code>services/pantsagon/</code> with top-level layers (<code>domain</code>, <code>ports</code>, <code>application</code>, <code>adapters</code>, <code>entrypoints</code>), strict dependency/visibility rules, and a non-importable entrypoints layer. Keep <code>packs/</code> at repo root and move JSON schemas to <code>shared/contracts/schemas/</code>.</p> <p>Tech Stack: Pants 2.30.x, Python 3.12, Ruff, Pyright, Pytest, PEX.</p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-1-add-pants-baseline-configuration-tool-configs","title":"Task 1: Add Pants baseline configuration + tool configs","text":"<p>Files: - Create: <code>pants.toml</code> - Create: <code>3rdparty/python/requirements.txt</code> - Create: <code>3rdparty/python/BUILD</code> - Create: <code>.ruff.toml</code> - Create: <code>pyrightconfig.json</code></p> <p>Step 1: Write a failing check (existence test)</p> <p>Create <code>services/pantsagon/tests/test_repo_layout.py</code> with: <pre><code>from pathlib import Path\n\n\ndef test_repo_layout_basics_exist() -&gt; None:\n    root = Path(__file__).resolve().parents[3]\n    assert (root / \"pants.toml\").exists()\n    assert (root / \"3rdparty/python/requirements.txt\").exists()\n</code></pre> Expected: FAIL because files don\u2019t exist yet.</p> <p>Step 2: Create Pants + tool configs</p> <p>Create <code>pants.toml</code>: <pre><code>[GLOBAL]\npants_version = \"2.30.0\"\nbackend_packages = [\n  \"pants.backend.python\",\n  \"pants.backend.shell\",\n  \"pants.backend.docker\",\n\n  \"pants.backend.experimental.python.lint.ruff.check\",\n  \"pants.backend.experimental.python.lint.ruff.format\",\n  \"pants.backend.experimental.python.typecheck.pyright\",\n  \"pants.backend.python.test.pytest\",\n\n  \"pants.backend.experimental.openapi\",\n  \"pants.backend.experimental.openapi.codegen.python\",\n  \"pants.backend.experimental.openapi.lint.spectral\",\n  \"pants.backend.experimental.openapi.lint.openapi_format\",\n\n  \"pants.backend.experimental.terraform\",\n  \"pants.backend.experimental.visibility\",\n  \"pants.backend.experimental.adhoc\",\n  \"pants.backend.build_files.fmt.ruff\",\n]\n\n[source]\nroot_patterns = [\n  \"shared/**/src\",\n  \"services/**/src\",\n  \"tools/**/src\",\n]\n\n[python]\ninterpreter_constraints = [\"CPython&gt;=3.12,&lt;3.15\"]\nenable_resolves = true\ndefault_resolve = \"python-default\"\nresolves = { python-default = \"3rdparty/python/python-default.lock\" }\n\n[python-infer]\nunowned_dependency_behavior = \"error\"\n\n[visibility]\nenforce = true\n</code></pre></p> <p>Create <code>3rdparty/python/requirements.txt</code>: <pre><code>typer&gt;=0.12\ncopier&gt;=9.0\npyyaml&gt;=6.0\njsonschema&gt;=4.22\ntomli-w&gt;=1.0\nrich&gt;=13.7\npytest&gt;=8.0\npytest-cov&gt;=5.0\n</code></pre></p> <p>Create <code>3rdparty/python/BUILD</code>: <pre><code>python_requirements(name=\"reqs\", source=\"requirements.txt\")\n</code></pre></p> <p>Create <code>.ruff.toml</code>: <pre><code>line-length = 100\ntarget-version = \"py312\"\n\n[lint]\nselect = [\"E\", \"F\", \"I\"]\n</code></pre></p> <p>Create <code>pyrightconfig.json</code>: <pre><code>{\n  \"pythonVersion\": \"3.12\",\n  \"typeCheckingMode\": \"strict\",\n  \"reportMissingTypeStubs\": false,\n  \"exclude\": [\".git\", \".worktrees\", \"dist\", \"build\"]\n}\n</code></pre></p> <p>Step 3: Run tests to verify Step 1 passes Run: <code>python3.12 -m pytest services/pantsagon/tests/test_repo_layout.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add pants.toml 3rdparty/python/requirements.txt 3rdparty/python/BUILD .ruff.toml pyrightconfig.json services/pantsagon/tests/test_repo_layout.py\ngit commit -m \"chore: add pants baseline config\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-2-move-schemas-to-sharedcontracts-and-add-sharedfoundation-skeleton","title":"Task 2: Move schemas to shared/contracts and add shared/foundation skeleton","text":"<p>Files: - Move: <code>schemas/pack.schema.v1.json</code> \u2192 <code>shared/contracts/schemas/pack.schema.v1.json</code> - Create: <code>shared/contracts/BUILD</code> - Create: <code>shared/foundation/src/foundation/__init__.py</code> - Create: <code>shared/foundation/BUILD</code></p> <p>Step 1: Write a failing check Add to <code>services/pantsagon/tests/test_repo_layout.py</code>: <pre><code>    assert (root / \"shared/contracts/schemas/pack.schema.v1.json\").exists()\n</code></pre> Expected: FAIL.</p> <p>Step 2: Move schema and add shared targets Run: <pre><code>mkdir -p shared/contracts/schemas\nmkdir -p shared/foundation/src/foundation\nmkdir -p shared/foundation/tests\nmv schemas/pack.schema.v1.json shared/contracts/schemas/pack.schema.v1.json\n</code></pre></p> <p>Create <code>shared/contracts/BUILD</code>: <pre><code>__dependents_rules__ = [{\"type\": \"*\"}]\n\nresources(\n  name=\"schemas\",\n  sources=[\"schemas/**/*.json\"],\n  tags=[\"shared:contracts\"],\n)\n</code></pre></p> <p>Create <code>shared/foundation/src/foundation/__init__.py</code>: <pre><code># Foundation layer placeholder.\n</code></pre></p> <p>Create <code>shared/foundation/BUILD</code>: <pre><code>__dependents_rules__ = [{\"type\": \"*\"}]\n\npython_sources(\n  name=\"lib\",\n  tags=[\"shared:foundation\"],\n  __dependencies_rules__=[\n    {\"path\": \"shared/foundation/src/**\"},\n  ],\n)\n\npython_tests(\n  name=\"tests\",\n  dependencies=[\":lib\"],\n)\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/test_repo_layout.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add shared/contracts shared/foundation services/pantsagon/tests/test_repo_layout.py\n\ngit commit -m \"chore: add shared contracts and foundation\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-3-move-service-code-to-servicespantsagonsrcpantsagon","title":"Task 3: Move service code to <code>services/pantsagon/src/pantsagon</code>","text":"<p>Files: - Move: <code>pantsagon/</code> \u2192 <code>services/pantsagon/src/pantsagon/</code> - Ensure: <code>services/pantsagon/src/pantsagon/ports/</code> stays top-level</p> <p>Step 1: Write a failing check Add to <code>services/pantsagon/tests/test_repo_layout.py</code>: <pre><code>    assert (root / \"services/pantsagon/src/pantsagon/entrypoints/cli.py\").exists()\n</code></pre> Expected: FAIL.</p> <p>Step 2: Move package Run: <pre><code>mkdir -p services/pantsagon/src\nmv pantsagon services/pantsagon/src/pantsagon\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/test_repo_layout.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add services/pantsagon/src/pantsagon services/pantsagon/tests/test_repo_layout.py\n\ngit commit -m \"refactor: move pantsagon package into services layout\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-4-move-tests-into-service-and-update-paths","title":"Task 4: Move tests into service and update paths","text":"<p>Files: - Move: <code>tests/</code> \u2192 <code>services/pantsagon/tests/</code> - Modify: <code>services/pantsagon/tests/packs/test_bundled_packs.py</code> - Modify: <code>pyproject.toml</code></p> <p>Step 1: Write a failing test (path) Update <code>services/pantsagon/tests/test_repo_layout.py</code> to assert: <pre><code>    assert (root / \"services/pantsagon/tests/packs/test_bundled_packs.py\").exists()\n</code></pre> Expected: FAIL.</p> <p>Step 2: Move tests and fix path reference Run: <pre><code>mv tests services/pantsagon/tests\n</code></pre></p> <p>Update <code>services/pantsagon/tests/packs/test_bundled_packs.py</code>: <pre><code>from pathlib import Path\n\nfrom pantsagon.application.pack_validation import validate_pack\n\n\ndef test_all_bundled_packs_validate():\n    root = Path(__file__).resolve().parents[3]\n    packs_dir = root / \"packs\"\n    for pack in (\"core\", \"python\", \"openapi\", \"docker\"):\n        result = validate_pack(packs_dir / pack)\n        assert result.is_ok(), result\n</code></pre></p> <p>Update <code>pyproject.toml</code> pytest config to include the new src path: <pre><code>[tool.pytest.ini_options]\naddopts = \"-q\"\npythonpath = [\"services/pantsagon/src\", \".\"]\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/packs/test_bundled_packs.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add services/pantsagon/tests pyproject.toml\n\ngit commit -m \"refactor: move tests under service\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-5-add-pants-build-files-for-service-layers-packaging","title":"Task 5: Add Pants BUILD files for service layers + packaging","text":"<p>Files: - Create: <code>services/pantsagon/BUILD</code> - Create: <code>services/pantsagon/src/pantsagon/domain/BUILD</code> - Create: <code>services/pantsagon/src/pantsagon/ports/BUILD</code> - Create: <code>services/pantsagon/src/pantsagon/application/BUILD</code> - Create: <code>services/pantsagon/src/pantsagon/adapters/BUILD</code> - Create: <code>services/pantsagon/src/pantsagon/entrypoints/BUILD</code> - Create: <code>services/pantsagon/tests/BUILD</code></p> <p>Step 1: Write a failing test (Pants address check) Add a minimal test to <code>services/pantsagon/tests/test_repo_layout.py</code> to check the BUILD file exists: <pre><code>    assert (root / \"services/pantsagon/src/pantsagon/domain/BUILD\").exists()\n</code></pre> Expected: FAIL.</p> <p>Step 2: Create BUILD files</p> <p>Create <code>services/pantsagon/BUILD</code>: <pre><code>pex_binary(\n  name=\"cli\",\n  entry_point=\"pantsagon.entrypoints.cli:app\",\n  dependencies=[\"//services/pantsagon/src/pantsagon/entrypoints:entrypoints\"],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/src/pantsagon/domain/BUILD</code>: <pre><code>__dependents_rules__ = [{\"tags\": [\"svc:pantsagon\"]}]\n\npython_sources(\n  name=\"domain\",\n  tags=[\"svc:pantsagon\", \"layer:domain\"],\n  dependencies=[\"//shared/foundation:lib\"],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n  ],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/src/pantsagon/ports/BUILD</code>: <pre><code>__dependents_rules__ = [{\"tags\": [\"svc:pantsagon\"]}]\n\npython_sources(\n  name=\"ports\",\n  tags=[\"svc:pantsagon\", \"layer:ports\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//shared/foundation:lib\",\n  ],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/ports/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n  ],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/src/pantsagon/application/BUILD</code>: <pre><code>__dependents_rules__ = [{\"tags\": [\"svc:pantsagon\"]}]\n\npython_sources(\n  name=\"application\",\n  tags=[\"svc:pantsagon\", \"layer:application\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//shared/foundation:lib\",\n  ],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/application/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/ports/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n  ],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/src/pantsagon/adapters/BUILD</code>: <pre><code>__dependents_rules__ = [{\"tags\": [\"svc:pantsagon\"]}]\n\npython_sources(\n  name=\"adapters\",\n  tags=[\"svc:pantsagon\", \"layer:adapters\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//shared/foundation:lib\",\n  ],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/adapters/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/application/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/ports/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n    {\"path\": \"shared/adapters/**\"},\n    {\"path\": \"3rdparty/python/**\"},\n  ],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/src/pantsagon/entrypoints/BUILD</code>: <pre><code>__dependents_rules__ = [\n  {\"address\": \"services/pantsagon:cli\"},\n]\n\npython_sources(\n  name=\"entrypoints\",\n  tags=[\"svc:pantsagon\", \"layer:entrypoints\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/adapters:adapters\",\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//shared/foundation:lib\",\n  ],\n  __dependencies_rules__=[\n    {\"path\": \"services/pantsagon/src/pantsagon/entrypoints/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/adapters/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/application/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/ports/**\"},\n    {\"path\": \"services/pantsagon/src/pantsagon/domain/**\"},\n    {\"path\": \"shared/foundation/src/**\"},\n    {\"path\": \"shared/adapters/**\"},\n    {\"path\": \"3rdparty/python/**\"},\n  ],\n)\n</code></pre></p> <p>Create <code>services/pantsagon/tests/BUILD</code>: <pre><code>python_tests(\n  name=\"domain\",\n  sources=[\"domain/**/*.py\"],\n  dependencies=[\"//services/pantsagon/src/pantsagon/domain:domain\"],\n)\n\npython_tests(\n  name=\"application\",\n  sources=[\"application/**/*.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n  ],\n)\n\npython_tests(\n  name=\"adapters\",\n  sources=[\"adapters/**/*.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/adapters:adapters\",\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n  ],\n)\n\npython_tests(\n  name=\"entrypoints\",\n  sources=[\"entrypoints/**/*.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/entrypoints:entrypoints\",\n    \"//services/pantsagon/src/pantsagon/adapters:adapters\",\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/ports:ports\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n  ],\n)\n\npython_tests(\n  name=\"packs\",\n  sources=[\"packs/**/*.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n    \"//shared/contracts:schemas\",\n    \"//packs:bundled\",\n  ],\n)\n\npython_tests(\n  name=\"e2e\",\n  sources=[\"e2e/**/*.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/entrypoints:entrypoints\",\n  ],\n)\n\npython_tests(\n  name=\"misc\",\n  sources=[\"test_imports.py\"],\n  dependencies=[\n    \"//services/pantsagon/src/pantsagon/application:application\",\n    \"//services/pantsagon/src/pantsagon/domain:domain\",\n  ],\n)\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/test_repo_layout.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add services/pantsagon/BUILD services/pantsagon/src/pantsagon/**/BUILD services/pantsagon/tests/BUILD services/pantsagon/tests/test_repo_layout.py\n\ngit commit -m \"build: add pants targets for service layers\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-6-add-packsresources-build-and-wire-shared-contracts","title":"Task 6: Add packs/resources BUILD and wire shared contracts","text":"<p>Files: - Create: <code>packs/BUILD</code></p> <p>Step 1: Write a failing check Add to <code>services/pantsagon/tests/test_repo_layout.py</code>: <pre><code>    assert (root / \"packs/BUILD\").exists()\n</code></pre> Expected: FAIL.</p> <p>Step 2: Create packs BUILD Create <code>packs/BUILD</code>: <pre><code>resources(\n  name=\"bundled\",\n  sources=[\"**/*\"],\n)\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/test_repo_layout.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add packs/BUILD services/pantsagon/tests/test_repo_layout.py\n\ngit commit -m \"build: add packs resources target\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-7-implement-forbidden-imports-checker-with-ports-support-tdd","title":"Task 7: Implement forbidden-imports checker with ports support (TDD)","text":"<p>Files: - Create: <code>tools/forbidden_imports/forbidden_imports.yaml</code> - Create: <code>tools/forbidden_imports/src/forbidden_imports/checker.py</code> - Create: <code>tools/forbidden_imports/tests/test_checker.py</code> - Create: <code>tools/forbidden_imports/tests/test_repo_scan.py</code> - Create: <code>tools/forbidden_imports/BUILD</code></p> <p>Step 1: Write failing tests Create <code>tools/forbidden_imports/tests/test_checker.py</code>: <pre><code>from pathlib import Path\n\nfrom forbidden_imports.checker import load_config, scan_files\n\n\ndef test_ports_reject_framework_import(tmp_path: Path) -&gt; None:\n    cfg = tmp_path / \"forbidden_imports.yaml\"\n    cfg.write_text(\n        \"layers:\\n\"\n        \"  ports:\\n\"\n        \"    include: ['ports/*.py']\\n\"\n        \"    deny: ['fastapi', 'requests']\\n\"\n    )\n    bad = tmp_path / \"ports\" / \"bad.py\"\n    bad.parent.mkdir(parents=True)\n    bad.write_text(\"import fastapi\\n\")\n\n    config = load_config(cfg)\n    violations = scan_files(config, [bad])\n    assert violations, \"Expected a violation for ports layer\"\n</code></pre></p> <p>Create <code>tools/forbidden_imports/tests/test_repo_scan.py</code>: <pre><code>from pathlib import Path\n\nfrom forbidden_imports.checker import load_config, scan_tree\n\n\ndef test_repo_has_no_forbidden_imports() -&gt; None:\n    root = Path(__file__).resolve().parents[3]\n    config = load_config(root / \"tools/forbidden_imports/forbidden_imports.yaml\")\n    violations = scan_tree(config, root)\n    assert not violations, \"\\n\" + \"\\n\".join(violations)\n</code></pre> Expected: FAIL (checker not implemented).</p> <p>Step 2: Implement checker + config Create <code>tools/forbidden_imports/forbidden_imports.yaml</code>: <pre><code>layers:\n  domain:\n    include:\n      - \"services/**/src/**/domain/**/*.py\"\n    deny:\n      - \"requests\"\n      - \"fastapi\"\n      - \"boto3\"\n  application:\n    include:\n      - \"services/**/src/**/application/**/*.py\"\n    deny:\n      - \"requests\"\n      - \"fastapi\"\n      - \"boto3\"\n  ports:\n    include:\n      - \"services/**/src/**/ports/**/*.py\"\n    deny:\n      - \"requests\"\n      - \"fastapi\"\n      - \"boto3\"\n</code></pre></p> <p>Create <code>tools/forbidden_imports/src/forbidden_imports/checker.py</code>: <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport ast\nimport fnmatch\nimport yaml\n\n\n@dataclass(frozen=True)\nclass LayerRule:\n    name: str\n    include: list[str]\n    deny: list[str]\n\n\n@dataclass(frozen=True)\nclass Config:\n    layers: list[LayerRule]\n\n\ndef load_config(path: Path) -&gt; Config:\n    data = yaml.safe_load(path.read_text()) or {}\n    layers = []\n    for name, rules in (data.get(\"layers\") or {}).items():\n        layers.append(LayerRule(name=name, include=rules.get(\"include\", []), deny=rules.get(\"deny\", [])))\n    return Config(layers=layers)\n\n\ndef _matches_any(path: Path, patterns: list[str]) -&gt; bool:\n    rel = path.as_posix()\n    return any(fnmatch.fnmatch(rel, pattern) for pattern in patterns)\n\n\ndef _deny_hit(import_name: str, deny: list[str]) -&gt; bool:\n    return any(import_name == d or import_name.startswith(d + \".\") for d in deny)\n\n\ndef scan_files(config: Config, files: list[Path]) -&gt; list[str]:\n    violations: list[str] = []\n    for file in files:\n        for layer in config.layers:\n            if _matches_any(file, layer.include):\n                tree = ast.parse(file.read_text(), filename=str(file))\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for alias in node.names:\n                            if _deny_hit(alias.name, layer.deny):\n                                violations.append(f\"{file}:{node.lineno} forbidden import '{alias.name}' in layer {layer.name}\")\n                    elif isinstance(node, ast.ImportFrom) and node.module:\n                        if _deny_hit(node.module, layer.deny):\n                            violations.append(\n                                f\"{file}:{node.lineno} forbidden import '{node.module}' in layer {layer.name}\"\n                            )\n    return violations\n\n\ndef scan_tree(config: Config, root: Path) -&gt; list[str]:\n    files: list[Path] = [p for p in root.rglob(\"*.py\") if p.is_file()]\n    return scan_files(config, files)\n</code></pre></p> <p>Create <code>tools/forbidden_imports/BUILD</code>: <pre><code>python_sources(name=\"lib\", sources=[\"src/**/*.py\"])\n\npython_tests(\n  name=\"tests\",\n  sources=[\"tests/**/*.py\"],\n  dependencies=[\":lib\"],\n)\n</code></pre></p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest tools/forbidden_imports/tests/test_checker.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add tools/forbidden_imports\n\ngit commit -m \"feat: add forbidden imports checker with ports support\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-8-update-references-to-schemas-path","title":"Task 8: Update references to schemas path","text":"<p>Files: - Modify: <code>services/pantsagon/src/pantsagon/application/pack_validation.py</code> - Modify: <code>services/pantsagon/tests/pack/*</code> if path is embedded</p> <p>Step 1: Write failing test Add to <code>services/pantsagon/tests/pack/test_pack_validation.py</code> (or equivalent): <pre><code>from pathlib import Path\n\nfrom pantsagon.application.pack_validation import _schema_path\n\n\ndef test_schema_path_points_to_shared_contracts() -&gt; None:\n    root = Path(__file__).resolve().parents[3]\n    assert _schema_path(root).as_posix().endswith(\"shared/contracts/schemas/pack.schema.v1.json\")\n</code></pre> Expected: FAIL until <code>_schema_path</code> is updated.</p> <p>Step 2: Update path logic Update <code>services/pantsagon/src/pantsagon/application/pack_validation.py</code> to compute schema path via repo root: <pre><code>from pathlib import Path\n\n\ndef _schema_path(root: Path) -&gt; Path:\n    return root / \"shared/contracts/schemas/pack.schema.v1.json\"\n</code></pre> (Adjust callers to pass repo root as needed.)</p> <p>Step 3: Run tests Run: <code>python3.12 -m pytest services/pantsagon/tests/pack/test_pack_validation.py -v</code> Expected: PASS.</p> <p>Step 4: Commit <pre><code>git add services/pantsagon/src/pantsagon/application/pack_validation.py services/pantsagon/tests/pack/test_pack_validation.py\n\ngit commit -m \"refactor: update schema path to shared/contracts\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-9-generate-pants-lockfile-and-run-repo-checks","title":"Task 9: Generate Pants lockfile and run repo checks","text":"<p>Files: - Create: <code>3rdparty/python/python-default.lock</code></p> <p>Step 1: Generate lockfiles Run: <code>pants generate-lockfiles</code> Expected: lockfile generated at <code>3rdparty/python/python-default.lock</code>.</p> <p>Step 2: Run Pants hygiene + tests Run: <pre><code>pants tailor --check ::\npants update-build-files --check ::\npants lint check test ::\n</code></pre> Expected: all pass.</p> <p>Step 3: Commit <pre><code>git add 3rdparty/python/python-default.lock\n\ngit commit -m \"chore: generate pants lockfile\"\n</code></pre></p>"},{"location":"plans/2026-01-10-pants-monorepo-conversion/#task-10-final-verification","title":"Task 10: Final verification","text":"<p>Files: - None (verification only)</p> <p>Step 1: Run full test suite Run: <code>python3.12 -m pytest -q</code> Expected: PASS.</p> <p>Step 2: Run Pants targets for the service only Run: <code>pants lint check test services/pantsagon::</code> Expected: PASS.</p> <p>Step 3: Commit (if needed) If verification steps required changes, commit them. Otherwise, no commit needed.</p>"},{"location":"plans/2026-01-10-pantsagon-cli-design/","title":"Pantsagon CLI + Pack System Design","text":"<p>Goal: Ship Pantsagon v1 as a hexagonal, pack-based scaffolding CLI that generates enforced Pants hexagonal monorepos with contract-first (OpenAPI) and Docker packaging support.</p> <p>Architecture: Hexagonal core (domain/application) with ports/adapters. Packs are tool-agnostic via <code>pack.yaml</code>, rendered via Copier. CLI is a thin entrypoint; logic lives in application use-cases. <code>.pantsagon.toml</code> is the single source of truth for repo state.</p> <p>Tech Stack: Python, Typer (CLI), Copier (renderer), Pants.</p>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#scope-v1","title":"Scope (v1)","text":"<ul> <li>Commands: <code>init</code>, <code>add service</code>, <code>validate</code>.</li> <li>Packs: <code>core</code>, <code>python</code>, <code>openapi</code>, <code>docker</code>.</li> <li>Pack sources: bundled + local only (no git/registry in v1).</li> <li>Hooks: disabled by default; bundled packs may be allowed with explicit trust.</li> <li>No upgrade command in v1.</li> <li>Optional augmented-coding file creation (AGENTS/Claude/Gemini) during repo setup when explicitly requested.</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#repo-layout","title":"Repo Layout","text":"<pre><code>pantsagon/\n  pantsagon/\n    domain/\n    application/\n    ports/\n    adapters/\n      pack_catalog/\n      renderer/\n      workspace/\n      policy/\n      command/\n    entrypoints/\n  packs/\n    _shared/\n      templates/\n    core/\n    python/\n    openapi/\n    docker/\n  schemas/\n    pack.schema.v1.json\n    lock.schema.v1.json\n  tests/\n  docs/\n  pyproject.toml\n  README.md\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#domain-model","title":"Domain Model","text":"<ul> <li>Blueprint: user intent (repo name, languages, services, features).</li> <li>PackRef: <code>{id, version, source, location?, git_ref?, commit?, digest?, subdir?}</code>.</li> <li>PackDigest: optional hash for content-addressing (v1 unused, but modeled).</li> <li>PackSelection: ordered list of PackRef + resolved dependency graph.</li> <li>RenderPlan: deterministic plan of outputs and a patch (create/modify/delete).</li> <li>RepoLock: representation of <code>.pantsagon.toml</code> (single source of truth).</li> <li>Diagnostic: structured error/warn/info with <code>code</code>, <code>rule</code>, <code>id</code>, <code>severity</code>, <code>message</code>, <code>location</code>, <code>hint</code>, <code>details</code>.</li> <li>Result[T]: <code>value?</code>, <code>diagnostics[]</code>, <code>artifacts[]</code>, <code>exit_code</code>.</li> <li>Location union: Pack(id,path), File(path,line,col), Path(path), Command(name).</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#pantsagontoml-structure","title":"<code>.pantsagon.toml</code> Structure","text":"<pre><code>[tool]\nname = \"pantsagon\"\nversion = \"1.0.0\"\n\n[settings]\nrenderer = \"copier\"\nstrict = false\nstrict_manifest = true\nallow_hooks = false\n\n[selection]\nlanguages = [\"python\"]\nfeatures = [\"openapi\", \"docker\"]\nservices = [\"monitors\", \"governance\"]\naugmented_coding = \"agents\" # or \"claude\" | \"gemini\" | \"none\"\n\n[[resolved.packs]]\nid = \"pantsagon.core\"\nversion = \"1.0.0\"\nsource = \"bundled\"\n\n[resolved.answers]\npython_min = \"3.12\"\npython_max = \"3.14\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#use-case-flows","title":"Use-Case Flows","text":""},{"location":"plans/2026-01-10-pantsagon-cli-design/#init","title":"<code>init</code>","text":"<ol> <li>Parse inputs \u2192 <code>Blueprint</code>.</li> <li>Resolve <code>PackSelection</code> (validate compatibility, required/conflicts).</li> <li>Validate pack schema (<code>pack.yaml</code>) + manifest\u2194Copier cross-check.</li> <li>Build deterministic <code>RenderPlan</code> (patch-oriented).</li> <li>Workspace transaction: render into staging dir, write <code>.pantsagon.toml</code> in staging, then atomic commit.</li> <li>Run repo policy checks.</li> <li>Optional execution (<code>pants tailor --check</code>, <code>pants lint/check/test</code>) if explicitly requested.</li> </ol>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#add-service","title":"<code>add service</code>","text":"<ul> <li>Validate repo + load <code>.pantsagon.toml</code>.</li> <li>Enforce naming rules (kebab-case, reserved names forbidden, deterministic package name mapping).</li> <li>Idempotent by default: fail if service exists unless <code>--overwrite</code> (future).</li> <li>Render only service-scoped <code>RenderPlan</code> into staging and commit atomically.</li> <li>Update <code>.pantsagon.toml</code>.</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#validate","title":"<code>validate</code>","text":"<ul> <li>Validate schema, compatibility, pack selection, and repo invariants.</li> <li>Detect lock drift: recompute expected paths from lock and check existence.</li> <li>Optional exec validation with <code>--exec</code>.</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#validate_pack-internal-use-case","title":"<code>validate_pack</code> (internal use-case)","text":"<ul> <li>Schema validation</li> <li>Manifest\u2194Copier cross-check</li> <li>Render smoke-test into temp dir</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#ports-contracts","title":"Ports (Contracts)","text":"<ul> <li>PackCatalogPort: list/find/fetch packs (by PackRef).</li> <li>RendererPort: render <code>RenderRequest</code> \u2192 <code>RenderOutcome</code> (renderer-agnostic).</li> <li>WorkspacePort: begin transaction, apply patch, commit/rollback atomically.</li> <li>PolicyEnginePort: validate packs + repo invariants, return Diagnostics.</li> <li>CommandRunnerPort: execute Pants commands (optional, explicit).</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#errors-and-results","title":"Errors and Results","text":"<ul> <li>Expected validation failures return <code>Result</code> with diagnostics (exit code 2).</li> <li>Execution/IO failures raise typed <code>AdapterError</code> (exit code 3).</li> <li>Exit code precedence: exec error \u2192 3, else validation error \u2192 2, else 0; unexpected \u2192 4.</li> </ul> <p>AdapterError taxonomy (stable): - PackFetchError, PackReadError, PackParseError - RendererTemplateError, RendererExecutionError - WorkspaceTransactionError, WorkspaceCommitError - CommandNotFound, CommandFailed, CommandTimeout</p>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#packs","title":"Packs","text":"<ul> <li>Pack format: <code>pack.yaml</code> (authoritative) + <code>copier.yml</code> (renderer config) + <code>templates/</code>.</li> <li><code>pack.yaml</code> schema is validated by <code>schemas/pack.schema.v1.json</code>.</li> <li>Cross-check rules (strict by default):</li> <li>all manifest variables must exist in Copier</li> <li>no undeclared Copier variables unless <code>extra_variables=true</code></li> <li>default mismatch = warning (upgraded to error in <code>--strict</code>)</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#trust-model","title":"Trust Model","text":"<ul> <li>Trust is split between content and hook execution.</li> <li>Defaults: allow content from bundled/local; allow hooks from bundled only.</li> <li><code>--allow-hooks</code> overrides (explicit).</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#cli-contract-v1","title":"CLI Contract (v1)","text":"<ul> <li><code>pantsagon init &lt;repo&gt;</code></li> <li><code>--lang python</code> (required)</li> <li><code>--services a,b</code></li> <li><code>--feature openapi --feature docker</code> (alias <code>--with</code>)</li> <li><code>--augmented-coding {agents|claude|gemini|none}</code> (creates AGENTS.md or equivalent)</li> <li><code>--non-interactive</code></li> <li><code>--strict</code></li> <li><code>--renderer copier</code></li> <li><code>--json</code></li> <li><code>pantsagon add service &lt;name&gt;</code></li> <li><code>--lang python</code></li> <li><code>--feature openapi --feature docker</code></li> <li><code>--strict</code></li> <li><code>--json</code></li> <li><code>pantsagon validate</code></li> <li><code>--exec</code></li> <li><code>--strict</code></li> <li><code>--json</code></li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#json-output","title":"JSON Output","text":"<ul> <li>Always include <code>result_schema_version</code>, <code>timestamp</code>, <code>command</code>, <code>args</code>, <code>exit_code</code>.</li> <li><code>Diagnostic</code> is stable with structured <code>location</code> and deterministic <code>id</code>.</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Deterministic mode via <code>--deterministic</code> or <code>PANTSAGON_DETERMINISTIC=1</code>.</li> <li>Unit tests: domain invariants, pack resolution, naming rules, exit-code precedence.</li> <li>Adapter tests: Copier failure mapping, workspace commit/rollback, policy checks.</li> <li>Pack tests (gated on any change under <code>packs/**</code>):   1) schema validation   2) manifest\u2194Copier cross-check   3) render smoke-test</li> <li>E2E tests: verify key files/paths and invariants (avoid full-tree diffs by default).</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#versioning-compatibility","title":"Versioning &amp; Compatibility","text":"<ul> <li>Tool and packs use SemVer independently.</li> <li>Packs declare compatibility ranges in <code>pack.yaml</code>.</li> <li>Bundled pack compatibility is verified in CI.</li> <li>Pack SemVer rules:</li> <li>Patch: docs/typos, non-functional tweaks</li> <li>Minor: additive variables with defaults, additive files</li> <li>Major: variable removals, path renames, behavior changes</li> <li>Schema versions are file-based (<code>pack.schema.v1.json</code>).</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-design/#implementation-notes-v1","title":"Implementation Notes (v1)","text":"<ul> <li>Bundled packs: core/python/openapi/docker.</li> <li>Local pack catalog adapter reads <code>pack.yaml</code> from path.</li> <li>Renderer adapter uses Copier; no Copier concepts leak into ports.</li> <li>Workspace adapter provides atomic staging + commit.</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/","title":"Pantsagon CLI Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement Pantsagon v1 as a hexagonal, pack\u2011based scaffolding CLI (Typer + Copier) that generates enforced Pants hexagonal monorepos with OpenAPI + Docker packs.</p> <p>Architecture: Hexagonal core (domain/application) with ports/adapters. Packs are tool\u2011agnostic via <code>pack.yaml</code> validated by schema. Copier renders templates. <code>.pantsagon.toml</code> is the single source of truth for repo state. CLI is a thin adapter.</p> <p>Tech Stack: Python 3.12, Typer, Copier, PyYAML, jsonschema, pytest.</p>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-1-project-skeleton-tooling-bootstrap","title":"Task 1: Project skeleton + tooling bootstrap","text":"<p>Files: - Create: <code>pyproject.toml</code> - Create: <code>pantsagon/__init__.py</code> - Create: <code>pantsagon/domain/__init__.py</code> - Create: <code>pantsagon/application/__init__.py</code> - Create: <code>pantsagon/ports/__init__.py</code> - Create: <code>pantsagon/adapters/__init__.py</code> - Create: <code>pantsagon/entrypoints/__init__.py</code> - Create: <code>tests/__init__.py</code></p> <p>Step 1: Write failing test (package import smoke)</p> <pre><code># tests/test_imports.py\n\ndef test_imports():\n    import pantsagon\n    assert pantsagon.__package__ == \"pantsagon\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/test_imports.py -q</code> Expected: FAIL (module not found)</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/__init__.py\n__all__ = [\"__version__\"]\n__version__ = \"0.1.0\"\n</code></pre> <pre><code># pyproject.toml\n[build-system]\nrequires = [\"hatchling&gt;=1.21.0\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"pantsagon\"\nversion = \"0.1.0\"\ndescription = \"Hexagonal monorepos, generated with enforcement.\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n  \"typer&gt;=0.12\",\n  \"copier&gt;=9.0\",\n  \"pyyaml&gt;=6.0\",\n  \"jsonschema&gt;=4.22\",\n  \"tomli-w&gt;=1.0\",\n  \"rich&gt;=13.7\",\n]\n\n[project.optional-dependencies]\ndev = [\"pytest&gt;=8.0\", \"pytest-cov&gt;=5.0\"]\n\n[project.scripts]\npantsagon = \"pantsagon.entrypoints.cli:app\"\n\n[tool.pytest.ini_options]\naddopts = \"-q\"\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/test_imports.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pyproject.toml pantsagon/__init__.py tests/test_imports.py\n\ngit commit -m \"chore: bootstrap python package\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-2-domain-primitives-diagnostic-result-location-packref","title":"Task 2: Domain primitives (Diagnostic, Result, Location, PackRef)","text":"<p>Files: - Create: <code>pantsagon/domain/diagnostics.py</code> - Create: <code>pantsagon/domain/result.py</code> - Create: <code>pantsagon/domain/pack.py</code> - Test: <code>tests/domain/test_diagnostics.py</code> - Test: <code>tests/domain/test_result.py</code> - Test: <code>tests/domain/test_packref.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/domain/test_diagnostics.py\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity, FileLocation\n\ndef test_diagnostic_id_is_deterministic():\n    d1 = Diagnostic(code=\"X\", rule=\"r\", severity=Severity.ERROR, message=\"m\", location=FileLocation(\"a.txt\", 1, 2))\n    d2 = Diagnostic(code=\"X\", rule=\"r\", severity=Severity.ERROR, message=\"m\", location=FileLocation(\"a.txt\", 1, 2))\n    assert d1.id == d2.id\n</code></pre> <pre><code># tests/domain/test_result.py\nfrom pantsagon.domain.result import Result\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\n\ndef test_exit_code_precedence_exec_over_validation():\n    r = Result(diagnostics=[\n        Diagnostic(code=\"VAL\", rule=\"r\", severity=Severity.ERROR, message=\"v\"),\n        Diagnostic(code=\"EXEC\", rule=\"r\", severity=Severity.ERROR, message=\"e\", is_execution=True),\n    ])\n    assert r.exit_code == 3\n</code></pre> <pre><code># tests/domain/test_packref.py\nfrom pantsagon.domain.pack import PackRef\n\ndef test_packref_supports_future_fields():\n    ref = PackRef(id=\"pantsagon.core\", version=\"1.0.0\", source=\"bundled\", location=None, git_ref=None, commit=None, digest=None, subdir=None)\n    assert ref.source == \"bundled\"\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>pytest tests/domain/test_diagnostics.py tests/domain/test_result.py tests/domain/test_packref.py -q</code> Expected: FAIL (imports missing)</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/domain/diagnostics.py\nfrom __future__ import annotations\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport hashlib\nfrom typing import Any\n\nclass Severity(str, Enum):\n    ERROR = \"error\"\n    WARN = \"warn\"\n    INFO = \"info\"\n\n@dataclass(frozen=True)\nclass Location:\n    kind: str\n\n@dataclass(frozen=True)\nclass FileLocation(Location):\n    path: str\n    line: int | None = None\n    col: int | None = None\n    def __init__(self, path: str, line: int | None = None, col: int | None = None):\n        object.__setattr__(self, \"kind\", \"file\")\n        object.__setattr__(self, \"path\", path)\n        object.__setattr__(self, \"line\", line)\n        object.__setattr__(self, \"col\", col)\n\n@dataclass(frozen=True)\nclass Diagnostic:\n    code: str\n    rule: str\n    severity: Severity\n    message: str\n    location: Location | None = None\n    hint: str | None = None\n    details: dict[str, Any] | None = None\n    is_execution: bool = False\n    id: str = field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        raw = f\"{self.code}|{self.rule}|{self.severity}|{self.message}|{self.location}\"\n        object.__setattr__(self, \"id\", hashlib.sha256(raw.encode()).hexdigest()[:12])\n</code></pre> <pre><code># pantsagon/domain/result.py\nfrom dataclasses import dataclass, field\nfrom typing import Generic, TypeVar\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\n\nT = TypeVar(\"T\")\n\n@dataclass\nclass Result(Generic[T]):\n    value: T | None = None\n    diagnostics: list[Diagnostic] = field(default_factory=list)\n    artifacts: list[dict] = field(default_factory=list)\n\n    @property\n    def exit_code(self) -&gt; int:\n        has_exec = any(d.is_execution and d.severity == Severity.ERROR for d in self.diagnostics)\n        has_val = any((not d.is_execution) and d.severity == Severity.ERROR for d in self.diagnostics)\n        if has_exec:\n            return 3\n        if has_val:\n            return 2\n        return 0\n</code></pre> <pre><code># pantsagon/domain/pack.py\nfrom dataclasses import dataclass\nfrom typing import Literal\n\nPackSource = Literal[\"bundled\", \"local\", \"git\", \"registry\"]\n\n@dataclass(frozen=True)\nclass PackRef:\n    id: str\n    version: str\n    source: PackSource\n    location: str | None = None\n    git_ref: str | None = None\n    commit: str | None = None\n    digest: str | None = None\n    subdir: str | None = None\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/domain/test_diagnostics.py tests/domain/test_result.py tests/domain/test_packref.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/domain tests/domain\ngit commit -m \"feat: add domain primitives\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-3-pack-schema-manifest-parsing-copier-cross-check","title":"Task 3: Pack schema + manifest parsing + Copier cross-check","text":"<p>Files: - Create: <code>schemas/pack.schema.v1.json</code> - Create: <code>pantsagon/application/pack_validation.py</code> - Create: <code>pantsagon/adapters/policy/pack_validator.py</code> - Test: <code>tests/pack/test_pack_schema.py</code> - Test: <code>tests/pack/test_copier_crosscheck.py</code> - Fixture: <code>tests/fixtures/packs/minimal/pack.yaml</code> - Fixture: <code>tests/fixtures/packs/minimal/copier.yml</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/pack/test_pack_schema.py\nfrom pantsagon.application.pack_validation import validate_pack\n\n\ndef test_manifest_schema_validation(tmp_path):\n    pack = tmp_path / \"pack\"\n    pack.mkdir()\n    (pack / \"pack.yaml\").write_text(\"id: x\\nversion: 1.0.0\\n\")\n    (pack / \"copier.yml\").write_text(\"_min_copier_version: '9.0'\\n\")\n    result = validate_pack(pack)\n    assert any(d.code == \"PACK_SCHEMA_INVALID\" for d in result.diagnostics)\n</code></pre> <pre><code># tests/pack/test_copier_crosscheck.py\nfrom pantsagon.application.pack_validation import validate_pack\n\n\ndef test_copier_crosscheck_detects_undeclared_var(tmp_path):\n    pack = tmp_path / \"pack\"\n    pack.mkdir()\n    (pack / \"pack.yaml\").write_text(\"id: x\\nversion: 1.0.0\\nvariables: [{name: service_name, type: string}]\\n\")\n    (pack / \"copier.yml\").write_text(\"service_name: {type: str}\\nextra_var: {type: str}\\n\")\n    result = validate_pack(pack)\n    assert any(d.code == \"PACK_COPIER_UNDECLARED_VAR\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>pytest tests/pack/test_pack_schema.py tests/pack/test_copier_crosscheck.py -q</code> Expected: FAIL (missing validator)</p> <p>Step 3: Write minimal implementation</p> <pre><code>// schemas/pack.schema.v1.json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"version\"],\n  \"properties\": {\n    \"id\": {\"type\": \"string\"},\n    \"version\": {\"type\": \"string\"},\n    \"description\": {\"type\": \"string\"},\n    \"variables\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"name\", \"type\"],\n        \"properties\": {\n          \"name\": {\"type\": \"string\"},\n          \"type\": {\"type\": \"string\"},\n          \"default\": {}\n        }\n      }\n    }\n  }\n}\n</code></pre> <pre><code># pantsagon/adapters/policy/pack_validator.py\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\nimport yaml\nimport jsonschema\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\n\nSCHEMA_PATH = Path(__file__).resolve().parents[2] / \"schemas\" / \"pack.schema.v1.json\"\n\n\ndef load_manifest(pack_dir: Path) -&gt; dict:\n    return yaml.safe_load((pack_dir / \"pack.yaml\").read_text()) or {}\n\n\ndef load_copier_vars(pack_dir: Path) -&gt; set[str]:\n    data = yaml.safe_load((pack_dir / \"copier.yml\").read_text()) or {}\n    return {k for k in data.keys() if not k.startswith(\"_\")}\n\n\ndef validate_manifest_schema(manifest: dict) -&gt; list[Diagnostic]:\n    schema = json.loads(SCHEMA_PATH.read_text())\n    try:\n        jsonschema.validate(manifest, schema)\n        return []\n    except jsonschema.ValidationError as e:\n        return [Diagnostic(code=\"PACK_SCHEMA_INVALID\", rule=\"pack.schema\", severity=Severity.ERROR, message=str(e))]\n\n\ndef crosscheck_variables(manifest: dict, copier_vars: set[str]) -&gt; list[Diagnostic]:\n    declared = {v[\"name\"] for v in manifest.get(\"variables\", [])}\n    diagnostics: list[Diagnostic] = []\n    undeclared = copier_vars - declared\n    for var in sorted(undeclared):\n        diagnostics.append(Diagnostic(code=\"PACK_COPIER_UNDECLARED_VAR\", rule=\"pack.copier\", severity=Severity.ERROR, message=f\"Undeclared variable: {var}\"))\n    return diagnostics\n</code></pre> <pre><code># pantsagon/application/pack_validation.py\nfrom pathlib import Path\nfrom pantsagon.domain.result import Result\nfrom pantsagon.adapters.policy.pack_validator import load_manifest, load_copier_vars, validate_manifest_schema, crosscheck_variables\n\n\ndef validate_pack(pack_path: Path) -&gt; Result[dict]:\n    manifest = load_manifest(pack_path)\n    copier_vars = load_copier_vars(pack_path)\n    diags = []\n    diags.extend(validate_manifest_schema(manifest))\n    diags.extend(crosscheck_variables(manifest, copier_vars))\n    return Result(value=manifest, diagnostics=diags)\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/pack/test_pack_schema.py tests/pack/test_copier_crosscheck.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add schemas pantsagon/application/pack_validation.py pantsagon/adapters/policy/pack_validator.py tests/pack\ngit commit -m \"feat: add pack schema validation\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-4-ports-adaptererror-taxonomy","title":"Task 4: Ports + AdapterError taxonomy","text":"<p>Files: - Create: <code>pantsagon/ports/pack_catalog.py</code> - Create: <code>pantsagon/ports/renderer.py</code> - Create: <code>pantsagon/ports/workspace.py</code> - Create: <code>pantsagon/ports/policy_engine.py</code> - Create: <code>pantsagon/ports/command_runner.py</code> - Create: <code>pantsagon/adapters/errors.py</code> - Test: <code>tests/adapters/test_adapter_errors.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/adapters/test_adapter_errors.py\nfrom pantsagon.adapters.errors import RendererExecutionError\n\ndef test_adapter_error_has_message_and_details():\n    err = RendererExecutionError(\"boom\", details={\"x\": 1})\n    assert \"boom\" in str(err)\n    assert err.details[\"x\"] == 1\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/adapters/test_adapter_errors.py -q</code> Expected: FAIL (missing class)</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/adapters/errors.py\nfrom dataclasses import dataclass\nfrom typing import Any\n\n@dataclass\nclass AdapterError(Exception):\n    message: str\n    details: dict[str, Any] | None = None\n    hint: str | None = None\n    cause: Exception | None = None\n\n    def __str__(self) -&gt; str:\n        return self.message\n\nclass PackFetchError(AdapterError):\n    pass\n\nclass PackReadError(AdapterError):\n    pass\n\nclass PackParseError(AdapterError):\n    pass\n\nclass RendererTemplateError(AdapterError):\n    pass\n\nclass RendererExecutionError(AdapterError):\n    pass\n\nclass WorkspaceTransactionError(AdapterError):\n    pass\n\nclass WorkspaceCommitError(AdapterError):\n    pass\n\nclass CommandNotFound(AdapterError):\n    pass\n\nclass CommandFailed(AdapterError):\n    pass\n\nclass CommandTimeout(AdapterError):\n    pass\n</code></pre> <pre><code># pantsagon/ports/renderer.py\nfrom typing import Protocol\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom pantsagon.domain.pack import PackRef\n\n@dataclass\nclass RenderRequest:\n    pack: PackRef\n    pack_path: Path\n    staging_dir: Path\n    answers: dict\n    allow_hooks: bool\n\n@dataclass\nclass RenderOutcome:\n    rendered_paths: list[Path]\n    warnings: list[str]\n\nclass RendererPort(Protocol):\n    def render(self, request: RenderRequest) -&gt; RenderOutcome: ...\n</code></pre> <p>(Implement similar Protocols for pack_catalog, workspace, policy_engine, command_runner.)</p> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/adapters/test_adapter_errors.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/ports pantsagon/adapters/errors.py tests/adapters/test_adapter_errors.py\n\ngit commit -m \"feat: add ports and adapter error taxonomy\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-5-pack-catalog-adapters-bundled-local","title":"Task 5: Pack catalog adapters (bundled + local)","text":"<p>Files: - Create: <code>pantsagon/adapters/pack_catalog/bundled.py</code> - Create: <code>pantsagon/adapters/pack_catalog/local.py</code> - Test: <code>tests/adapters/test_pack_catalog.py</code> - Fixture: <code>tests/fixtures/packs/minimal/pack.yaml</code> - Fixture: <code>tests/fixtures/packs/minimal/copier.yml</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/adapters/test_pack_catalog.py\nfrom pathlib import Path\nfrom pantsagon.adapters.pack_catalog.local import LocalPackCatalog\n\n\ndef test_local_pack_catalog_loads_manifest(tmp_path):\n    pack = tmp_path / \"pack\"\n    pack.mkdir()\n    (pack / \"pack.yaml\").write_text(\"id: x\\nversion: 1.0.0\\n\")\n    (pack / \"copier.yml\").write_text(\"_min_copier_version: '9.0'\\n\")\n    catalog = LocalPackCatalog()\n    manifest = catalog.load_manifest(pack)\n    assert manifest[\"id\"] == \"x\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/adapters/test_pack_catalog.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/adapters/pack_catalog/local.py\nfrom pathlib import Path\nimport yaml\n\nclass LocalPackCatalog:\n    def load_manifest(self, pack_dir: Path) -&gt; dict:\n        return yaml.safe_load((pack_dir / \"pack.yaml\").read_text()) or {}\n</code></pre> <pre><code># pantsagon/adapters/pack_catalog/bundled.py\nfrom pathlib import Path\n\nclass BundledPackCatalog:\n    def __init__(self, root: Path) -&gt; None:\n        self.root = root\n\n    def get_pack_path(self, pack_id: str) -&gt; Path:\n        return self.root / pack_id.split(\".\")[-1]\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/adapters/test_pack_catalog.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/adapters/pack_catalog tests/adapters/test_pack_catalog.py\n\ngit commit -m \"feat: add pack catalog adapters\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-6-renderer-adapter-copier","title":"Task 6: Renderer adapter (Copier)","text":"<p>Files: - Create: <code>pantsagon/adapters/renderer/copier_renderer.py</code> - Test: <code>tests/adapters/test_renderer_copier.py</code> - Fixture: <code>tests/fixtures/packs/minimal/templates/README.md.jinja</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/adapters/test_renderer_copier.py\nfrom pathlib import Path\nfrom pantsagon.adapters.renderer.copier_renderer import CopierRenderer\nfrom pantsagon.domain.pack import PackRef\nfrom pantsagon.ports.renderer import RenderRequest\n\n\ndef test_copier_renders_template(tmp_path):\n    pack = tmp_path / \"pack\"\n    (pack / \"templates\").mkdir(parents=True)\n    (pack / \"pack.yaml\").write_text(\"id: x\\nversion: 1.0.0\\nvariables: [{name: name, type: string}]\\n\")\n    (pack / \"copier.yml\").write_text(\"name: {type: str}\\n_templates_suffix: '.jinja'\\n_subdirectory: 'templates'\\n\")\n    (pack / \"templates\" / \"README.md.jinja\").write_text(\"Hello {{ name }}\")\n    out = tmp_path / \"out\"\n    out.mkdir()\n    req = RenderRequest(pack=PackRef(id=\"x\", version=\"1.0.0\", source=\"local\"), pack_path=pack, staging_dir=out, answers={\"name\": \"World\"}, allow_hooks=False)\n    result = CopierRenderer().render(req)\n    assert (out / \"README.md\").read_text() == \"Hello World\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/adapters/test_renderer_copier.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/adapters/renderer/copier_renderer.py\nfrom copier import run_copy\nfrom pantsagon.adapters.errors import RendererExecutionError\nfrom pantsagon.ports.renderer import RenderRequest, RenderOutcome\n\nclass CopierRenderer:\n    def render(self, request: RenderRequest) -&gt; RenderOutcome:\n        try:\n            run_copy(\n                str(request.pack_path),\n                str(request.staging_dir),\n                data=request.answers,\n                unsafe=request.allow_hooks,\n            )\n        except Exception as e:  # Copier raises various exceptions\n            raise RendererExecutionError(\"Copier failed\", details={\"pack\": request.pack.id}, cause=e)\n        return RenderOutcome(rendered_paths=[request.staging_dir], warnings=[])\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/adapters/test_renderer_copier.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/adapters/renderer tests/adapters/test_renderer_copier.py\n\ngit commit -m \"feat: add copier renderer adapter\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-7-workspace-adapter-with-staging-atomic-commit-init-add-service","title":"Task 7: Workspace adapter with staging + atomic commit (init + add service)","text":"<p>Files: - Create: <code>pantsagon/adapters/workspace/filesystem.py</code> - Test: <code>tests/adapters/test_workspace.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/adapters/test_workspace.py\nfrom pathlib import Path\nfrom pantsagon.adapters.workspace.filesystem import FilesystemWorkspace\n\n\ndef test_workspace_commit_writes_files(tmp_path):\n    ws = FilesystemWorkspace(tmp_path)\n    stage = ws.begin_transaction()\n    (stage / \"hello.txt\").write_text(\"hi\")\n    ws.commit(stage)\n    assert (tmp_path / \"hello.txt\").read_text() == \"hi\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/adapters/test_workspace.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/adapters/workspace/filesystem.py\nfrom pathlib import Path\nimport shutil\nimport tempfile\nfrom pantsagon.adapters.errors import WorkspaceCommitError\n\nclass FilesystemWorkspace:\n    def __init__(self, root: Path) -&gt; None:\n        self.root = root\n\n    def begin_transaction(self) -&gt; Path:\n        return Path(tempfile.mkdtemp(prefix=\"pantsagon-stage-\", dir=self.root.parent))\n\n    def commit(self, stage: Path) -&gt; None:\n        try:\n            for path in stage.rglob(\"*\"):\n                rel = path.relative_to(stage)\n                dest = self.root / rel\n                if path.is_dir():\n                    dest.mkdir(parents=True, exist_ok=True)\n                else:\n                    dest.parent.mkdir(parents=True, exist_ok=True)\n                    shutil.copy2(path, dest)\n        except Exception as e:\n            raise WorkspaceCommitError(\"Workspace commit failed\", cause=e)\n        finally:\n            shutil.rmtree(stage, ignore_errors=True)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/adapters/test_workspace.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/adapters/workspace tests/adapters/test_workspace.py\n\ngit commit -m \"feat: add filesystem workspace adapter\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-8-application-use-cases-init-add-service-validate","title":"Task 8: Application use-cases (init / add service / validate)","text":"<p>Files: - Create: <code>pantsagon/application/init_repo.py</code> - Create: <code>pantsagon/application/add_service.py</code> - Create: <code>pantsagon/application/validate_repo.py</code> - Test: <code>tests/application/test_init_repo.py</code> - Test: <code>tests/application/test_add_service.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/application/test_init_repo.py\nfrom pathlib import Path\nfrom pantsagon.application.init_repo import init_repo\n\n\ndef test_init_repo_writes_lock(tmp_path, monkeypatch):\n    result = init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"monitors\"], features=[\"openapi\"], renderer=\"copier\")\n    assert (tmp_path / \".pantsagon.toml\").exists()\n</code></pre> <pre><code># tests/application/test_add_service.py\nfrom pathlib import Path\nfrom pantsagon.application.add_service import add_service\n\n\ndef test_add_service_fails_on_existing(tmp_path):\n    (tmp_path / \".pantsagon.toml\").write_text(\"[tool]\\nname='pantsagon'\\nversion='0.1.0'\\n\")\n    svc_dir = tmp_path / \"services\" / \"foo\"\n    svc_dir.mkdir(parents=True)\n    result = add_service(repo_path=tmp_path, name=\"foo\", lang=\"python\")\n    assert any(d.code == \"SERVICE_EXISTS\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>pytest tests/application/test_init_repo.py tests/application/test_add_service.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/application/init_repo.py\nfrom pathlib import Path\nfrom pantsagon.domain.result import Result\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\nimport tomli_w\n\n\ndef init_repo(repo_path: Path, languages: list[str], services: list[str], features: list[str], renderer: str) -&gt; Result[None]:\n    lock = {\n        \"tool\": {\"name\": \"pantsagon\", \"version\": \"0.1.0\"},\n        \"settings\": {\"renderer\": renderer, \"strict\": False, \"strict_manifest\": True, \"allow_hooks\": False},\n        \"selection\": {\"languages\": languages, \"features\": features, \"services\": services, \"augmented_coding\": \"none\"},\n        \"resolved\": {\"packs\": [], \"answers\": {}},\n    }\n    (repo_path / \".pantsagon.toml\").write_text(tomli_w.dumps(lock))\n    return Result()\n</code></pre> <pre><code># pantsagon/application/add_service.py\nfrom pathlib import Path\nfrom pantsagon.domain.result import Result\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\n\n\ndef add_service(repo_path: Path, name: str, lang: str) -&gt; Result[None]:\n    svc_dir = repo_path / \"services\" / name\n    if svc_dir.exists():\n        return Result(diagnostics=[Diagnostic(code=\"SERVICE_EXISTS\", rule=\"service.name\", severity=Severity.ERROR, message=\"Service already exists\")])\n    return Result()\n</code></pre> <pre><code># pantsagon/application/validate_repo.py\nfrom pathlib import Path\nfrom pantsagon.domain.result import Result\n\n\ndef validate_repo(repo_path: Path) -&gt; Result[None]:\n    return Result()\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/application/test_init_repo.py tests/application/test_add_service.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application tests/application\n\ngit commit -m \"feat: add minimal use-case scaffolds\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-9-cli-entrypoint-with-typer-json-output","title":"Task 9: CLI entrypoint with Typer + JSON output","text":"<p>Files: - Create: <code>pantsagon/entrypoints/cli.py</code> - Test: <code>tests/entrypoints/test_cli_init.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/entrypoints/test_cli_init.py\nfrom typer.testing import CliRunner\nfrom pantsagon.entrypoints.cli import app\n\n\ndef test_cli_init_writes_lock(tmp_path):\n    runner = CliRunner()\n    result = runner.invoke(app, [\"init\", str(tmp_path), \"--lang\", \"python\", \"--services\", \"monitors\", \"--feature\", \"openapi\"])\n    assert result.exit_code == 0\n    assert (tmp_path / \".pantsagon.toml\").exists()\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/entrypoints/test_cli_init.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/entrypoints/cli.py\nimport typer\nfrom pathlib import Path\nfrom pantsagon.application.init_repo import init_repo\n\napp = typer.Typer(add_completion=False)\n\n@app.command()\ndef init(repo: Path, lang: str = typer.Option(...), services: str = \"\", feature: list[str] = typer.Option(None)):\n    features = feature or []\n    svc_list = [s for s in services.split(\",\") if s]\n    init_repo(repo, [lang], svc_list, features, renderer=\"copier\")\n    raise typer.Exit(0)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/entrypoints/test_cli_init.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/entrypoints tests/entrypoints\n\ngit commit -m \"feat: add minimal typer cli\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-10-bundled-packs-corepythonopenapidocker-pack-tests","title":"Task 10: Bundled packs (core/python/openapi/docker) + pack tests","text":"<p>Files: - Create: <code>packs/core/pack.yaml</code>, <code>packs/core/copier.yml</code>, <code>packs/core/templates/...</code> - Create: <code>packs/python/pack.yaml</code>, <code>packs/python/copier.yml</code>, <code>packs/python/templates/...</code> - Create: <code>packs/openapi/pack.yaml</code>, <code>packs/openapi/copier.yml</code>, <code>packs/openapi/templates/...</code> - Create: <code>packs/docker/pack.yaml</code>, <code>packs/docker/copier.yml</code>, <code>packs/docker/templates/...</code> - Test: <code>tests/packs/test_bundled_packs.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/packs/test_bundled_packs.py\nfrom pathlib import Path\nfrom pantsagon.application.pack_validation import validate_pack\n\n\ndef test_all_bundled_packs_validate():\n    packs_dir = Path(__file__).resolve().parents[2] / \"packs\"\n    for pack in [\"core\", \"python\", \"openapi\", \"docker\"]:\n        result = validate_pack(packs_dir / pack)\n        assert not [d for d in result.diagnostics if d.severity.value == \"error\"]\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/packs/test_bundled_packs.py -q</code> Expected: FAIL (missing packs)</p> <p>Step 3: Write minimal templates</p> <p>Create minimal <code>pack.yaml</code> + <code>copier.yml</code> and core skeleton templates for each pack. Example for core:</p> <pre><code># packs/core/pack.yaml\nid: pantsagon.core\nversion: 1.0.0\ndescription: Core monorepo skeleton\nvariables:\n  - name: repo_name\n    type: string\n</code></pre> <pre><code># packs/core/copier.yml\n_min_copier_version: \"9.0.0\"\n_subdirectory: \"templates\"\n_templates_suffix: \".jinja\"\nrepo_name:\n  type: str\n  default: \"repo\"\n</code></pre> <pre><code># packs/core/templates/pants.toml.jinja\n[GLOBAL]\npants_version = \"2.30.0\"\n</code></pre> <p>Repeat for python/openapi/docker with minimal placeholders.</p> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/packs/test_bundled_packs.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add packs tests/packs/test_bundled_packs.py\n\ngit commit -m \"feat: add bundled packs and pack tests\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-11-e2e-init-test-deterministic-mode","title":"Task 11: E2E init test (deterministic mode)","text":"<p>Files: - Test: <code>tests/e2e/test_init_e2e.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/e2e/test_init_e2e.py\nfrom pathlib import Path\nfrom pantsagon.entrypoints.cli import app\nfrom typer.testing import CliRunner\n\n\ndef test_init_generates_core_files(tmp_path, monkeypatch):\n    monkeypatch.setenv(\"PANTSAGON_DETERMINISTIC\", \"1\")\n    runner = CliRunner()\n    result = runner.invoke(app, [\"init\", str(tmp_path), \"--lang\", \"python\", \"--services\", \"monitors\", \"--feature\", \"openapi\", \"--feature\", \"docker\"])\n    assert result.exit_code == 0\n    assert (tmp_path / \"pants.toml\").exists()\n    assert (tmp_path / \".pantsagon.toml\").exists()\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/e2e/test_init_e2e.py -q</code> Expected: FAIL</p> <p>Step 3: Implement deterministic mode hook</p> <p>Add a global helper in <code>pantsagon/domain/determinism.py</code> to fix timestamps or skip them, and ensure CLI honors <code>PANTSAGON_DETERMINISTIC=1</code> by passing a deterministic flag into render/use-cases (even if no timestamps are emitted in v1).</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/e2e/test_init_e2e.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tests/e2e/test_init_e2e.py pantsagon/domain/determinism.py\n\ngit commit -m \"test: add deterministic e2e init\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-cli-plan/#task-12-polish-cli-flags-augmented-coding-option","title":"Task 12: Polish CLI flags + augmented-coding option","text":"<p>Files: - Modify: <code>pantsagon/entrypoints/cli.py</code> - Modify: <code>pantsagon/application/init_repo.py</code> - Test: <code>tests/entrypoints/test_cli_augmented.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/entrypoints/test_cli_augmented.py\nfrom typer.testing import CliRunner\nfrom pantsagon.entrypoints.cli import app\n\n\ndef test_augmented_coding_creates_agents_file(tmp_path):\n    runner = CliRunner()\n    result = runner.invoke(app, [\"init\", str(tmp_path), \"--lang\", \"python\", \"--augmented-coding\", \"agents\"])\n    assert result.exit_code == 0\n    assert (tmp_path / \"AGENTS.md\").exists()\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/entrypoints/test_cli_augmented.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Update <code>init_repo</code> to create AGENTS/CLAUDE/GEMINI file based on selection, and persist <code>selection.augmented_coding</code> in <code>.pantsagon.toml</code>.</p> <pre><code># pantsagon/application/init_repo.py (snippet)\naugmented = augmented_coding or \"none\"\nlock[\"selection\"][\"augmented_coding\"] = augmented\nif augmented == \"agents\":\n    (repo_path / \"AGENTS.md\").write_text(\"# AGENTS\\n\")\nelif augmented == \"claude\":\n    (repo_path / \"CLAUDE.md\").write_text(\"# CLAUDE\\n\")\nelif augmented == \"gemini\":\n    (repo_path / \"GEMINI.md\").write_text(\"# GEMINI\\n\")\n</code></pre> <p>Update CLI options:</p> <pre><code># pantsagon/entrypoints/cli.py (snippet)\naugmented_coding: str = typer.Option(\"none\", \"--augmented-coding\")\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/entrypoints/test_cli_augmented.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/init_repo.py pantsagon/entrypoints/cli.py tests/entrypoints/test_cli_augmented.py\n\ngit commit -m \"feat: add augmented coding file option\"\n</code></pre> <p>Plan complete and saved to <code>docs/plans/2026-01-10-pantsagon-cli-plan.md</code>.</p> <p>Two execution options:</p> <ol> <li>Subagent-Driven (this session) \u2014 I dispatch a fresh subagent per task, review between tasks.</li> <li>Parallel Session (separate) \u2014 Open a new session with executing-plans and batch execution.</li> </ol> <p>Which approach would you like?</p>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/","title":"Pantsagon M2 CLI Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Complete the v1 M2 CLI surface: add <code>add service</code>, <code>validate</code>, JSON output, and exit-code precedence, with README updates.</p> <p>Architecture: Extend the application layer with add/validate use-cases and validation helpers, wire into Typer CLI, and serialize Result objects for <code>--json</code>. Keep logic in application/domain, CLI thin.</p> <p>Tech Stack: Python 3.12, Typer, pytest.</p>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/#task-1-result-serialization-for-json-output","title":"Task 1: Result serialization for JSON output","text":"<p>Files: - Create: <code>pantsagon/application/result_serialization.py</code> - Modify: <code>pantsagon/domain/diagnostics.py</code> - Test: <code>tests/application/test_result_serialization.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/application/test_result_serialization.py\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity, FileLocation\nfrom pantsagon.domain.result import Result\nfrom pantsagon.application.result_serialization import serialize_result\n\n\ndef test_result_serializes_with_schema_version():\n    result = Result(diagnostics=[\n        Diagnostic(code=\"X\", rule=\"r\", severity=Severity.ERROR, message=\"m\", location=FileLocation(\"x.py\", 1, 2))\n    ])\n    data = serialize_result(result, command=\"init\", args=[\".\"])\n    assert data[\"result_schema_version\"] == 1\n    assert data[\"exit_code\"] == result.exit_code\n    assert data[\"diagnostics\"][0][\"location\"][\"path\"] == \"x.py\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/application/test_result_serialization.py -q</code> Expected: FAIL (module missing)</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/application/result_serialization.py\nfrom datetime import datetime, timezone\nfrom pantsagon.domain.result import Result\nfrom pantsagon.domain.diagnostics import Diagnostic, FileLocation\n\n\ndef _serialize_location(loc):\n    if loc is None:\n        return None\n    data = {\"kind\": loc.kind}\n    if isinstance(loc, FileLocation):\n        data.update({\"path\": loc.path, \"line\": loc.line, \"col\": loc.col})\n    return data\n\n\ndef serialize_result(result: Result, command: str, args: list[str]) -&gt; dict:\n    return {\n        \"result_schema_version\": 1,\n        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n        \"command\": command,\n        \"args\": args,\n        \"exit_code\": result.exit_code,\n        \"diagnostics\": [\n            {\n                \"id\": d.id,\n                \"code\": d.code,\n                \"rule\": d.rule,\n                \"severity\": d.severity.value,\n                \"message\": d.message,\n                \"location\": _serialize_location(d.location),\n                \"hint\": d.hint,\n                \"details\": d.details,\n                \"is_execution\": d.is_execution,\n            }\n            for d in result.diagnostics\n        ],\n        \"artifacts\": result.artifacts,\n    }\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/application/test_result_serialization.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/result_serialization.py tests/application/test_result_serialization.py\n\ngit commit -m \"feat: serialize results to json\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/#task-2-add-service-use-case-naming-idempotency","title":"Task 2: <code>add service</code> use-case (naming + idempotency)","text":"<p>Files: - Modify: <code>pantsagon/application/add_service.py</code> - Test: <code>tests/application/test_add_service_naming.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/application/test_add_service_naming.py\nfrom pantsagon.application.add_service import add_service\n\n\ndef test_add_service_rejects_bad_name(tmp_path):\n    (tmp_path / \".pantsagon.toml\").write_text(\"[tool]\\nname='pantsagon'\\nversion='0.1.0'\\n\")\n    result = add_service(repo_path=tmp_path, name=\"BadName\", lang=\"python\")\n    assert any(d.code == \"SERVICE_NAME_INVALID\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/application/test_add_service_naming.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Implement kebab-case validation and reserved-name checks in <code>add_service</code>. Return diagnostics with code <code>SERVICE_NAME_INVALID</code>.</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/application/test_add_service_naming.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/add_service.py tests/application/test_add_service_naming.py\n\ngit commit -m \"feat: validate service naming\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/#task-3-validate-use-case-lock-drift-pack-checks","title":"Task 3: <code>validate</code> use-case (lock drift + pack checks)","text":"<p>Files: - Modify: <code>pantsagon/application/validate_repo.py</code> - Test: <code>tests/application/test_validate_repo.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/application/test_validate_repo.py\nfrom pantsagon.application.validate_repo import validate_repo\n\n\ndef test_validate_repo_missing_lock(tmp_path):\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"LOCK_MISSING\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Add checks for <code>.pantsagon.toml</code>, produce diagnostics with <code>LOCK_MISSING</code>, and stub pack validation.</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/validate_repo.py tests/application/test_validate_repo.py\n\ngit commit -m \"feat: add validate use-case scaffold\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/#task-4-cli-wiring-for-add-service-and-validate-json-flag","title":"Task 4: CLI wiring for <code>add service</code> and <code>validate</code> + JSON flag","text":"<p>Files: - Modify: <code>pantsagon/entrypoints/cli.py</code> - Test: <code>tests/entrypoints/test_cli_validate.py</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/entrypoints/test_cli_validate.py\nfrom typer.testing import CliRunner\nfrom pantsagon.entrypoints.cli import app\n\n\ndef test_cli_validate_exits_nonzero_when_lock_missing(tmp_path):\n    runner = CliRunner()\n    result = runner.invoke(app, [\"validate\", \"--json\"])\n    assert result.exit_code != 0\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/entrypoints/test_cli_validate.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Wire <code>validate</code> to return JSON via <code>serialize_result</code> when <code>--json</code> is set.</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/entrypoints/test_cli_validate.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/entrypoints/cli.py tests/entrypoints/test_cli_validate.py\n\ngit commit -m \"feat: wire validate cli\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-m2-cli-plan/#task-5-readme-update-for-cli-surface","title":"Task 5: README update for CLI surface","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/docs/test_readme_cli_m2.py\nfrom pathlib import Path\n\n\ndef test_readme_mentions_validate_command():\n    text = Path(\"README.md\").read_text().lower()\n    assert \"pantsagon validate\" in text\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/docs/test_readme_cli_m2.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Update README CLI section with <code>add service</code> and <code>validate</code> usage and <code>--json</code> flag.</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/docs/test_readme_cli_m2.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add README.md tests/docs/test_readme_cli_m2.py\n\ngit commit -m \"docs: update readme for m2 cli\"\n</code></pre> <p>Plan complete and saved to <code>docs/plans/2026-01-10-pantsagon-m2-cli-plan.md</code>.</p> <p>Two execution options:</p> <ol> <li>Subagent-Driven (this session) \u2014 I dispatch a fresh subagent per task, review between tasks, fast iteration</li> <li>Parallel Session (separate) \u2014 Open new session with executing-plans and batch execution with checkpoints</li> </ol> <p>Which approach?</p>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/","title":"Pantsagon v1.0 Milestone Checklist","text":"<p>Goal: Reach a credible v1.0 release of Pantsagon with real pack rendering, complete CLI surface, and accurate docs.</p>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m0-documentation-licensing-baseline","title":"M0 \u2014 Documentation + Licensing Baseline","text":"<ul> <li>[ ] README reflects current state and planned features</li> <li>[ ] README explicitly states Apache License 2.0 (not MIT)</li> <li>[ ] <code>LICENSE</code> confirmed as Apache 2.0</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m1-pack-rendering-in-init-core-capability","title":"M1 \u2014 Pack Rendering in <code>init</code> (Core Capability)","text":"<ul> <li>[ ] Resolve pack selection: <code>core</code>, <code>python</code>, <code>openapi</code>, <code>docker</code></li> <li>[ ] Validate pack schema + manifest\u2194Copier variables</li> <li>[ ] Render packs into staging dir via Copier</li> <li>[ ] Atomic commit to repo</li> <li>[ ] <code>.pantsagon.toml</code> written into staged output</li> <li>[ ] E2E test verifies real skeleton files</li> <li>[ ] README updated to reflect rendering behavior</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m2-cli-surface-complete","title":"M2 \u2014 CLI Surface Complete","text":"<ul> <li>[ ] <code>pantsagon add service</code> implemented (naming rules, idempotent)</li> <li>[ ] <code>pantsagon validate</code> implemented (schema + lock drift + cross\u2011check)</li> <li>[ ] JSON output contract implemented</li> <li>[ ] Exit code precedence enforced</li> <li>[ ] README updated with full CLI usage</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m3-repo-lock-fidelity","title":"M3 \u2014 Repo Lock Fidelity","text":"<ul> <li>[ ] <code>.pantsagon.toml</code> split into <code>[tool]</code>, <code>[selection]</code>, <code>[resolved]</code>, <code>[settings]</code></li> <li>[ ] Persist pack refs (id/version/source + optional location/ref/digest)</li> <li>[ ] Persist resolved answers from Copier</li> <li>[ ] Validation detects lock drift</li> <li>[ ] README updated with lock structure</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m4-real-pack-content-hexagonal-skeleton","title":"M4 \u2014 Real Pack Content (Hexagonal Skeleton)","text":"<ul> <li>[ ] <code>core</code> pack: repo layout, CI scaffold, shared foundation/adapters</li> <li>[ ] <code>python</code> pack: hex layers + BUILD rules</li> <li>[ ] <code>openapi</code> pack: contract scaffolding + openapi targets</li> <li>[ ] <code>docker</code> pack: Dockerfile + <code>docker_image</code> target</li> <li>[ ] Pack tests cover schema + cross\u2011check + render smoke\u2011test</li> <li>[ ] README updated with example tree</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m5-policy-validation-hardening","title":"M5 \u2014 Policy + Validation Hardening","text":"<ul> <li>[ ] Naming rules: kebab\u2011case + reserved names</li> <li>[ ] Strictness tiers (<code>--strict</code> upgrades warnings \u2192 errors)</li> <li>[ ] Diagnostic codes + structured locations</li> <li>[ ] README updated with validation behavior</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-checklist/#m6-ci-release-readiness","title":"M6 \u2014 CI + Release Readiness","text":"<ul> <li>[x] GitHub Actions runs pytest + pack validation</li> <li>[x] Deterministic mode used in CI for reproducible tests</li> <li>[x] Release checklist for v1.0.0</li> <li>[x] README final pass</li> </ul>"},{"location":"plans/2026-01-10-pantsagon-v1-impl-plan/","title":"Pantsagon v1.0 Implementation Plan (Phase 1)","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Deliver M0 + M1 foundation: correct licensing/docs and real pack rendering in <code>init</code> with atomic staging.</p> <p>Architecture: Preserve hexagonal core. Add rendering workflow in application layer using existing ports/adapters. Update README to truthfully represent state.</p> <p>Tech Stack: Python 3.12, Typer, Copier, PyYAML, jsonschema, pytest.</p>"},{"location":"plans/2026-01-10-pantsagon-v1-impl-plan/#task-1-fix-readme-license-status-m0","title":"Task 1: Fix README license + status (M0)","text":"<p>Files: - Modify: <code>README.md</code> - Verify: <code>LICENSE</code></p> <p>Step 1: Write failing test (doc assertion)</p> <pre><code># tests/docs/test_readme_license.py\nfrom pathlib import Path\n\n\ndef test_readme_mentions_apache_license():\n    text = Path(\"README.md\").read_text().lower()\n    assert \"apache license 2.0\" in text\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/docs/test_readme_license.py -q</code> Expected: FAIL (license text missing)</p> <p>Step 3: Write minimal implementation</p> <p>Update <code>README.md</code>: - Add a \u201cLicense\u201d section that explicitly says Apache License 2.0. - Ensure status section reflects current capabilities (no misleading claims).</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/docs/test_readme_license.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add README.md tests/docs/test_readme_license.py\n\ngit commit -m \"docs: fix license statement in readme\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-v1-impl-plan/#task-2-init-renders-packs-into-staging-m1","title":"Task 2: <code>init</code> renders packs into staging (M1)","text":"<p>Files: - Modify: <code>pantsagon/application/init_repo.py</code> - Modify: <code>pantsagon/adapters/workspace/filesystem.py</code> - Create: <code>pantsagon/application/rendering.py</code> - Test: <code>tests/application/test_init_repo_renders.py</code> - Test: <code>tests/adapters/test_workspace_atomic.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/application/test_init_repo_renders.py\nfrom pathlib import Path\nfrom pantsagon.application.init_repo import init_repo\n\n\ndef test_init_repo_renders_core_pack(tmp_path):\n    result = init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"monitors\"], features=[\"openapi\", \"docker\"], renderer=\"copier\")\n    assert (tmp_path / \"pants.toml\").exists()\n    assert (tmp_path / \".pantsagon.toml\").exists()\n</code></pre> <pre><code># tests/adapters/test_workspace_atomic.py\nfrom pathlib import Path\nfrom pantsagon.adapters.workspace.filesystem import FilesystemWorkspace\n\n\ndef test_workspace_rollback_on_error(tmp_path, monkeypatch):\n    ws = FilesystemWorkspace(tmp_path)\n    stage = ws.begin_transaction()\n    (stage / \"file.txt\").write_text(\"data\")\n    monkeypatch.setattr(ws, \"_copy_file\", lambda *args, **kwargs: (_ for _ in ()).throw(RuntimeError(\"boom\")))\n    try:\n        ws.commit(stage)\n    except Exception:\n        pass\n    assert not (tmp_path / \"file.txt\").exists()\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>pytest tests/application/test_init_repo_renders.py tests/adapters/test_workspace_atomic.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <ul> <li>Add <code>application/rendering.py</code> to:</li> <li>resolve pack paths (bundled only in v1)</li> <li>validate packs with <code>validate_pack</code></li> <li>call Copier renderer per pack into staging</li> <li>Update <code>FilesystemWorkspace</code>:</li> <li>add <code>_copy_file</code> helper for test injection</li> <li>ensure commit cleans stage and does not partially apply on error</li> <li>Update <code>init_repo</code> to:</li> <li>use staging dir</li> <li>render packs via new helper</li> <li>write <code>.pantsagon.toml</code> into staging</li> <li>commit atomically</li> <li>remove placeholder <code>pants.toml</code> write</li> </ul> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>pytest tests/application/test_init_repo_renders.py tests/adapters/test_workspace_atomic.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/init_repo.py pantsagon/application/rendering.py pantsagon/adapters/workspace/filesystem.py tests/application/test_init_repo_renders.py tests/adapters/test_workspace_atomic.py\n\ngit commit -m \"feat: render packs during init\"\n</code></pre>"},{"location":"plans/2026-01-10-pantsagon-v1-impl-plan/#task-3-readme-update-for-rendered-init-m1","title":"Task 3: README update for rendered init (M1)","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Write failing test</p> <pre><code># tests/docs/test_readme_init_rendering.py\nfrom pathlib import Path\n\n\ndef test_readme_mentions_rendered_init():\n    text = Path(\"README.md\").read_text().lower()\n    assert \"renders\" in text and \"init\" in text\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/docs/test_readme_init_rendering.py -q</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <p>Update README \u201cQuick start / Status\u201d to state that <code>init</code> renders packs into a real repo skeleton.</p> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/docs/test_readme_init_rendering.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add README.md tests/docs/test_readme_init_rendering.py\n\ngit commit -m \"docs: update readme for rendered init\"\n</code></pre> <p>Plan complete and saved to <code>docs/plans/2026-01-10-pantsagon-v1-impl-plan.md</code>.</p> <p>Two execution options:</p> <ol> <li>Subagent-Driven (this session) \u2014 I dispatch a fresh subagent per task, review between tasks.</li> <li>Parallel Session (separate) \u2014 Open a new session with executing-plans and batch execution.</li> </ol> <p>Which approach would you like?</p>"},{"location":"plans/2026-01-10-policy-validation-hardening/","title":"Policy + Validation Hardening Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement M5 naming rules, strictness tiers, diagnostic codes/locations, and documentation updates with deterministic validation behavior.</p> <p>Architecture: Add a small domain validation module (pure, side\u2011effect free) for naming and strictness, then wire it into application orchestration (init/add/validate) with explicit phase ordering and strictness precedence. Schemas remain defensive guardrails; semantics live in domain validators.</p> <p>Tech Stack: Python 3.12, pytest, jsonschema, typer, copier.</p>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-1-add-strictness-upgradeable-support-in-diagnostics","title":"Task 1: Add strictness upgradeable support in diagnostics","text":"<p>Files: - Modify: <code>pantsagon/domain/diagnostics.py</code> - Create: <code>pantsagon/domain/strictness.py</code> - Test: <code>tests/domain/test_strictness.py</code></p> <p>Step 1: Write the failing test (@superpowers:test-driven-development)</p> <pre><code># tests/domain/test_strictness.py\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\nfrom pantsagon.domain.strictness import apply_strictness\n\ndef test_strictness_only_upgrades_upgradeable_warnings():\n    diags = [\n        Diagnostic(code=\"W_UP\", rule=\"r\", severity=Severity.WARN, message=\"warn\", upgradeable=True),\n        Diagnostic(code=\"W_NO\", rule=\"r\", severity=Severity.WARN, message=\"warn\", upgradeable=False),\n        Diagnostic(code=\"E\", rule=\"r\", severity=Severity.ERROR, message=\"err\"),\n    ]\n    strict = apply_strictness(diags, strict=True)\n    assert [d.severity.value for d in strict] == [\"error\", \"warn\", \"error\"]\n\n    non_strict = apply_strictness(diags, strict=False)\n    assert [d.severity.value for d in non_strict] == [\"warn\", \"warn\", \"error\"]\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/domain/test_strictness.py -q</code> Expected: FAIL with <code>ImportError</code> or <code>AttributeError</code> because <code>upgradeable</code> / <code>apply_strictness</code> do not exist yet.</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/domain/diagnostics.py\n@dataclass(frozen=True)\nclass Diagnostic:\n    ...\n    upgradeable: bool = False\n</code></pre> <pre><code># pantsagon/domain/strictness.py\nfrom __future__ import annotations\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\n\ndef apply_strictness(diagnostics: list[Diagnostic], strict: bool) -&gt; list[Diagnostic]:\n    if not strict:\n        return diagnostics\n    upgraded: list[Diagnostic] = []\n    for d in diagnostics:\n        if d.severity == Severity.WARN and d.upgradeable:\n            upgraded.append(d.__class__(**{**d.__dict__, \"severity\": Severity.ERROR}))\n        else:\n            upgraded.append(d)\n    return upgraded\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/domain/test_strictness.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/domain/diagnostics.py pantsagon/domain/strictness.py tests/domain/test_strictness.py\ngit commit -m \"feat: add upgradeable strictness handling\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-2-add-naming-validators-reserved-name-policy","title":"Task 2: Add naming validators + reserved name policy","text":"<p>Files: - Create: <code>pantsagon/domain/naming.py</code> - Modify: <code>pantsagon/domain/diagnostics.py</code> - Test: <code>tests/domain/test_naming.py</code></p> <p>Step 1: Write the failing test</p> <pre><code># tests/domain/test_naming.py\nfrom pantsagon.domain.naming import (\n    validate_service_name,\n    validate_pack_id,\n    validate_feature_name,\n    BUILTIN_RESERVED_SERVICES,\n)\n\ndef test_service_name_rules():\n    assert validate_service_name(\"my-service\", BUILTIN_RESERVED_SERVICES, set()) == []\n    assert validate_service_name(\"MyService\", BUILTIN_RESERVED_SERVICES, set())\n    assert validate_service_name(\"bad--name\", BUILTIN_RESERVED_SERVICES, set())\n    assert validate_service_name(\"trailing-\", BUILTIN_RESERVED_SERVICES, set())\n    assert validate_service_name(\"services\", BUILTIN_RESERVED_SERVICES, set())\n\n\ndef test_pack_id_rules():\n    assert validate_pack_id(\"pantsagon.core\") == []\n    assert validate_pack_id(\"Pantsagon.Core\")\n    assert validate_pack_id(\"nope\")\n\n\ndef test_feature_name_rules():\n    assert validate_feature_name(\"openapi\") == []\n    assert validate_feature_name(\"snake_case\") == []\n    assert validate_feature_name(\"bad.name\")\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/domain/test_naming.py -q</code> Expected: FAIL with <code>ImportError</code> because naming validators do not exist.</p> <p>Step 3: Write minimal implementation</p> <pre><code># pantsagon/domain/naming.py\nimport re\nimport keyword\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity\nfrom pantsagon.domain.diagnostics import Location\n\nSERVICE_PATTERN = re.compile(r\"^[a-z](?:[a-z0-9]*(-[a-z0-9]+)*)$\")\nPACK_ID_PATTERN = re.compile(r\"^[a-z][a-z0-9-]*(\\.[a-z][a-z0-9-]*)+$\")\nFEATURE_PATTERN = re.compile(r\"^[a-z][a-z0-9_-]*$\")\n\nBUILTIN_RESERVED_SERVICES = {\n    \"services\", \"shared\", \"tools\", \"docs\", \"packs\", \"schemas\", \"infra\", \"tests\",\n    \"domain\", \"ports\", \"application\", \"adapters\", \"entrypoints\",\n    \"pantsagon\", \"core\", \"foundation\",\n    *keyword.kwlist,\n}\n\nclass ValueLocation(Location):\n    value: str\n    field: str\n    def __init__(self, field: str, value: str):\n        object.__setattr__(self, \"kind\", \"value\")\n        object.__setattr__(self, \"field\", field)\n        object.__setattr__(self, \"value\", value)\n\n\ndef validate_service_name(name: str, builtins: set[str], project: set[str]) -&gt; list[Diagnostic]:\n    diags: list[Diagnostic] = []\n    if not SERVICE_PATTERN.match(name):\n        diags.append(Diagnostic(code=\"SERVICE_NAME_INVALID\", rule=\"naming.service.format\", severity=Severity.ERROR,\n            message=f\"Invalid service name: {name}\", location=ValueLocation(\"service\", name)))\n        return diags\n    if name in builtins:\n        diags.append(Diagnostic(code=\"SERVICE_NAME_RESERVED\", rule=\"naming.service.reserved\", severity=Severity.ERROR,\n            message=f\"Service name is reserved: {name}\", location=ValueLocation(\"service\", name), details={\"scope\":\"builtin\"}))\n    if name in project:\n        diags.append(Diagnostic(code=\"SERVICE_NAME_RESERVED\", rule=\"naming.service.reserved\", severity=Severity.ERROR,\n            message=f\"Service name is reserved: {name}\", location=ValueLocation(\"service\", name), details={\"scope\":\"project\"}))\n    return diags\n\n\ndef validate_pack_id(pack_id: str) -&gt; list[Diagnostic]:\n    if PACK_ID_PATTERN.match(pack_id):\n        return []\n    return [Diagnostic(code=\"PACK_ID_INVALID\", rule=\"naming.pack.id\", severity=Severity.ERROR,\n        message=f\"Invalid pack id: {pack_id}\", location=ValueLocation(\"pack.id\", pack_id))]\n\n\ndef validate_feature_name(feature: str) -&gt; list[Diagnostic]:\n    if FEATURE_PATTERN.match(feature) and \".\" not in feature:\n        return []\n    return [Diagnostic(code=\"FEATURE_NAME_INVALID\", rule=\"naming.feature.format\", severity=Severity.ERROR,\n        message=f\"Invalid feature name: {feature}\", location=ValueLocation(\"feature\", feature))]\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>pytest tests/domain/test_naming.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/domain/naming.py pantsagon/domain/diagnostics.py tests/domain/test_naming.py\ngit commit -m \"feat: add naming validators\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-3-add-new-diagnostic-codes-regenerate-reference-docs","title":"Task 3: Add new diagnostic codes + regenerate reference docs","text":"<p>Files: - Modify: <code>pantsagon/diagnostics/codes.yaml</code> - Modify (generated): <code>docs/reference/diagnostic-codes.md</code></p> <p>Step 1: Add codes to YAML</p> <p>Add entries for: - <code>SERVICE_NAME_INVALID</code> (error) - <code>SERVICE_NAME_RESERVED</code> (error) - <code>PACK_ID_INVALID</code> (error) - <code>FEATURE_NAME_INVALID</code> (error) - <code>FEATURE_NAME_SHADOWS_PACK</code> (warn, upgradeable) - <code>LOCK_INVALID</code> (error)</p> <p>Step 2: Regenerate docs</p> <p>Run: <code>python scripts/generate_diagnostic_codes.py</code> Expected: <code>Generated docs/reference/diagnostic-codes.md</code></p> <p>Step 3: Commit</p> <pre><code>git add pantsagon/diagnostics/codes.yaml docs/reference/diagnostic-codes.md\ngit commit -m \"docs: add naming diagnostics\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-4-load-repo-lock-strictness-precedence-validate_repo-phases","title":"Task 4: Load repo lock + strictness precedence + validate_repo phases","text":"<p>Files: - Create: <code>pantsagon/application/repo_lock.py</code> - Modify: <code>pantsagon/application/validate_repo.py</code> - Modify: <code>tests/application/test_validate_repo.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/application/test_validate_repo.py\nfrom pantsagon.application.validate_repo import validate_repo\n\ndef test_validate_repo_missing_lock(tmp_path):\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"LOCK_MISSING\" for d in result.diagnostics)\n\ndef test_validate_repo_invalid_lock(tmp_path):\n    (tmp_path / \".pantsagon.toml\").write_text(\"not=toml:::\")\n    result = validate_repo(repo_path=tmp_path)\n    assert any(d.code == \"LOCK_INVALID\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code> Expected: FAIL with missing <code>LOCK_INVALID</code> behavior.</p> <p>Step 3: Minimal implementation</p> <pre><code># pantsagon/application/repo_lock.py\nimport tomllib\nfrom pathlib import Path\nfrom pantsagon.domain.diagnostics import Diagnostic, Severity, FileLocation\n\n\ndef load_repo_lock(repo_path: Path) -&gt; tuple[dict | None, list[Diagnostic]]:\n    lock_path = repo_path / \".pantsagon.toml\"\n    if not lock_path.exists():\n        return None, [Diagnostic(code=\"LOCK_MISSING\", rule=\"repo.lock.missing\", severity=Severity.ERROR,\n            message=\"Missing .pantsagon.toml\", location=FileLocation(str(lock_path)))]\n    try:\n        return tomllib.loads(lock_path.read_text()), []\n    except Exception as e:\n        return None, [Diagnostic(code=\"LOCK_INVALID\", rule=\"repo.lock.invalid\", severity=Severity.ERROR,\n            message=f\"Invalid .pantsagon.toml: {e}\", location=FileLocation(str(lock_path)))]\n\n\ndef effective_strict(cli_strict: bool | None, lock: dict | None) -&gt; bool:\n    if cli_strict is not None:\n        return cli_strict\n    if lock is None:\n        return False\n    return bool(lock.get(\"settings\", {}).get(\"strict\", False))\n\n\ndef project_reserved_services(lock: dict | None) -&gt; set[str]:\n    if not lock:\n        return set()\n    return set(lock.get(\"settings\", {}).get(\"naming\", {}).get(\"reserved_services\", []) or [])\n</code></pre> <p>Update <code>validate_repo</code> to: - call <code>load_repo_lock</code> - if lock invalid/missing, return diagnostics immediately (skip later phases) - otherwise run phase 1/2/3 and apply <code>apply_strictness</code> at the end</p> <p>Step 4: Run tests</p> <p>Run: <code>pytest tests/application/test_validate_repo.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/repo_lock.py pantsagon/application/validate_repo.py tests/application/test_validate_repo.py\ngit commit -m \"feat: load repo lock and validate phases\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-5-pack-validation-naming-default-mismatch-warnings","title":"Task 5: Pack validation naming + default mismatch warnings","text":"<p>Files: - Modify: <code>pantsagon/adapters/policy/pack_validator.py</code> - Modify: <code>pantsagon/application/pack_validation.py</code> - Test: <code>tests/pack/test_pack_schema.py</code> - Create: <code>tests/pack/test_pack_naming.py</code> - Create: <code>tests/pack/test_copier_defaults.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/pack/test_pack_naming.py\nfrom pantsagon.application.pack_validation import validate_pack\n\ndef test_pack_id_must_be_namespaced(tmp_path):\n    pack = tmp_path / \"pack\"\n    pack.mkdir()\n    (pack / \"pack.yaml\").write_text(\"id: bad\\nversion: 1.0.0\\ncompatibility: {pants: '&gt;=2.0.0'}\")\n    (pack / \"copier.yml\").write_text(\"_min_copier_version: '9.0'\\n\")\n    result = validate_pack(pack)\n    assert any(d.code == \"PACK_ID_INVALID\" for d in result.diagnostics)\n</code></pre> <pre><code># tests/pack/test_copier_defaults.py\nfrom pantsagon.application.pack_validation import validate_pack\n\ndef test_default_mismatch_warns(tmp_path):\n    pack = tmp_path / \"pack\"\n    pack.mkdir()\n    (pack / \"pack.yaml\").write_text(\n        \"id: pantsagon.core\\nversion: 1.0.0\\ncompatibility: {pants: '&gt;=2.0.0'}\\nvariables: [{name: repo_name, type: string, default: repo}]\\n\"\n    )\n    (pack / \"copier.yml\").write_text(\"repo_name: {type: str, default: other}\\n\")\n    result = validate_pack(pack)\n    assert any(d.code == \"COPIER_DEFAULT_MISMATCH\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify failure</p> <p>Run: <code>pytest tests/pack/test_pack_naming.py tests/pack/test_copier_defaults.py -q</code> Expected: FAIL with missing diagnostics.</p> <p>Step 3: Minimal implementation</p> <ul> <li>In <code>pack_validator.py</code>, after schema validation, call <code>validate_pack_id</code>, <code>validate_feature_name</code> for each <code>provides.features</code>, and <code>validate_variable_name</code> for each variable.</li> <li>Add default mismatch detection: when both pack variable default and copier default exist and differ, emit <code>COPIER_DEFAULT_MISMATCH</code> with <code>Severity.WARN</code> and <code>upgradeable=True</code> and a <code>FileLocation</code> on <code>pack.yaml</code>.</li> <li>Keep diagnostics in deterministic order; sort inputs as needed.</li> </ul> <p>Step 4: Run tests</p> <p>Run: <code>pytest tests/pack/test_pack_naming.py tests/pack/test_copier_defaults.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/adapters/policy/pack_validator.py pantsagon/application/pack_validation.py tests/pack/test_pack_naming.py tests/pack/test_copier_defaults.py\n\ngit commit -m \"feat: validate pack ids and default mismatches\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-6-serviceinit-validation-strict-cli-flags","title":"Task 6: Service/init validation + strict CLI flags","text":"<p>Files: - Modify: <code>pantsagon/application/add_service.py</code> - Modify: <code>pantsagon/application/init_repo.py</code> - Modify: <code>pantsagon/application/rendering.py</code> - Modify: <code>pantsagon/entrypoints/cli.py</code> - Test: <code>tests/application/test_add_service.py</code> - Create: <code>tests/application/test_init_validation.py</code></p> <p>Step 1: Write failing tests</p> <pre><code># tests/application/test_add_service.py\nfrom pantsagon.application.add_service import add_service\n\ndef test_add_service_rejects_reserved(tmp_path):\n    (tmp_path / \".pantsagon.toml\").write_text(\"[settings.naming]\\nreserved_services=['api']\\n\")\n    result = add_service(repo_path=tmp_path, name=\"api\", lang=\"python\")\n    assert any(d.code == \"SERVICE_NAME_RESERVED\" for d in result.diagnostics)\n</code></pre> <pre><code># tests/application/test_init_validation.py\nfrom pantsagon.application.init_repo import init_repo\n\ndef test_init_rejects_invalid_service_name(tmp_path):\n    result = init_repo(repo_path=tmp_path, languages=[\"python\"], services=[\"bad--name\"], features=[], renderer=\"copier\")\n    assert any(d.code == \"SERVICE_NAME_INVALID\" for d in result.diagnostics)\n</code></pre> <p>Step 2: Run tests to verify failure</p> <p>Run: <code>pytest tests/application/test_add_service.py tests/application/test_init_validation.py -q</code> Expected: FAIL with missing diagnostics.</p> <p>Step 3: Minimal implementation</p> <ul> <li>In <code>add_service</code>, load repo lock, compute project reserved list, validate service name with built-ins + project names before filesystem checks.</li> <li>In <code>init_repo</code>, validate services list early (built-ins only) and return diagnostics if invalid.</li> <li>Thread <code>strict</code> flag through CLI (<code>--strict</code>) and into <code>init_repo</code> / <code>add_service</code> / <code>validate_repo</code> with precedence rules.</li> <li>Apply <code>apply_strictness</code> to diagnostics before returning from application functions.</li> </ul> <p>Step 4: Run tests</p> <p>Run: <code>pytest tests/application/test_add_service.py tests/application/test_init_validation.py -q</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add pantsagon/application/add_service.py pantsagon/application/init_repo.py pantsagon/application/rendering.py pantsagon/entrypoints/cli.py tests/application/test_add_service.py tests/application/test_init_validation.py\n\ngit commit -m \"feat: enforce service naming and strict flags\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-7-update-schemas-regenerate-schema-docs","title":"Task 7: Update schemas + regenerate schema docs","text":"<p>Files: - Modify: <code>schemas/pack.schema.v1.json</code> - Modify: <code>schemas/repo-lock.schema.v1.json</code> - Modify (generated): <code>docs/reference/pack.schema.v1.md</code>, <code>docs/reference/repo-lock.schema.v1.md</code></p> <p>Step 1: Update schemas</p> <ul> <li><code>pack.schema.v1.json</code>: tighten <code>id</code> and <code>requires.packs</code> patterns to dot\u2011namespaced IDs.</li> <li><code>pack.schema.v1.json</code>: add <code>provides.features</code> items pattern <code>^[a-z][a-z0-9_-]*$</code>.</li> <li><code>repo-lock.schema.v1.json</code>: add <code>settings.naming.reserved_services</code> array of strings.</li> <li><code>repo-lock.schema.v1.json</code>: update <code>selection.services</code> pattern to <code>^[a-z](?:[a-z0-9]*(-[a-z0-9]+)*)$</code>.</li> </ul> <p>Step 2: Regenerate docs</p> <p>Run: <code>python scripts/generate_schema_docs.py</code> Expected: <code>Generated schema docs into docs/reference</code></p> <p>Step 3: Commit</p> <pre><code>git add schemas/pack.schema.v1.json schemas/repo-lock.schema.v1.json docs/reference/pack.schema.v1.md docs/reference/repo-lock.schema.v1.md\n\ngit commit -m \"docs: tighten schemas for naming rules\"\n</code></pre>"},{"location":"plans/2026-01-10-policy-validation-hardening/#task-8-update-readme-full-test-run","title":"Task 8: Update README + full test run","text":"<p>Files: - Modify: <code>README.md</code></p> <p>Step 1: Update README</p> <p>Add a short \u201cValidation &amp; Strictness\u201d section documenting: - strict naming for services + reserved names - pack id namespace rules - <code>--strict</code> upgrades warnings to errors - <code>.pantsagon.toml</code> additive reserved service names</p> <p>Step 2: Run full tests</p> <p>Run: <code>pytest -q</code> Expected: PASS (note pytest-asyncio warning is acceptable per README).</p> <p>Step 3: Commit</p> <pre><code>git add README.md\ngit commit -m \"docs: describe validation behavior\"\n</code></pre> <p>Plan complete and saved to <code>docs/plans/2026-01-10-policy-validation-hardening.md</code>. Two execution options:</p> <ol> <li>Subagent-Driven (this session) \u2014 I dispatch fresh subagent per task, review between tasks, fast iteration</li> <li>Parallel Session (separate) \u2014 Open new session with executing-plans, batch execution with checkpoints</li> </ol> <p>Which approach?</p>"},{"location":"plugin-authoring/","title":"Plugin authoring","text":"<p>Plugins provide adapter implementations for ports (future scope).</p> <p>In v1, plugins are not loaded, but the port contracts are designed for it.</p>"},{"location":"plugin-authoring/adapters/","title":"Adapters","text":"<p>Adapters implement ports. They should:</p> <ul> <li>raise typed AdapterError on IO/exec failures</li> <li>return Result/Diagnostics for expected validation outcomes</li> </ul>"},{"location":"plugin-authoring/discovery/","title":"Discovery (future)","text":"<p>Future plugins will be discovered via Python entry points, grouped by port:</p> <ul> <li>pantsagon.pack_catalog</li> <li>pantsagon.renderer</li> <li>pantsagon.workspace</li> <li>pantsagon.policy_engine</li> <li>pantsagon.command_runner</li> </ul>"},{"location":"plugin-authoring/ports/","title":"Ports","text":"<p>Core ports:</p> <ul> <li>PackCatalogPort</li> <li>RendererPort</li> <li>WorkspacePort</li> <li>PolicyEnginePort</li> <li>CommandPort</li> </ul> <p>Ports accept and return domain objects and must not leak implementation details.</p>"},{"location":"reference/diagnostic-codes/","title":"Diagnostic codes","text":"<p>Generated file. Do not edit directly. Run: <code>python scripts/generate_diagnostic_codes.py</code></p>"},{"location":"reference/diagnostic-codes/#diagnostic-codes","title":"Diagnostic codes","text":"<p>This page is generated from <code>pantsagon/diagnostics/codes.yaml</code>.</p> Code Severity Rule Message Hint <code>COPIER_DEFAULT_MISMATCH</code> <code>warn</code> <code>pack.variables.default_mismatch</code> Copier default does not match pack.yaml default. Align defaults, or run in strict mode to fail builds. <code>COPIER_UNDECLARED_VARIABLE</code> <code>error</code> <code>pack.variables.copier_undeclared</code> Copier defines a variable that is not declared in pack.yaml. Declare it in pack.yaml.variables or remove it from copier.yml. <code>FEATURE_NAME_INVALID</code> <code>error</code> <code>naming.feature.format</code> Feature name format is invalid. Use lowercase kebab-case or snake_case with no dots. <code>FEATURE_NAME_SHADOWS_PACK</code> <code>warn</code> <code>naming.feature.shadows_pack</code> Feature name shadows a pack id. Rename the feature to avoid confusion with pack identifiers. <code>LOCK_MISSING</code> <code>error</code> <code>lock.exists</code> Repo lock file is missing. Run pantsagon init or restore .pantsagon.toml. <code>LOCK_PACK_DUPLICATE</code> <code>error</code> <code>lock.resolved.packs</code> Repo lock contains duplicate pack entries. Remove duplicate pack ids from resolved.packs. <code>LOCK_PACK_INVALID</code> <code>error</code> <code>lock.resolved.packs</code> Repo lock contains an invalid pack entry. Ensure each pack has id, version, and source. <code>LOCK_PARSE_FAILED</code> <code>error</code> <code>lock.parse</code> Repo lock file could not be parsed. Fix invalid TOML in .pantsagon.toml. <code>LOCK_SECTION_MISSING</code> <code>error</code> <code>lock.section</code> Repo lock is missing a required section. Regenerate the repo lock or repair the missing section. <code>LOCK_SELECTION_MISMATCH</code> <code>warn</code> <code>lock.selection</code> Selection does not match resolved pack set. Update selection or re-resolve packs to align. <code>PACK_COMPAT_INVALID</code> <code>error</code> <code>pack.compatibility</code> Pack compatibility metadata is invalid. Ensure compatibility.pants is a string. <code>PACK_FILE_MISSING</code> <code>error</code> <code>pack.files</code> Pack is missing a required file. Ensure pack.yaml and copier.yml exist in the pack directory. <code>PACK_ID_INVALID</code> <code>error</code> <code>naming.pack.id</code> Pack id format is invalid. Use lowercase dot-namespaced ids (e.g. pantsagon.core). <code>PACK_INDEX_UNKNOWN_FEATURE</code> <code>error</code> <code>pack.index.feature</code> Selection feature is not defined in the pack index. Add the feature mapping to packs/_index.json. <code>PACK_INDEX_UNKNOWN_LANGUAGE</code> <code>error</code> <code>pack.index.language</code> Selection language is not defined in the pack index. Add the language mapping to packs/_index.json. <code>PACK_LOCATION_MISSING</code> <code>error</code> <code>pack.catalog.fetch</code> Local pack is missing a location. Set location for local pack refs in the lock. <code>PACK_MISSING_REQUIRED</code> <code>error</code> <code>pack.requires.packs</code> Pack is missing required dependency packs. Add the required pack or choose a compatible feature set. <code>PACK_NOT_FOUND</code> <code>error</code> <code>pack.catalog.fetch</code> Pack could not be found. Check pack id/version and configured pack sources. <code>PACK_RENDER_FAILED</code> <code>error</code> <code>pack.render</code> Pack render failed. Check Copier templates and inputs. <code>REPO_LAYER_MISSING</code> <code>error</code> <code>repo.layer.exists</code> Service layer directory is missing. Regenerate the service skeleton or fix the layout. <code>REPO_SERVICE_MISSING</code> <code>error</code> <code>repo.service.exists</code> Service directory is missing for a declared service. Regenerate the service or remove it from selection. <code>SERVICE_NAME_INVALID</code> <code>error</code> <code>naming.service.format</code> Service name format is invalid. Use lowercase kebab-case without leading, trailing, or doubled dashes. <code>SERVICE_NAME_RESERVED</code> <code>error</code> <code>naming.service.reserved</code> Service name is reserved. Choose a different name or add project-level reserved names in .pantsagon.toml. <code>VARIABLE_NAME_INVALID</code> <code>error</code> <code>naming.variable.format</code> Variable name format is invalid. Use a valid identifier (letters, numbers, underscore) starting with a letter or underscore."},{"location":"reference/pack.schema.v1/","title":"pack.schema.v1","text":"<p>Generated file. Do not edit directly. Run: <code>python scripts/generate_schema_docs.py</code></p>"},{"location":"reference/pack.schema.v1/#pantsagon-pack-manifest-v1","title":"Pantsagon Pack Manifest (v1)","text":"<p>Tool-agnostic manifest describing a Pantsagon pack: identity, compatibility, features, and variables.</p> <ul> <li>$id: <code>https://pantsagon.dev/schemas/pack.schema.v1.json</code></li> <li>$schema: <code>https://json-schema.org/draft/2020-12/schema</code></li> </ul>"},{"location":"reference/pack.schema.v1/#properties","title":"Properties","text":"Name Type Required Description <code>compatibility</code> <code>object</code> yes <code>description</code> <code>string</code> no Human-readable description of the pack. <code>id</code> <code>string</code> yes Globally unique pack identifier (e.g. pantsagon.python). <code>provides</code> <code>object</code> no <code>requires</code> <code>object</code> no <code>schema_version</code> <code>integer</code> no Schema version for this manifest. <code>variables</code> <code>array</code> no Variables required or accepted by this pack. <code>version</code> <code>string</code> yes SemVer version of the pack."},{"location":"reference/pack.schema.v1/#raw-json","title":"Raw JSON","text":"<pre><code>{\n  \"$id\": \"https://pantsagon.dev/schemas/pack.schema.v1.json\",\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"additionalProperties\": false,\n  \"description\": \"Tool-agnostic manifest describing a Pantsagon pack: identity, compatibility, features, and variables.\",\n  \"properties\": {\n    \"compatibility\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"languages\": {\n          \"additionalProperties\": {\n            \"description\": \"Supported version range for a language (e.g. python: \\\"&gt;=3.12,&lt;3.15\\\").\",\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        \"pants\": {\n          \"description\": \"Supported Pants version range (PEP 440 / semver-style range).\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"pants\"\n      ],\n      \"type\": \"object\"\n    },\n    \"description\": {\n      \"description\": \"Human-readable description of the pack.\",\n      \"type\": \"string\"\n    },\n    \"id\": {\n      \"description\": \"Globally unique pack identifier (e.g. pantsagon.python).\",\n      \"pattern\": \"^[a-z][a-z0-9-]*(\\\\.[a-z][a-z0-9-]*)+$\",\n      \"type\": \"string\"\n    },\n    \"provides\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"features\": {\n          \"description\": \"Feature flags provided by this pack (e.g. openapi, docker).\",\n          \"items\": {\n            \"pattern\": \"^[a-z][a-z0-9_-]*$\",\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        \"service_templates\": {\n          \"description\": \"Service template capabilities exposed by this pack.\",\n          \"items\": {\n            \"additionalProperties\": false,\n            \"properties\": {\n              \"kind\": {\n                \"description\": \"Template kind.\",\n                \"enum\": [\n                  \"service\"\n                ],\n                \"type\": \"string\"\n              },\n              \"language\": {\n                \"description\": \"Language supported by this template.\",\n                \"type\": \"string\"\n              },\n              \"layout\": {\n                \"description\": \"Declared layout (e.g. hexagonal).\",\n                \"type\": \"string\"\n              }\n            },\n            \"required\": [\n              \"kind\",\n              \"language\"\n            ],\n            \"type\": \"object\"\n          },\n          \"type\": \"array\"\n        }\n      },\n      \"type\": \"object\"\n    },\n    \"requires\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"packs\": {\n          \"description\": \"Other packs that must be present for this pack to be applied.\",\n          \"items\": {\n            \"pattern\": \"^[a-z][a-z0-9-]*(\\\\.[a-z][a-z0-9-]*)+$\",\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        }\n      },\n      \"type\": \"object\"\n    },\n    \"schema_version\": {\n      \"const\": 1,\n      \"description\": \"Schema version for this manifest.\",\n      \"type\": \"integer\"\n    },\n    \"variables\": {\n      \"description\": \"Variables required or accepted by this pack.\",\n      \"items\": {\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"default\": {\n            \"description\": \"Default value if not provided.\"\n          },\n          \"enum\": {\n            \"description\": \"Allowed values when type is enum.\",\n            \"items\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"name\": {\n            \"description\": \"Variable name.\",\n            \"pattern\": \"^[a-zA-Z_][a-zA-Z0-9_]*$\",\n            \"type\": \"string\"\n          },\n          \"required\": {\n            \"default\": false,\n            \"description\": \"Whether the variable is required.\",\n            \"type\": \"boolean\"\n          },\n          \"type\": {\n            \"description\": \"Variable type.\",\n            \"enum\": [\n              \"string\",\n              \"int\",\n              \"bool\",\n              \"enum\"\n            ],\n            \"type\": \"string\"\n          }\n        },\n        \"required\": [\n          \"name\",\n          \"type\"\n        ],\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"version\": {\n      \"description\": \"SemVer version of the pack.\",\n      \"pattern\": \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\",\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"id\",\n    \"version\",\n    \"compatibility\"\n  ],\n  \"title\": \"Pantsagon Pack Manifest (v1)\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"reference/repo-lock.schema.v1/","title":"repo lock schema","text":"<p>Generated file. Do not edit directly. Run: <code>python scripts/generate_schema_docs.py</code></p>"},{"location":"reference/repo-lock.schema.v1/#pantsagon-repo-lock-pantsagontoml-v1","title":"Pantsagon Repo Lock (.pantsagon.toml) (v1)","text":"<p>Single source of truth for a Pantsagon-generated repository.</p> <ul> <li>$id: <code>https://pantsagon.dev/schemas/repo-lock.schema.v1.json</code></li> <li>$schema: <code>https://json-schema.org/draft/2020-12/schema</code></li> </ul>"},{"location":"reference/repo-lock.schema.v1/#properties","title":"Properties","text":"Name Type Required Description <code>resolved</code> <code>object</code> yes <code>selection</code> <code>object</code> no <code>settings</code> <code>object</code> no <code>tool</code> <code>object</code> yes"},{"location":"reference/repo-lock.schema.v1/#raw-json","title":"Raw JSON","text":"<pre><code>{\n  \"$id\": \"https://pantsagon.dev/schemas/repo-lock.schema.v1.json\",\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"additionalProperties\": false,\n  \"description\": \"Single source of truth for a Pantsagon-generated repository.\",\n  \"properties\": {\n    \"resolved\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"answers\": {\n          \"additionalProperties\": true,\n          \"description\": \"Resolved variable answers passed to the renderer.\",\n          \"type\": \"object\"\n        },\n        \"packs\": {\n          \"items\": {\n            \"additionalProperties\": false,\n            \"properties\": {\n              \"digest\": {\n                \"description\": \"Content digest for the pack.\",\n                \"type\": \"string\"\n              },\n              \"id\": {\n                \"type\": \"string\"\n              },\n              \"location\": {\n                \"description\": \"Filesystem path or URL, depending on source.\",\n                \"type\": \"string\"\n              },\n              \"ref\": {\n                \"description\": \"Git ref, commit, or registry digest.\",\n                \"type\": \"string\"\n              },\n              \"source\": {\n                \"enum\": [\n                  \"bundled\",\n                  \"local\",\n                  \"git\",\n                  \"registry\"\n                ],\n                \"type\": \"string\"\n              },\n              \"version\": {\n                \"type\": \"string\"\n              }\n            },\n            \"required\": [\n              \"id\",\n              \"version\",\n              \"source\"\n            ],\n            \"type\": \"object\"\n          },\n          \"type\": \"array\"\n        }\n      },\n      \"required\": [\n        \"packs\"\n      ],\n      \"type\": \"object\"\n    },\n    \"selection\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"augmented_coding\": {\n          \"enum\": [\n            \"agents\",\n            \"claude\",\n            \"gemini\",\n            \"none\"\n          ],\n          \"type\": \"string\"\n        },\n        \"features\": {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        \"languages\": {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        \"services\": {\n          \"items\": {\n            \"pattern\": \"^[a-z](?:[a-z0-9]*(-[a-z0-9]+)*)$\",\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        }\n      },\n      \"type\": \"object\"\n    },\n    \"settings\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"allow_hooks\": {\n          \"default\": false,\n          \"description\": \"Whether pack hooks are allowed to execute.\",\n          \"type\": \"boolean\"\n        },\n        \"naming\": {\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"reserved_services\": {\n              \"description\": \"Project-specific additional reserved service names.\",\n              \"items\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            }\n          },\n          \"type\": \"object\"\n        },\n        \"renderer\": {\n          \"default\": \"copier\",\n          \"description\": \"Renderer adapter to use.\",\n          \"type\": \"string\"\n        },\n        \"strict\": {\n          \"default\": false,\n          \"description\": \"Whether strict mode is enabled.\",\n          \"type\": \"boolean\"\n        },\n        \"strict_manifest\": {\n          \"default\": true,\n          \"description\": \"Whether manifest/Copier mismatches are fatal.\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"type\": \"object\"\n    },\n    \"tool\": {\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"name\": {\n          \"const\": \"pantsagon\",\n          \"type\": \"string\"\n        },\n        \"version\": {\n          \"description\": \"Pantsagon tool version used to generate or update this repo.\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"version\"\n      ],\n      \"type\": \"object\"\n    }\n  },\n  \"required\": [\n    \"tool\",\n    \"resolved\"\n  ],\n  \"title\": \"Pantsagon Repo Lock (.pantsagon.toml) (v1)\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"reference/result.schema.v1/","title":"result schema","text":"<p>Generated file. Do not edit directly. Run: <code>python scripts/generate_schema_docs.py</code></p>"},{"location":"reference/result.schema.v1/#pantsagon-result-v1","title":"Pantsagon Result (v1)","text":"<p>Structured output returned by Pantsagon commands for humans and machines.</p> <ul> <li>$id: <code>https://pantsagon.dev/schemas/result.schema.v1.json</code></li> <li>$schema: <code>https://json-schema.org/draft/2020-12/schema</code></li> </ul>"},{"location":"reference/result.schema.v1/#properties","title":"Properties","text":"Name Type Required Description <code>artifacts</code> <code>array</code> no Artifacts produced by the command (paths, packs, commands). <code>diagnostics</code> <code>array</code> yes Structured diagnostics emitted during execution. <code>exit_code</code> <code>integer</code> yes Process exit code. <code>result_schema_version</code> <code>integer</code> yes Schema version for the Result object."},{"location":"reference/result.schema.v1/#raw-json","title":"Raw JSON","text":"<pre><code>{\n  \"$id\": \"https://pantsagon.dev/schemas/result.schema.v1.json\",\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"additionalProperties\": false,\n  \"description\": \"Structured output returned by Pantsagon commands for humans and machines.\",\n  \"properties\": {\n    \"artifacts\": {\n      \"description\": \"Artifacts produced by the command (paths, packs, commands).\",\n      \"items\": {\n        \"additionalProperties\": true,\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"diagnostics\": {\n      \"description\": \"Structured diagnostics emitted during execution.\",\n      \"items\": {\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"code\": {\n            \"description\": \"Short, stable diagnostic code (e.g. PACK_NOT_FOUND).\",\n            \"type\": \"string\"\n          },\n          \"details\": {\n            \"additionalProperties\": true,\n            \"description\": \"Optional machine-readable details.\",\n            \"type\": \"object\"\n          },\n          \"hint\": {\n            \"description\": \"Optional remediation hint.\",\n            \"type\": \"string\"\n          },\n          \"id\": {\n            \"description\": \"Stable or deterministic diagnostic identifier.\",\n            \"type\": \"string\"\n          },\n          \"location\": {\n            \"additionalProperties\": true,\n            \"description\": \"Optional structured location of the diagnostic.\",\n            \"type\": \"object\"\n          },\n          \"message\": {\n            \"type\": \"string\"\n          },\n          \"rule\": {\n            \"description\": \"Rule identifier or namespace (e.g. pack.requires.packs).\",\n            \"type\": \"string\"\n          },\n          \"severity\": {\n            \"enum\": [\n              \"error\",\n              \"warn\",\n              \"info\"\n            ],\n            \"type\": \"string\"\n          }\n        },\n        \"required\": [\n          \"code\",\n          \"rule\",\n          \"severity\",\n          \"message\"\n        ],\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"exit_code\": {\n      \"description\": \"Process exit code.\",\n      \"enum\": [\n        0,\n        2,\n        3,\n        4\n      ],\n      \"type\": \"integer\"\n    },\n    \"result_schema_version\": {\n      \"const\": 1,\n      \"description\": \"Schema version for the Result object.\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"result_schema_version\",\n    \"exit_code\",\n    \"diagnostics\"\n  ],\n  \"title\": \"Pantsagon Result (v1)\",\n  \"type\": \"object\"\n}\n</code></pre>"}]}